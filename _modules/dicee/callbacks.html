

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dicee.callbacks &mdash; DICE Embeddings 0.1.3.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=677a9ea0" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
      <link rel="stylesheet" type="text/css" href="../../_static/theme.css?v=ea877efc" />
      <link rel="stylesheet" type="text/css" href="../../_static/theme_tweak.css?v=f0ad19f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=677a9ea0" />

  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=c6726a90"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            DICE Embeddings
              <img src="../../_static/dicee_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html">Dicee Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#download-knowledge-graphs">Download Knowledge Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#knowledge-graph-embedding-models">Knowledge Graph Embedding Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#how-to-train">How to Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#creating-an-embedding-vector-database">Creating an Embedding Vector Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#answering-complex-queries">Answering Complex Queries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#predicting-missing-links">Predicting Missing Links</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#downloading-pretrained-models">Downloading Pretrained Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#how-to-deploy">How to Deploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#docker">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#coverage-report">Coverage Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#how-to-cite">How to cite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autoapi/dicee/index.html">dicee</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DICE Embeddings</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dicee.callbacks</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dicee.callbacks</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">datetime</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">dicee.models.base_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.static_funcs</span><span class="w"> </span><span class="kn">import</span> <span class="n">save_checkpoint_model</span><span class="p">,</span> <span class="n">save_pickle</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.abstracts</span><span class="w"> </span><span class="kn">import</span> <span class="n">AbstractCallback</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LambdaLR</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.eval_static_funcs</span><span class="w"> </span><span class="kn">import</span> <span class="n">evaluate_ensemble_link_prediction_performance</span>


<div class="viewcode-block" id="AccumulateEpochLossCallback">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.AccumulateEpochLossCallback">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AccumulateEpochLossCallback</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>

<div class="viewcode-block" id="AccumulateEpochLossCallback.on_fit_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.AccumulateEpochLossCallback.on_fit_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Store epoch loss</span>


<span class="sd">        Parameter</span>
<span class="sd">        ---------</span>
<span class="sd">        trainer:</span>

<span class="sd">        model:</span>

<span class="sd">        Returns</span>
<span class="sd">        ---------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">loss_history</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;EpochLoss&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="si">}</span><span class="s1">/epoch_losses.csv&#39;</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="PrintCallback">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PrintCallback">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PrintCallback</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<div class="viewcode-block" id="PrintCallback.on_fit_start">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PrintCallback.on_fit_start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
        <span class="c1"># print(pl_module)</span>
        <span class="c1"># print(pl_module.summarize())</span>
        <span class="c1"># print(pl_module.selected_optimizer)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training is starting </span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="PrintCallback.on_fit_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PrintCallback.on_fit_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
        <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>
        <span class="k">if</span> <span class="mi">60</span> <span class="o">&gt;</span> <span class="n">training_time</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> seconds.&#39;</span>
        <span class="k">elif</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">60</span> <span class="o">&gt;</span> <span class="n">training_time</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">training_time</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">60</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> minutes.&#39;</span>
        <span class="k">elif</span> <span class="n">training_time</span> <span class="o">&gt;</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">60</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">training_time</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">60</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">60</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> hours.&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> seconds.&#39;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Runtime: </span><span class="si">{</span><span class="n">message</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="PrintCallback.on_train_batch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PrintCallback.on_train_batch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span></div>


<div class="viewcode-block" id="PrintCallback.on_train_epoch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PrintCallback.on_train_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span></div>
</div>



<div class="viewcode-block" id="KGESaveCallback">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KGESaveCallback">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">KGESaveCallback</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">every_x_epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">every_x_epoch</span> <span class="o">=</span> <span class="n">every_x_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="n">max_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">every_x_epoch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">every_x_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="KGESaveCallback.on_train_batch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KGESaveCallback.on_train_batch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span></div>


<div class="viewcode-block" id="KGESaveCallback.on_fit_start">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KGESaveCallback.on_fit_start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
        <span class="k">pass</span></div>


<div class="viewcode-block" id="KGESaveCallback.on_train_epoch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KGESaveCallback.on_train_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span></div>


<div class="viewcode-block" id="KGESaveCallback.on_fit_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KGESaveCallback.on_fit_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span></div>


<div class="viewcode-block" id="KGESaveCallback.on_epoch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KGESaveCallback.on_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">every_x_epoch</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Storing model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span><span class="si">}</span><span class="s1">...&#39;</span><span class="p">)</span>
            <span class="n">save_checkpoint_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                                  <span class="n">path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39;/model_at_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span><span class="p">)</span><span class="si">}</span><span class="s1">_&#39;</span>
                                                   <span class="sa">f</span><span class="s1">&#39;epoch_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()))</span><span class="si">}</span><span class="s1">.pt&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">+=</span> <span class="mi">1</span></div>
</div>



<div class="viewcode-block" id="PseudoLabellingCallback">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PseudoLabellingCallback">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PseudoLabellingCallback</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_module</span><span class="p">,</span> <span class="n">kg</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_module</span> <span class="o">=</span> <span class="n">data_module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kg</span> <span class="o">=</span> <span class="n">kg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_of_epochs</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unlabelled_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kg</span><span class="o">.</span><span class="n">unlabelled_set</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

<div class="viewcode-block" id="PseudoLabellingCallback.create_random_data">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PseudoLabellingCallback.create_random_data">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_random_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">entities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kg</span><span class="o">.</span><span class="n">num_entities</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">relations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kg</span><span class="o">.</span><span class="n">num_relations</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,))</span>
        <span class="c1"># unlabelled triples</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">entities</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">relations</span><span class="p">,</span> <span class="n">entities</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="PseudoLabellingCallback.on_epoch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PseudoLabellingCallback.on_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="c1"># Create random triples</span>
        <span class="c1"># if trainer.current_epoch &lt; 10:</span>
        <span class="c1">#    return None</span>
        <span class="c1"># Increase it size, Now we increase it.</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># (1) Create random triples</span>
            <span class="c1"># unlabelled_input_batch = self.create_random_data()</span>
            <span class="c1"># (2) or use unlabelled batch</span>
            <span class="n">unlabelled_input_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kg</span><span class="o">.</span><span class="n">unlabelled_set</span><span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unlabelled_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,))]</span>
            <span class="c1"># (2) Predict unlabelled batch, and use prediction as pseudo-labels</span>
            <span class="n">pseudo_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">unlabelled_input_batch</span><span class="p">))</span>
            <span class="n">selected_triples</span> <span class="o">=</span> <span class="n">unlabelled_input_batch</span><span class="p">[</span><span class="n">pseudo_label</span> <span class="o">&gt;=</span> <span class="mf">.90</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">selected_triples</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Update dataset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_module</span><span class="o">.</span><span class="n">train_set_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_module</span><span class="o">.</span><span class="n">train_set_idx</span><span class="p">,</span> <span class="n">selected_triples</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_module</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">Epoch:</span><span class="si">{</span><span class="n">trainer</span><span class="o">.</span><span class="n">current_epoch</span><span class="si">}</span><span class="s1">: Pseudo-labelling</span><span class="se">\t</span><span class="s1"> |D|= </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_module</span><span class="o">.</span><span class="n">train_set_idx</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span></div>
</div>



<div class="viewcode-block" id="estimate_q">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.estimate_q">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">estimate_q</span><span class="p">(</span><span class="n">eps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; estimate rate of convergence q from sequence esp&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">eps</span><span class="p">))))</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># fit degree 1 polynomial</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># find q</span>
    <span class="k">return</span> <span class="n">q</span></div>



<div class="viewcode-block" id="compute_convergence">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.compute_convergence">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_convergence</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">estimate_q</span><span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="o">-</span><span class="n">i</span><span class="p">:]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span></div>



<div class="viewcode-block" id="ASWA">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.ASWA">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ASWA</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Adaptive stochastic weight averaging</span>
<span class="sd">        ASWE keeps track of the validation performance and update s the ensemble model accordingly.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="o">=</span><span class="n">path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_eval_setting</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_count</span><span class="o">=</span><span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_aswa</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

<div class="viewcode-block" id="ASWA.on_fit_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.ASWA.on_fit_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="c1"># super().on_fit_end(trainer, model)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_eval_setting</span><span class="p">:</span>
            <span class="c1"># ADD this info back</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_eval_setting</span>
        
        <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">global_rank</span><span class="o">==</span><span class="n">trainer</span><span class="o">.</span><span class="n">local_rank</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">param_ensemble</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="si">}</span><span class="s2">/aswa.pt&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">param_ensemble</span><span class="p">)</span></div>


<div class="viewcode-block" id="ASWA.compute_mrr">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.ASWA.compute_mrr">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_mrr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="c1"># (2) Enable eval mode.</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># (3) MRR performance on the validation data of running model.</span>
        <span class="n">device_name</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">device</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">last_val_mrr_running_model</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
                                                            <span class="n">trained_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                                                            <span class="n">form_of_labelling</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">form_of_labelling</span><span class="p">,</span>
                                                            <span class="n">during_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s2">&quot;Val&quot;</span><span class="p">][</span><span class="s2">&quot;MRR&quot;</span><span class="p">]</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device_name</span><span class="p">)</span>
        <span class="c1"># (4) Enable train mode.</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">last_val_mrr_running_model</span></div>


<div class="viewcode-block" id="ASWA.get_aswa_state_dict">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.ASWA.get_aswa_state_dict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_aswa_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="c1"># (2) Question: Soft update or Rejection?!</span>
        <span class="n">ensemble_state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="si">}</span><span class="s2">/aswa.pt&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="c1"># Perform provision parameter update.</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">parameters</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">:</span>
                    <span class="n">ensemble_state_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ensemble_state_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">)</span> <span class="o">+</span> <span class="n">parameters</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ensemble_state_dict</span></div>


<div class="viewcode-block" id="ASWA.decide">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.ASWA.decide">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">decide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">running_model_state_dict</span><span class="p">,</span> <span class="n">ensemble_state_dict</span><span class="p">,</span> <span class="n">val_running_model</span><span class="p">,</span> <span class="n">mrr_updated_ensemble_model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform Hard Update, software or rejection</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        running_model_state_dict</span>
<span class="sd">        ensemble_state_dict</span>
<span class="sd">        val_running_model</span>
<span class="sd">        mrr_updated_ensemble_model</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># (1) HARD UPDATE:</span>
        <span class="c1"># If the validation performance of the running model is greater than</span>
        <span class="c1"># the validation performance of updated ASWA and</span>
        <span class="c1"># the validation performance of ASWA</span>
        <span class="k">if</span> <span class="n">val_running_model</span> <span class="o">&gt;</span> <span class="n">mrr_updated_ensemble_model</span> <span class="ow">and</span> <span class="n">val_running_model</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_aswa</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Hard Update &quot;&quot;&quot;</span>
            <span class="c1"># (1.1) Save the running model as ASWA</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">running_model_state_dict</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="si">}</span><span class="s2">/aswa.pt&quot;</span><span class="p">)</span>
            <span class="c1"># (2.1) Resect alphas/ensemble weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="c1"># (2.2) Store the validation performance of ASWA</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_aswa</span> <span class="o">=</span> <span class="n">val_running_model</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># (2) SOFT UPDATE:</span>
        <span class="c1"># If the validation performance of the running model is less  than</span>
        <span class="c1"># the validation performance of updated ASWA</span>
        <span class="k">if</span> <span class="n">mrr_updated_ensemble_model</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_aswa</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Soft update&quot;&quot;&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_aswa</span> <span class="o">=</span> <span class="n">mrr_updated_ensemble_model</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">ensemble_state_dict</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="si">}</span><span class="s2">/aswa.pt&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="c1"># (3) Rejection:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_aswa</span> <span class="o">&gt;</span> <span class="n">mrr_updated_ensemble_model</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot; Ignore &quot;&quot;&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span></div>


<div class="viewcode-block" id="ASWA.on_train_epoch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.ASWA.on_train_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_rank</span> <span class="o">==</span> <span class="n">trainer</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># (1) Increment epoch counter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># (2) Save the given eval setting if it is not saved.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_eval_setting</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initial_eval_setting</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">eval_model</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">eval_model</span> <span class="o">=</span> <span class="s2">&quot;val&quot;</span>
        <span class="c1"># (3) Compute MRR of the running model.</span>
        <span class="n">val_running_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_mrr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

        <span class="c1"># (4) Initialize ASWA if it is not initialized.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_aswa</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">f</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="si">}</span><span class="s2">/aswa.pt&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_aswa</span> <span class="o">=</span> <span class="n">val_running_model</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># (5) Load ASWA ensemble parameters.</span>
            <span class="n">ensemble_state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_aswa_state_dict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="c1"># (6) Initialize ASWA ensemble with (5).</span>
            <span class="n">ensemble</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>
            <span class="n">ensemble</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ensemble_state_dict</span><span class="p">)</span>
            <span class="c1"># (7) Evaluate (6) on the validation data, i.e., perform the lookahead operation.</span>
            <span class="n">mrr_updated_ensemble_model</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
                                                                <span class="n">trained_model</span><span class="o">=</span><span class="n">ensemble</span><span class="p">,</span>
                                                                <span class="n">form_of_labelling</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">form_of_labelling</span><span class="p">,</span>
                                                                <span class="n">during_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s2">&quot;Val&quot;</span><span class="p">][</span><span class="s2">&quot;MRR&quot;</span><span class="p">]</span>
            <span class="c1"># print(f&quot;| MRR Running {val_running_model:.4f} | MRR ASWA: {self.val_aswa:.4f} |ASWA|:{sum(self.alphas)}&quot;)</span>
            <span class="c1"># (8) Decide whether ASWA should be updated via the current running model.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decide</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">ensemble_state_dict</span><span class="p">,</span> <span class="n">val_running_model</span><span class="p">,</span> <span class="n">mrr_updated_ensemble_model</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="Eval">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.Eval">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Eval</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">epoch_ratio</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reports</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_ratio</span> <span class="o">=</span> <span class="n">epoch_ratio</span> <span class="k">if</span> <span class="n">epoch_ratio</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">=</span> <span class="mi">0</span>

<div class="viewcode-block" id="Eval.on_fit_start">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.Eval.on_fit_start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="k">pass</span></div>


<div class="viewcode-block" id="Eval.on_fit_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.Eval.on_fit_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">save_pickle</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reports</span><span class="p">,</span> <span class="n">file_path</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">attributes</span><span class="o">.</span><span class="n">full_storage_path</span> <span class="o">+</span> <span class="s1">&#39;/evals_per_epoch&#39;</span><span class="p">)</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(7, 7))</span>
<span class="sd">        for (p,q), mrr in pairs_to_train_mrr.items():</span>
<span class="sd">            ax1.plot(mrr, label=f&#39;{p},{q}&#39;)</span>
<span class="sd">        ax1.set_ylabel(&#39;Train MRR&#39;)</span>

<span class="sd">        for (p,q), mrr in pairs_to_val_mrr.items():</span>
<span class="sd">            ax2.plot(mrr, label=f&#39;{p},{q}&#39;)</span>
<span class="sd">        ax2.set_ylabel(&#39;Val MRR&#39;)</span>

<span class="sd">        plt.legend()</span>
<span class="sd">        plt.xlabel(&#39;Epochs&#39;)</span>
<span class="sd">        plt.savefig(&#39;{full_storage_path}train_val_mrr.pdf&#39;)</span>
<span class="sd">        plt.show()</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Eval.on_train_epoch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.Eval.on_train_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_ratio</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="n">report</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="n">trained_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                                            <span class="n">form_of_labelling</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">form_of_labelling</span><span class="p">,</span> <span class="n">during_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reports</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">report</span><span class="p">)</span></div>


<div class="viewcode-block" id="Eval.on_train_batch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.Eval.on_train_batch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span></div>
</div>



<div class="viewcode-block" id="KronE">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KronE">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">KronE</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="KronE.batch_kronecker_product">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KronE.batch_kronecker_product">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_kronecker_product</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Kronecker product of matrices a and b with leading batch dimensions.</span>
<span class="sd">        Batch dimensions are broadcast. The number of them mush</span>
<span class="sd">        :type a: torch.Tensor</span>
<span class="sd">        :type b: torch.Tensor</span>
<span class="sd">        :rtype: torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">b</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">siz1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">b</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">siz0</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">siz0</span> <span class="o">+</span> <span class="n">siz1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="KronE.get_kronecker_triple_representation">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KronE.get_kronecker_triple_representation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_kronecker_triple_representation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indexed_triple</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get kronecker embeddings</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">indexed_triple</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="c1"># Get the embeddings</span>
        <span class="n">head_ent_emb</span><span class="p">,</span> <span class="n">rel_ent_emb</span><span class="p">,</span> <span class="n">tail_ent_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">indexed_triple</span><span class="p">)</span>

        <span class="n">head_ent_kron_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_kronecker_product</span><span class="p">(</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">head_ent_emb</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">rel_ent_kron_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_kronecker_product</span><span class="p">(</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">rel_ent_emb</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">tail_ent_kron_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_kronecker_product</span><span class="p">(</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">tail_ent_emb</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">head_ent_emb</span><span class="p">,</span> <span class="n">head_ent_kron_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> \
            <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">rel_ent_emb</span><span class="p">,</span> <span class="n">rel_ent_kron_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> \
            <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">tail_ent_emb</span><span class="p">,</span> <span class="n">tail_ent_kron_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="KronE.on_fit_start">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.KronE.on_fit_start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">normalize_head_entity_embeddings</span><span class="p">,</span> <span class="n">dicee</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">IdentityClass</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_triple_representation</span>
            <span class="n">model</span><span class="o">.</span><span class="n">get_triple_representation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_kronecker_triple_representation</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Normalizer should be reinitialized&#39;</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Perturb">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.Perturb">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Perturb</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; A callback for a three-Level Perturbation</span>

<span class="sd">    Input Perturbation: During training an input x is perturbed by randomly replacing its element.</span>
<span class="sd">    In the context of knowledge graph embedding models, x can denote a triple, a tuple of an entity and a relation,</span>
<span class="sd">    or a tuple of two entities.</span>
<span class="sd">    A perturbation means that a component of x is randomly replaced by an entity or a relation.</span>

<span class="sd">    Parameter Perturbation:</span>

<span class="sd">    Output Perturbation:</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">scaler</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">frequency</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        level in {input, param, output}</span>
<span class="sd">        ratio:float btw [0,1] a percentage of mini-batch data point to be perturbed.</span>
<span class="sd">        method = ?</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">assert</span> <span class="n">level</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;param&quot;</span><span class="p">,</span> <span class="s2">&quot;out&quot;</span><span class="p">}</span>
        <span class="k">assert</span> <span class="n">ratio</span> <span class="o">&gt;=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="n">level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">scaler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frequency</span> <span class="o">=</span> <span class="n">frequency</span>  <span class="c1"># per epoch, per mini-batch ?</span>

<div class="viewcode-block" id="Perturb.on_train_batch_start">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.Perturb.on_train_batch_start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_batch_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="c1"># Modifications should be in-place</span>
        <span class="c1"># (1) Extract the input and output data points in a given batch.</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="c1"># (2) Compute the number of perturbed data points.</span>
        <span class="n">num_of_perturbed_data</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_of_perturbed_data</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="c1"># (3) Detect the device on which data points reside</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="c1"># (4) Sample random integers from 0 to n without replacement and take num_of_perturbed_data of tem</span>
        <span class="n">random_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)[:</span><span class="n">num_of_perturbed_data</span><span class="p">]</span>
        <span class="c1"># (5) Apply perturbation depending on the level.</span>

        <span class="c1"># (5.1) Apply Input level perturbation.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="s2">&quot;input&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="c1"># (5.1.1) Perturb input via heads: Sample random indices for heads.</span>
                <span class="n">perturbation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">num_entities</span><span class="p">,</span>
                                             <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_of_perturbed_data</span><span class="p">,),</span>
                                             <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># Replace the head entities with (5.1.1) on given randomly selected data points in a mini-batch.</span>
                <span class="n">x</span><span class="p">[</span><span class="n">random_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">perturbation</span><span class="p">,</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">][</span><span class="n">random_indices</span><span class="p">]))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># (5.1.2) Perturb input via relations : Sample random indices for relations.</span>
                <span class="n">perturbation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">num_relations</span><span class="p">,</span>
                                             <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_of_perturbed_data</span><span class="p">,),</span>
                                             <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># Replace the relations with (5.1.2) on given randomly selected data points in a mini-batch.</span>
                <span class="n">x</span><span class="p">[</span><span class="n">random_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">][</span><span class="n">random_indices</span><span class="p">],</span> <span class="n">perturbation</span><span class="p">))</span>
        <span class="c1"># (5.2) Apply Parameter level perturbation.</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="s2">&quot;param&quot;</span><span class="p">:</span>
            <span class="n">h</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="c1"># (5.2.1) Apply Gaussian Perturbation</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;GN&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                    <span class="c1"># (5.2.1.1) Apply Gaussian Perturbation on heads.</span>
                    <span class="n">h_selected</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">random_indices</span><span class="p">]</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">entity_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">h_selected</span><span class="p">]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="p">,</span>
                                                                                   <span class="n">size</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">entity_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span>
                                                                                       <span class="n">h_selected</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                                                                   <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># (5.2.1.2) Apply Gaussian Perturbation on relations.</span>
                    <span class="n">r_selected</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">random_indices</span><span class="p">]</span>
                    <span class="k">with</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()):</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">relation_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">r_selected</span><span class="p">]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="p">,</span>
                                                                                     <span class="n">size</span><span class="o">=</span>
                                                                                     <span class="n">model</span><span class="o">.</span><span class="n">entity_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span>
                                                                                         <span class="n">r_selected</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                                                                     <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># (5.2.2) Apply Random Perturbation</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;RN&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                    <span class="c1"># (5.2.2.1) Apply Random Perturbation on heads.</span>
                    <span class="n">h_selected</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">random_indices</span><span class="p">]</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">entity_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">h_selected</span><span class="p">]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
                            <span class="n">size</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">entity_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">h_selected</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># (5.2.2.2) Apply Random Perturbation on relations.</span>
                    <span class="n">r_selected</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">random_indices</span><span class="p">]</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">relation_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">r_selected</span><span class="p">]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
                            <span class="n">size</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">entity_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">r_selected</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--method is given as </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="s2">&quot;out&quot;</span><span class="p">:</span>
            <span class="c1"># (5.3) Apply output level perturbation.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;Soft&quot;</span><span class="p">:</span>
                <span class="c1"># (5.3) Output level soft perturbation resembles label smoothing.</span>
                <span class="c1"># (5.3.1) Compute the perturbation rate.</span>
                <span class="n">perturb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span>
                <span class="c1"># https://pytorch.org/docs/stable/generated/torch.where.html</span>
                <span class="c1"># 1.0 =&gt; 1.0 - perturb</span>
                <span class="c1"># 0.0 =&gt; perturb</span>
                <span class="c1"># (5.3.2) Reduces 1s and increases 0s via (5.2.1)</span>
                <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">random_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">random_indices</span><span class="p">]</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">perturb</span><span class="p">,</span> <span class="n">perturb</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;Hard&quot;</span><span class="p">:</span>
                <span class="c1"># (5.3) Output level hard perturbation flips 1s to 0 and 0s to 1s.</span>
                <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">random_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">random_indices</span><span class="p">]</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--level is given as </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="PeriodicEvalCallback">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PeriodicEvalCallback">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PeriodicEvalCallback</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Callback to periodically evaluate the model and optionally save checkpoints during training.</span>

<span class="sd">    Evaluates at regular intervals (every N epochs) or at explicitly specified epochs.</span>
<span class="sd">    Stores evaluation reports and model checkpoints.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experiment_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">eval_every_n_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">eval_at_epochs</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">save_model_every_n_epoch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">n_epochs_eval_model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;val_test&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the PeriodicEvalCallback.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        experiment_path : str</span>
<span class="sd">            Directory where evaluation reports and model checkpoints will be saved.</span>
<span class="sd">        max_epochs : int</span>
<span class="sd">            Maximum number of training epochs.</span>
<span class="sd">        eval_every_n_epoch : int, optional</span>
<span class="sd">            Evaluate every N epochs. Ignored if eval_at_epochs is provided.</span>
<span class="sd">        eval_at_epochs : list, optional</span>
<span class="sd">            List of specific epochs at which to evaluate. If provided and non-empty, overrides eval_every_n_epoch.</span>
<span class="sd">        save_model_every_n_epoch : bool, optional</span>
<span class="sd">            Whether to save model checkpoints at each evaluation epoch.</span>
<span class="sd">        n_epochs_eval_model : str, optional</span>
<span class="sd">            Evaluation mode for N epochs. Default is &quot;val_test&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment_dir</span> <span class="o">=</span> <span class="n">experiment_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="n">max_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_model_every_n_epoch</span> <span class="o">=</span> <span class="n">save_model_every_n_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reports</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_epochs_eval_model</span> <span class="o">=</span> <span class="n">n_epochs_eval_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_eval_model</span> <span class="o">=</span>  <span class="kc">None</span>

        <span class="c1"># Determine evaluation epochs: combine explicit list and interval if provided</span>
        <span class="n">eval_epochs_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">eval_at_epochs</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">eval_at_epochs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">eval_epochs_set</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">eval_at_epochs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eval_every_n_epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">eval_epochs_set</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">eval_every_n_epoch</span><span class="p">,</span> <span class="n">max_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">eval_every_n_epoch</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_epochs</span> <span class="o">=</span> <span class="n">eval_epochs_set</span>

        <span class="c1"># Prepare directory for model checkpoints if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model_every_n_epoch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_epochs_storage_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_dir</span><span class="p">,</span> <span class="s1">&#39;models_n_epochs&#39;</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_epochs_storage_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<div class="viewcode-block" id="PeriodicEvalCallback.on_fit_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PeriodicEvalCallback.on_fit_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Called at the end of training. Saves final evaluation report.&quot;&quot;&quot;</span>
        <span class="n">report_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_dir</span><span class="p">,</span> <span class="s1">&#39;eval_report_n_epochs.json&#39;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">report_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reports</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></div>


<div class="viewcode-block" id="PeriodicEvalCallback.on_train_epoch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.PeriodicEvalCallback.on_train_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Called at the end of each training epoch. Performs evaluation and checkpointing if scheduled.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        trainer : object</span>
<span class="sd">            The training controller.</span>
<span class="sd">        model : torch.nn.Module</span>
<span class="sd">            The model being trained.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Check if current epoch is scheduled for evaluation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_epochs</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_eval_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Store the initial evaluation mode</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">default_eval_model</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">eval_model</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">split</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_eval_model</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_epochs_eval_model</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)):</span>
                    <span class="c1"># Skip evaluation at the end</span>
                    <span class="k">return</span>

            <span class="c1"># Set evaluation mode to the one specified in the callback</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_epochs_eval_model</span>
            <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;swa&quot;</span><span class="p">]:</span>
                <span class="c1"># If SWA is enabled, use the SWA model for evaluation</span>
                <span class="n">eval_model</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">swa_model</span>
            <span class="k">elif</span> <span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;adaptive_swa&quot;</span><span class="p">]:</span>
                <span class="c1"># If ASWA is enabled, use the ASWA model for evaluation</span>
                <span class="n">aswa_ensemble_params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_dir</span><span class="si">}</span><span class="s2">/aswa.pt&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
                <span class="c1"># Create a new model instance for evaluation</span>
                <span class="n">eval_model</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>
                <span class="n">eval_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">aswa_ensemble_params</span><span class="p">)</span>
                <span class="n">eval_model</span> <span class="o">=</span> <span class="n">eval_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">eval_model</span> <span class="o">=</span> <span class="n">model</span>
            
            <span class="c1"># Ensure the model is in evaluation mode</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">eval_model</span><span class="o">.</span><span class="n">device</span>  <span class="c1"># Save current device</span>
            <span class="n">eval_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>        <span class="c1"># Move model to CPU for evaluation</span>
            <span class="n">eval_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>           <span class="c1"># Set model to evaluation mode</span>

            <span class="c1"># Run evaluation using trainer&#39;s evaluator</span>
            <span class="n">report</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span>
                <span class="n">dataset</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
                <span class="n">trained_model</span><span class="o">=</span><span class="n">eval_model</span><span class="p">,</span>
                <span class="n">form_of_labelling</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">form_of_labelling</span><span class="p">,</span>
                <span class="n">during_training</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="n">eval_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>       <span class="c1"># Restore model device</span>
            <span class="n">eval_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>         <span class="c1"># Set model back to training mode</span>

            <span class="c1"># Restore the initial evaluation mode</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_eval_model</span>

            <span class="c1"># Store evaluation report</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reports</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;epoch_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span><span class="si">}</span><span class="s1">_eval&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">report</span>

            <span class="c1"># Optionally save model checkpoint</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model_every_n_epoch</span><span class="p">:</span>
                <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_epochs_storage_path</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;model_at_epoch_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch_counter</span><span class="si">}</span><span class="s1">.pt&#39;</span><span class="p">)</span>
                <span class="n">save_checkpoint_model</span><span class="p">(</span><span class="n">eval_model</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">save_path</span><span class="p">)</span></div>
</div>

<div class="viewcode-block" id="LRScheduler">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.LRScheduler">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LRScheduler</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Callback for managing learning rate scheduling and model snapshots.</span>

<span class="sd">    Supports cosine annealing (&quot;cca&quot;), MMCCLR (&quot;mmcclr&quot;), and their deferred (warmup) variants:</span>
<span class="sd">    - &quot;deferred_cca&quot;</span>
<span class="sd">    - &quot;deferred_mmcclr&quot;</span>

<span class="sd">    At the end of each learning rate cycle, the model can optionally be saved as a snapshot.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">adaptive_lr_config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">total_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">experiment_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">eta_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">snapshot_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;snapshots&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the LR scheduler callback.</span>

<span class="sd">        Args:</span>
<span class="sd">            adaptive_lr_config (dict): Configuration dictionary containing LR scheduling parameters.</span>
<span class="sd">                Can include: scheduler_name, lr_min, num_cycles, weighted_ensemble, n_snapshots</span>
<span class="sd">            total_epochs (int): Total number of training epochs (args.num_epochs)</span>
<span class="sd">            experiment_dir (str): Directory for the experiment, used as base for snapshots.</span>
<span class="sd">            eta_max (float, optional): Maximum learning rate at the start of each cycle.</span>
<span class="sd">                passed from `args.lr`. Default is 0.1.</span>
<span class="sd">            snapshot_dir (str, optional): Subdirectory inside experiment_dir where snapshots will be saved. Default is &quot;snapshots&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Validate and set defaults for configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_and_set_config</span><span class="p">(</span><span class="n">adaptive_lr_config</span><span class="p">,</span> <span class="n">eta_max</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="n">total_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment_dir</span> <span class="o">=</span> <span class="n">experiment_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">snapshot_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">experiment_dir</span><span class="p">,</span> <span class="n">snapshot_dir</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">snapshot_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_max</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_min</span><span class="p">,</span> \
            <span class="sa">f</span><span class="s2">&quot;Max Learning Rate (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eta_max</span><span class="si">}</span><span class="s2">) must be greater than Min Learning Rate (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eta_min</span><span class="si">}</span><span class="s2">)&quot;</span>

        <span class="c1"># Calculate warmup epochs only for deferred schedulers</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;deferred&quot;</span><span class="p">):</span>
            <span class="c1"># Use formula: defer for (n_cycles - n_snapshots) cycles</span>
            <span class="n">deferred_cycles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_snapshots</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">warmup_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">deferred_cycles</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Non-deferred schedulers don&#39;t use warmup</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">warmup_epochs</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Placeholders to be set during training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batches_per_epoch</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cycle_length</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_lambda</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">snapshot_loss</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_and_set_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">eta_max</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Validate the adaptive_lr_config and set default values for missing parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Default configuration</span>
        <span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;scheduler_name&quot;</span><span class="p">:</span> <span class="s2">&quot;cca&quot;</span><span class="p">,</span>
            <span class="s2">&quot;lr_min&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
            <span class="s2">&quot;num_cycles&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
            <span class="s2">&quot;weighted_ensemble&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;n_snapshots&quot;</span><span class="p">:</span> <span class="mi">5</span>
        <span class="p">}</span>
        
        <span class="c1"># Validate config is a dictionary</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;adaptive_lr_config must be a dictionary&quot;</span><span class="p">)</span>
        
        <span class="c1"># Validate scheduler_name</span>
        <span class="k">if</span> <span class="s2">&quot;scheduler_name&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="n">valid_schedulers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cca&quot;</span><span class="p">,</span> <span class="s2">&quot;mmcclr&quot;</span><span class="p">,</span> <span class="s2">&quot;deferred_cca&quot;</span><span class="p">,</span> <span class="s2">&quot;deferred_mmcclr&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;scheduler_name&quot;</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_schedulers</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid scheduler_name &#39;</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;scheduler_name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;. &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;Must be one of: </span><span class="si">{</span><span class="n">valid_schedulers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Validate lr_min</span>
        <span class="k">if</span> <span class="s2">&quot;lr_min&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="n">lr_min</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr_min&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr_min</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">or</span> <span class="n">lr_min</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;lr_min must be a positive number, got: </span><span class="si">{</span><span class="n">lr_min</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">lr_min</span> <span class="o">&gt;=</span> <span class="n">eta_max</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;lr_min (</span><span class="si">{</span><span class="n">lr_min</span><span class="si">}</span><span class="s2">) must be less than eta_max (</span><span class="si">{</span><span class="n">eta_max</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        
        <span class="c1"># Validate num_cycles</span>
        <span class="k">if</span> <span class="s2">&quot;num_cycles&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="n">num_cycles</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_cycles&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_cycles</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">or</span> <span class="n">num_cycles</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;num_cycles must be a positive number, got: </span><span class="si">{</span><span class="n">num_cycles</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Validate n_snapshots</span>
        <span class="k">if</span> <span class="s2">&quot;n_snapshots&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="n">n_snapshots</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;n_snapshots&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_snapshots</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">n_snapshots</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_snapshots must be a positive integer, got: </span><span class="si">{</span><span class="n">n_snapshots</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Validate weighted_ensemble</span>
        <span class="k">if</span> <span class="s2">&quot;weighted_ensemble&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="n">weighted_ensemble</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;weighted_ensemble&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weighted_ensemble</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;weighted_ensemble must be a boolean, got: </span><span class="si">{</span><span class="n">weighted_ensemble</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Set attributes with defaults for missing values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scheduler_name&quot;</span><span class="p">,</span> <span class="n">defaults</span><span class="p">[</span><span class="s2">&quot;scheduler_name&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta_min</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lr_min&quot;</span><span class="p">,</span> <span class="n">defaults</span><span class="p">[</span><span class="s2">&quot;lr_min&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_cycles&quot;</span><span class="p">,</span> <span class="n">defaults</span><span class="p">[</span><span class="s2">&quot;num_cycles&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weighted_ensemble</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;weighted_ensemble&quot;</span><span class="p">,</span> <span class="n">defaults</span><span class="p">[</span><span class="s2">&quot;weighted_ensemble&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_snapshots</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;n_snapshots&quot;</span><span class="p">,</span> <span class="n">defaults</span><span class="p">[</span><span class="s2">&quot;n_snapshots&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta_max</span> <span class="o">=</span> <span class="n">eta_max</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_snapshots</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span><span class="p">,</span> \
            <span class="sa">f</span><span class="s2">&quot;n_snapshots (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_snapshots</span><span class="si">}</span><span class="s2">) must be less than or equal to num_cycles (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span><span class="si">}</span><span class="s2">)&quot;</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LRScheduler initialized with config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using: scheduler_name=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span><span class="si">}</span><span class="s2">, eta_min=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eta_min</span><span class="si">}</span><span class="s2">, &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;n_cycles=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span><span class="si">}</span><span class="s2">, weighted_ensemble=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">weighted_ensemble</span><span class="si">}</span><span class="s2">, &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;n_snapshots=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_snapshots</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_training_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_training_batches</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set batches per epoch, total steps, cycle length, and warmup steps.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batches_per_epoch</span> <span class="o">=</span> <span class="n">num_training_batches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batches_per_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cycle_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span>
        <span class="c1"># Ensure cycle length is at least 1 to avoid division by zero</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_length</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cycle length (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cycle_length</span><span class="si">}</span><span class="s2">) must be at least 1. &quot;</span>
                             <span class="sa">f</span><span class="s2">&quot;Total steps: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span><span class="si">}</span><span class="s2">, n_cycles: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span><span class="p">,</span> \
            <span class="sa">f</span><span class="s2">&quot;Total steps (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span><span class="si">}</span><span class="s2">) must be greater than Total Cycles (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span><span class="si">}</span><span class="s2">).&quot;</span>
        
        <span class="c1"># Calculate warmup steps based on warmup epochs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_epochs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">warmup_epochs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batches_per_epoch</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warmup steps (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="si">}</span><span class="s2">) must be less than total steps (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_get_lr_schedule</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">cosine_annealing</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="n">cycle_length</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span><span class="p">)</span>
            <span class="n">cycle_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">%</span> <span class="n">cycle_length</span>
            <span class="c1"># Return multiplier: cosine annealing between eta_min/base_lr and eta_max/base_lr</span>
            <span class="c1"># Assuming base_lr is eta_max, we scale between eta_min/eta_max and 1.0</span>
            <span class="n">cosine_factor</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">cycle_step</span> <span class="o">/</span> <span class="n">cycle_length</span><span class="p">))</span>
            <span class="n">min_multiplier</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_min</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_max</span>
            <span class="k">return</span> <span class="n">min_multiplier</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">min_multiplier</span><span class="p">)</span> <span class="o">*</span> <span class="n">cosine_factor</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">mmcclr</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="c1"># Convert step to epoch-based calculation</span>
            <span class="n">current_epoch</span> <span class="o">=</span> <span class="n">step</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batches_per_epoch</span>
            <span class="n">cycle_length_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span>
            <span class="n">cycle_step</span> <span class="o">=</span> <span class="n">current_epoch</span> <span class="o">%</span> <span class="n">cycle_length_epochs</span>
            <span class="c1"># Return multiplier: cosine annealing between eta_min/base_lr and eta_max/base_lr</span>
            <span class="c1"># Assuming base_lr is eta_max, we scale between eta_min/eta_max and 1.0</span>
            <span class="n">cosine_factor</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">cycle_step</span> <span class="o">/</span> <span class="n">cycle_length_epochs</span><span class="p">))</span>
            <span class="n">min_multiplier</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_min</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_max</span>
            <span class="k">return</span> <span class="n">min_multiplier</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">min_multiplier</span><span class="p">)</span> <span class="o">*</span> <span class="n">cosine_factor</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">deferred</span><span class="p">(</span><span class="n">base_schedule</span><span class="p">):</span>
            <span class="c1"># Warmup returns 1.0; afterwards use base schedule shifted by warmup steps</span>
            <span class="k">return</span> <span class="k">lambda</span> <span class="n">step</span><span class="p">:</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="k">else</span> <span class="n">base_schedule</span><span class="p">(</span><span class="n">step</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">)</span>

        <span class="n">sched_map</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;cca&quot;</span><span class="p">:</span> <span class="n">cosine_annealing</span><span class="p">,</span>
            <span class="s2">&quot;mmcclr&quot;</span><span class="p">:</span> <span class="n">mmcclr</span><span class="p">,</span>
            <span class="s2">&quot;deferred_cca&quot;</span><span class="p">:</span> <span class="n">deferred</span><span class="p">(</span><span class="n">cosine_annealing</span><span class="p">),</span>
            <span class="s2">&quot;deferred_mmcclr&quot;</span><span class="p">:</span> <span class="n">deferred</span><span class="p">(</span><span class="n">mmcclr</span><span class="p">),</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sched_map</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown scheduler name: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sched_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span><span class="p">]</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">_calculate_snap_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate weights for model snapshots based on their loss values.</span>
<span class="sd">        The weight for each snapshot is inversely proportional to its loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get losses in the order of the model names you intend to use in your ensemble:</span>
        <span class="n">model_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">snapshot_loss</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">snapshot_loss</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">])</span>

        <span class="n">min_loss</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="n">max_loss</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

        <span class="c1"># SnapE weights: (max+min) - model_loss</span>
        <span class="n">raw_weights</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_loss</span> <span class="o">+</span> <span class="n">min_loss</span><span class="p">)</span> <span class="o">-</span> <span class="n">losses</span>

        <span class="c1"># Clip to avoid negative weights</span>
        <span class="n">raw_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">raw_weights</span><span class="p">,</span> <span class="n">a_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Normalize weights to sum to 1</span>
        <span class="k">if</span> <span class="n">raw_weights</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">raw_weights</span> <span class="o">/</span> <span class="n">raw_weights</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">raw_weights</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_weights</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">snapshot_weights</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">model_names</span><span class="p">,</span> <span class="n">weights</span><span class="p">))</span>

<div class="viewcode-block" id="LRScheduler.on_train_start">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.LRScheduler.on_train_start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize training parameters and LR scheduler at start of training.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_training_params</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">num_training_batches</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_lambda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr_schedule</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lr_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_lambda</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using learning rate scheduler: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="LRScheduler.on_train_batch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.LRScheduler.on_train_batch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Step the LR scheduler and save model snapshot if needed after each batch.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Log the learning rate for this step</span>
        <span class="c1"># current_lr = self.scheduler.get_last_lr()[0] if hasattr(self.scheduler, &quot;get_last_lr&quot;) else None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_snapshot_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_count</span><span class="p">):</span>
            <span class="n">snapshot_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">snapshot_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;snapshot_epoch_</span><span class="si">{</span><span class="n">trainer</span><span class="o">.</span><span class="n">current_epoch</span><span class="si">}</span><span class="s2">.pt&quot;</span>
            <span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">snapshot_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">snapshot_loss</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">snapshot_path</span><span class="p">)]</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># Store loss at snapshot step</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_is_snapshot_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine if the current step is a snapshot step.</span>

<span class="sd">        For deferred schedulers: Take n_snapshots evenly distributed in the active scheduling phase.</span>
<span class="sd">        For regular schedulers: Take snapshots at the end of each cycle.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;deferred&quot;</span><span class="p">):</span>
            <span class="c1"># Skip snapshots during warmup</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            
            <span class="c1"># Take n_snapshots evenly distributed in the remaining steps after warmup</span>
            <span class="n">remaining_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span>
            <span class="n">snapshot_interval</span> <span class="o">=</span> <span class="n">remaining_steps</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_snapshots</span>
            <span class="n">steps_after_warmup</span> <span class="o">=</span> <span class="n">step</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span>
            
            <span class="c1"># Check if we&#39;re at a snapshot interval boundary</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">steps_after_warmup</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">snapshot_interval</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For non-deferred schedulers, use cycle-based snapshots</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_length</span> <span class="o">==</span> <span class="mi">0</span>

<div class="viewcode-block" id="LRScheduler.on_fit_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.LRScheduler.on_fit_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="c1"># Load all model snapshots from the snapshot directory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ensemble_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">snapshot_files</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">snapshot_dir</span><span class="p">)</span> <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.pt&#39;</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_snapshots</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">checkpoint</span> <span class="ow">in</span> <span class="n">snapshot_files</span><span class="p">:</span>
            <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">snapshot_dir</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">)</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="n">model_copy</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>
            <span class="n">model_copy</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_snapshots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_copy</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">snapshot_loss</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">weighted_ensemble</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_snap_weights</span><span class="p">()</span>
            <span class="c1"># 2. Build the weight list aligned to snapshot_files order:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ensemble_weights</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">snapshot_weights</span><span class="p">[</span><span class="n">fname</span><span class="p">]</span> <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">snapshot_files</span><span class="p">]</span>
        
        
        <span class="n">ensemble_eval_report</span> <span class="o">=</span> <span class="n">evaluate_ensemble_link_prediction_performance</span><span class="p">(</span>
            <span class="n">models</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_snapshots</span><span class="p">,</span>
            <span class="n">triples</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">test_set</span><span class="p">,</span>
            <span class="n">er_vocab</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">er_vocab</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span>
            <span class="n">weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ensemble_weights</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">num_training_batches</span><span class="p">,</span>
            <span class="n">weighted_averaging</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weighted_ensemble</span>
            <span class="p">)</span>
        <span class="c1"># Prepare a single dictionary with LR scheduling info and nested ensemble eval report</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ensemble_eval_report</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;scheduler_name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_name</span><span class="p">,</span>
            <span class="s2">&quot;total_epochs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">,</span>
            <span class="s2">&quot;num_cycles&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cycles</span><span class="p">,</span>
            <span class="s2">&quot;warmup_epochs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_epochs</span><span class="p">,</span>
            <span class="s2">&quot;lr_max&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_max</span><span class="p">,</span>
            <span class="s2">&quot;lr_min&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_min</span><span class="p">,</span>
            <span class="s2">&quot;batches_per_epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batches_per_epoch</span><span class="p">,</span>
            <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span><span class="p">,</span>
            <span class="s2">&quot;cycle_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_length</span><span class="p">,</span>
            <span class="s2">&quot;warmup_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">,</span>
            <span class="s2">&quot;weighted_ensemble&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weighted_ensemble</span><span class="p">,</span>
            <span class="s2">&quot;n_snapshots&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_snapshots</span><span class="p">,</span>
            <span class="s2">&quot;ensemble_eval_report&quot;</span><span class="p">:</span> <span class="n">ensemble_eval_report</span><span class="p">,</span>
            <span class="s2">&quot;snapshot_loss&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">snapshot_loss</span>
        <span class="p">}</span>

        <span class="n">ensemble_eval_report_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_dir</span><span class="p">,</span> <span class="s2">&quot;ensemble_eval_report.json&quot;</span><span class="p">)</span>
        <span class="c1"># Write the dictionary to the JSON file</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">ensemble_eval_report_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ensemble_eval_report</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble Evaluations: Evaluate </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> on Test Set with an ensemble of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_snapshots</span><span class="p">)</span><span class="si">}</span><span class="s2"> models: </span><span class="se">\n</span><span class="si">{</span><span class="n">ensemble_eval_report</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="SWA">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.SWA">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SWA</span><span class="p">(</span><span class="n">AbstractCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stochastic Weight Averaging callbacks.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">swa_start_epoch</span><span class="p">,</span> <span class="n">swa_c_epochs</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_init</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">swa_lr</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_epochs</span> <span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize SWA callback.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        swa_start_epoch: int</span>
<span class="sd">            The epoch at which to start SWA.</span>
<span class="sd">        swa_c_epochs: int</span>
<span class="sd">            The number of epochs to use for SWA.</span>
<span class="sd">        lr_init: float</span>
<span class="sd">            The initial learning rate.</span>
<span class="sd">        swa_lr: float</span>
<span class="sd">            The learning rate to use during SWA.</span>
<span class="sd">        max_epochs: int</span>
<span class="sd">            The maximum number of epochs. args.num_epochs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swa_start_epoch</span> <span class="o">=</span> <span class="n">swa_start_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swa_c_epochs</span> <span class="o">=</span> <span class="n">swa_c_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swa_lr</span> <span class="o">=</span> <span class="n">swa_lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_init</span> <span class="o">=</span> <span class="n">lr_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="n">max_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swa_n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    
<div class="viewcode-block" id="SWA.moving_average">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.SWA.moving_average">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">moving_average</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">swa_model</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update SWA model with moving average of current model.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">swa_param</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">swa_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
                <span class="n">swa_param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">swa_param</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span></div>

        
<div class="viewcode-block" id="SWA.on_fit_start">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.SWA.on_fit_start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize SWA model with same architecture as main model.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Check if trainer has optimizer attribute, if not, try to get from optimizers list</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;optimizers&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">trainer</span><span class="o">.</span><span class="n">optimizers</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Trainer does not have a valid optimizer or optimizers list.&quot;</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="SWA.on_train_epoch_start">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.SWA.on_train_epoch_start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update learning rate according to SWA schedule.&quot;&quot;&quot;</span>
        <span class="c1"># Get current epoch - simplified with fallback</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;current_epoch&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">current_epoch</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">+=</span> <span class="mi">1</span>
            
        <span class="c1"># Calculate learning rate using the schedule</span>
        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span>
        <span class="n">lr_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">swa_lr</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_init</span>
        
        <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">elif</span> <span class="n">t</span> <span class="o">&lt;=</span> <span class="mf">0.9</span><span class="p">:</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">lr_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.4</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="n">lr_ratio</span>
            
        <span class="n">new_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_init</span> <span class="o">*</span> <span class="n">factor</span>

        <span class="c1"># Get the optimizer from the trainer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;optimizers&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">trainer</span><span class="o">.</span><span class="n">optimizers</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">optimizers</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">trainer</span><span class="o">.</span><span class="n">optimizers</span>
            
        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_lr</span></div>

    
<div class="viewcode-block" id="SWA.on_train_epoch_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.SWA.on_train_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply SWA averaging if conditions are met.&quot;&quot;&quot;</span>
        <span class="c1">#set swa_model in trainer if eval_every_n_epochs or eval_at_epochs is set</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;eval_every_n_epochs&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;eval_at_epochs&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">swa_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span>
        <span class="c1"># Check if we should apply SWA</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">swa_start_epoch</span> <span class="ow">and</span> \
           <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">swa_start_epoch</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">swa_c_epochs</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            
            <span class="c1"># Perform moving average update with the model directly</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">moving_average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">swa_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">swa_n</span> <span class="o">+=</span> <span class="mi">1</span></div>

    
<div class="viewcode-block" id="SWA.on_fit_end">
<a class="viewcode-back" href="../../autoapi/dicee/callbacks/index.html#dicee.callbacks.SWA.on_fit_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Replace main model with SWA model at the end of training.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">swa_n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Copy SWA weights back to main model directly</span>
            <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">swa_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Caglar Demir.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>