<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dicee &mdash; DICE Embeddings 0.1.3.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8775fe07" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=eafc0fe6" />
      <link rel="stylesheet" type="text/css" href="../../_static/theme.css?v=ea877efc" />
      <link rel="stylesheet" type="text/css" href="../../_static/theme_tweak.css?v=f0ad19f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8775fe07" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=c6726a90"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="dicee.models" href="models/index.html" />
    <link rel="prev" title="Dicee Manual" href="../../usage/main.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            DICE Embeddings
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html">Dicee Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#download-knowledge-graphs">Download Knowledge Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#knowledge-graph-embedding-models">Knowledge Graph Embedding Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#how-to-train">How to Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#creating-an-embedding-vector-database">Creating an Embedding Vector Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#answering-complex-queries">Answering Complex Queries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#predicting-missing-links">Predicting Missing Links</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#downloading-pretrained-models">Downloading Pretrained Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#how-to-deploy">How to Deploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#docker">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/main.html#how-to-cite">How to cite</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="models/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="read_preprocess_save_load_kg/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.read_preprocess_save_load_kg</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="scripts/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.scripts</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="trainer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.trainer</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="abstracts/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.abstracts</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="analyse_experiments/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.analyse_experiments</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="callbacks/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.callbacks</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="config/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.config</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dataset_classes/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.dataset_classes</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="eval_static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.eval_static_funcs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="evaluator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.evaluator</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="executer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.executer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="knowledge_graph/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.knowledge_graph</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="knowledge_graph_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.knowledge_graph_embeddings</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="query_generator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.query_generator</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="sanity_checkers/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.sanity_checkers</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_funcs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="static_funcs_training/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_funcs_training</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="static_preprocess_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_preprocess_funcs</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#package-contents">Package Contents</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#classes">Classes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#functions">Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#attributes">Attributes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dicee.CMult"><code class="docutils literal notranslate"><span class="pre">CMult</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.name"><code class="docutils literal notranslate"><span class="pre">CMult.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.entity_embeddings"><code class="docutils literal notranslate"><span class="pre">CMult.entity_embeddings</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.relation_embeddings"><code class="docutils literal notranslate"><span class="pre">CMult.relation_embeddings</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.p"><code class="docutils literal notranslate"><span class="pre">CMult.p</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.q"><code class="docutils literal notranslate"><span class="pre">CMult.q</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.clifford_mul"><code class="docutils literal notranslate"><span class="pre">CMult.clifford_mul()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.score"><code class="docutils literal notranslate"><span class="pre">CMult.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.forward_triples"><code class="docutils literal notranslate"><span class="pre">CMult.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CMult.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">CMult.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">CMult.clifford_mul()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id1"><code class="docutils literal notranslate"><span class="pre">CMult.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id2"><code class="docutils literal notranslate"><span class="pre">CMult.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id3"><code class="docutils literal notranslate"><span class="pre">CMult.forward_k_vs_all()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.Pyke"><code class="docutils literal notranslate"><span class="pre">Pyke</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Pyke.name"><code class="docutils literal notranslate"><span class="pre">Pyke.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Pyke.dist_func"><code class="docutils literal notranslate"><span class="pre">Pyke.dist_func</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Pyke.margin"><code class="docutils literal notranslate"><span class="pre">Pyke.margin</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Pyke.forward_triples"><code class="docutils literal notranslate"><span class="pre">Pyke.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id4"><code class="docutils literal notranslate"><span class="pre">Pyke.forward_triples()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.DistMult"><code class="docutils literal notranslate"><span class="pre">DistMult</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DistMult.name"><code class="docutils literal notranslate"><span class="pre">DistMult.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DistMult.k_vs_all_score"><code class="docutils literal notranslate"><span class="pre">DistMult.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DistMult.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">DistMult.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DistMult.forward_k_vs_sample"><code class="docutils literal notranslate"><span class="pre">DistMult.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DistMult.score"><code class="docutils literal notranslate"><span class="pre">DistMult.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id5"><code class="docutils literal notranslate"><span class="pre">DistMult.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id6"><code class="docutils literal notranslate"><span class="pre">DistMult.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id7"><code class="docutils literal notranslate"><span class="pre">DistMult.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id8"><code class="docutils literal notranslate"><span class="pre">DistMult.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.KeciBase"><code class="docutils literal notranslate"><span class="pre">KeciBase</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.Keci"><code class="docutils literal notranslate"><span class="pre">Keci</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.name"><code class="docutils literal notranslate"><span class="pre">Keci.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.p"><code class="docutils literal notranslate"><span class="pre">Keci.p</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.q"><code class="docutils literal notranslate"><span class="pre">Keci.q</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.r"><code class="docutils literal notranslate"><span class="pre">Keci.r</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.p_coefficients"><code class="docutils literal notranslate"><span class="pre">Keci.p_coefficients</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.q_coefficients"><code class="docutils literal notranslate"><span class="pre">Keci.q_coefficients</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.compute_sigma_pp"><code class="docutils literal notranslate"><span class="pre">Keci.compute_sigma_pp()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.compute_sigma_qq"><code class="docutils literal notranslate"><span class="pre">Keci.compute_sigma_qq()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.compute_sigma_pq"><code class="docutils literal notranslate"><span class="pre">Keci.compute_sigma_pq()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.apply_coefficients"><code class="docutils literal notranslate"><span class="pre">Keci.apply_coefficients()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.clifford_multiplication"><code class="docutils literal notranslate"><span class="pre">Keci.clifford_multiplication()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.construct_cl_multivector"><code class="docutils literal notranslate"><span class="pre">Keci.construct_cl_multivector()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.forward_k_vs_with_explicit"><code class="docutils literal notranslate"><span class="pre">Keci.forward_k_vs_with_explicit()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.k_vs_all_score"><code class="docutils literal notranslate"><span class="pre">Keci.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">Keci.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.forward_k_vs_sample"><code class="docutils literal notranslate"><span class="pre">Keci.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.score"><code class="docutils literal notranslate"><span class="pre">Keci.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Keci.forward_triples"><code class="docutils literal notranslate"><span class="pre">Keci.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id9"><code class="docutils literal notranslate"><span class="pre">Keci.compute_sigma_pp()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id10"><code class="docutils literal notranslate"><span class="pre">Keci.compute_sigma_qq()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id11"><code class="docutils literal notranslate"><span class="pre">Keci.compute_sigma_pq()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id12"><code class="docutils literal notranslate"><span class="pre">Keci.apply_coefficients()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id13"><code class="docutils literal notranslate"><span class="pre">Keci.clifford_multiplication()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id14"><code class="docutils literal notranslate"><span class="pre">Keci.construct_cl_multivector()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id15"><code class="docutils literal notranslate"><span class="pre">Keci.forward_k_vs_with_explicit()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id16"><code class="docutils literal notranslate"><span class="pre">Keci.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id17"><code class="docutils literal notranslate"><span class="pre">Keci.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id18"><code class="docutils literal notranslate"><span class="pre">Keci.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id19"><code class="docutils literal notranslate"><span class="pre">Keci.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id20"><code class="docutils literal notranslate"><span class="pre">Keci.forward_triples()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.TransE"><code class="docutils literal notranslate"><span class="pre">TransE</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.TransE.name"><code class="docutils literal notranslate"><span class="pre">TransE.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.TransE._norm"><code class="docutils literal notranslate"><span class="pre">TransE._norm</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.TransE.margin"><code class="docutils literal notranslate"><span class="pre">TransE.margin</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.TransE.score"><code class="docutils literal notranslate"><span class="pre">TransE.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.TransE.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">TransE.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id21"><code class="docutils literal notranslate"><span class="pre">TransE.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id22"><code class="docutils literal notranslate"><span class="pre">TransE.forward_k_vs_all()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.DeCaL"><code class="docutils literal notranslate"><span class="pre">DeCaL</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.forward_triples"><code class="docutils literal notranslate"><span class="pre">DeCaL.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.cl_pqr"><code class="docutils literal notranslate"><span class="pre">DeCaL.cl_pqr()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.compute_sigmas_single"><code class="docutils literal notranslate"><span class="pre">DeCaL.compute_sigmas_single()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.compute_sigmas_multivect"><code class="docutils literal notranslate"><span class="pre">DeCaL.compute_sigmas_multivect()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">DeCaL.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.apply_coefficients"><code class="docutils literal notranslate"><span class="pre">DeCaL.apply_coefficients()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.construct_cl_multivector"><code class="docutils literal notranslate"><span class="pre">DeCaL.construct_cl_multivector()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.compute_sigma_pp"><code class="docutils literal notranslate"><span class="pre">DeCaL.compute_sigma_pp()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.compute_sigma_qq"><code class="docutils literal notranslate"><span class="pre">DeCaL.compute_sigma_qq()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.compute_sigma_rr"><code class="docutils literal notranslate"><span class="pre">DeCaL.compute_sigma_rr()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.compute_sigma_pq"><code class="docutils literal notranslate"><span class="pre">DeCaL.compute_sigma_pq()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.compute_sigma_pr"><code class="docutils literal notranslate"><span class="pre">DeCaL.compute_sigma_pr()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DeCaL.compute_sigma_qr"><code class="docutils literal notranslate"><span class="pre">DeCaL.compute_sigma_qr()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.ComplEx"><code class="docutils literal notranslate"><span class="pre">ComplEx</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ComplEx.name"><code class="docutils literal notranslate"><span class="pre">ComplEx.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ComplEx.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">ComplEx.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ComplEx.score"><code class="docutils literal notranslate"><span class="pre">ComplEx.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ComplEx.k_vs_all_score"><code class="docutils literal notranslate"><span class="pre">ComplEx.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id29"><code class="docutils literal notranslate"><span class="pre">ComplEx.forward_k_vs_all()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.AConEx"><code class="docutils literal notranslate"><span class="pre">AConEx</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.name"><code class="docutils literal notranslate"><span class="pre">AConEx.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.conv2d"><code class="docutils literal notranslate"><span class="pre">AConEx.conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.fc_num_input"><code class="docutils literal notranslate"><span class="pre">AConEx.fc_num_input</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.fc1"><code class="docutils literal notranslate"><span class="pre">AConEx.fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.norm_fc1"><code class="docutils literal notranslate"><span class="pre">AConEx.norm_fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.bn_conv2d"><code class="docutils literal notranslate"><span class="pre">AConEx.bn_conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.feature_map_dropout"><code class="docutils literal notranslate"><span class="pre">AConEx.feature_map_dropout</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">AConEx.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.forward_triples"><code class="docutils literal notranslate"><span class="pre">AConEx.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.forward_k_vs_sample"><code class="docutils literal notranslate"><span class="pre">AConEx.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConEx.residual_convolution"><code class="docutils literal notranslate"><span class="pre">AConEx.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id30"><code class="docutils literal notranslate"><span class="pre">AConEx.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id31"><code class="docutils literal notranslate"><span class="pre">AConEx.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id32"><code class="docutils literal notranslate"><span class="pre">AConEx.forward_k_vs_sample()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.AConvO"><code class="docutils literal notranslate"><span class="pre">AConvO</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.name"><code class="docutils literal notranslate"><span class="pre">AConvO.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.conv2d"><code class="docutils literal notranslate"><span class="pre">AConvO.conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.fc_num_input"><code class="docutils literal notranslate"><span class="pre">AConvO.fc_num_input</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.fc1"><code class="docutils literal notranslate"><span class="pre">AConvO.fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.bn_conv2d"><code class="docutils literal notranslate"><span class="pre">AConvO.bn_conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.norm_fc1"><code class="docutils literal notranslate"><span class="pre">AConvO.norm_fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.feature_map_dropout"><code class="docutils literal notranslate"><span class="pre">AConvO.feature_map_dropout</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.octonion_normalizer"><code class="docutils literal notranslate"><span class="pre">AConvO.octonion_normalizer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.residual_convolution"><code class="docutils literal notranslate"><span class="pre">AConvO.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.forward_triples"><code class="docutils literal notranslate"><span class="pre">AConvO.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvO.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">AConvO.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id33"><code class="docutils literal notranslate"><span class="pre">AConvO.octonion_normalizer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id34"><code class="docutils literal notranslate"><span class="pre">AConvO.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id35"><code class="docutils literal notranslate"><span class="pre">AConvO.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id36"><code class="docutils literal notranslate"><span class="pre">AConvO.forward_k_vs_all()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.AConvQ"><code class="docutils literal notranslate"><span class="pre">AConvQ</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.name"><code class="docutils literal notranslate"><span class="pre">AConvQ.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.entity_embeddings"><code class="docutils literal notranslate"><span class="pre">AConvQ.entity_embeddings</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.relation_embeddings"><code class="docutils literal notranslate"><span class="pre">AConvQ.relation_embeddings</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.conv2d"><code class="docutils literal notranslate"><span class="pre">AConvQ.conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.fc_num_input"><code class="docutils literal notranslate"><span class="pre">AConvQ.fc_num_input</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.fc1"><code class="docutils literal notranslate"><span class="pre">AConvQ.fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.bn_conv1"><code class="docutils literal notranslate"><span class="pre">AConvQ.bn_conv1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.bn_conv2"><code class="docutils literal notranslate"><span class="pre">AConvQ.bn_conv2</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.feature_map_dropout"><code class="docutils literal notranslate"><span class="pre">AConvQ.feature_map_dropout</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.residual_convolution"><code class="docutils literal notranslate"><span class="pre">AConvQ.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.forward_triples"><code class="docutils literal notranslate"><span class="pre">AConvQ.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AConvQ.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">AConvQ.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id37"><code class="docutils literal notranslate"><span class="pre">AConvQ.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id38"><code class="docutils literal notranslate"><span class="pre">AConvQ.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id39"><code class="docutils literal notranslate"><span class="pre">AConvQ.forward_k_vs_all()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.ConvQ"><code class="docutils literal notranslate"><span class="pre">ConvQ</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.name"><code class="docutils literal notranslate"><span class="pre">ConvQ.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.entity_embeddings"><code class="docutils literal notranslate"><span class="pre">ConvQ.entity_embeddings</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.relation_embeddings"><code class="docutils literal notranslate"><span class="pre">ConvQ.relation_embeddings</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.conv2d"><code class="docutils literal notranslate"><span class="pre">ConvQ.conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.fc_num_input"><code class="docutils literal notranslate"><span class="pre">ConvQ.fc_num_input</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.fc1"><code class="docutils literal notranslate"><span class="pre">ConvQ.fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.bn_conv1"><code class="docutils literal notranslate"><span class="pre">ConvQ.bn_conv1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.bn_conv2"><code class="docutils literal notranslate"><span class="pre">ConvQ.bn_conv2</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.feature_map_dropout"><code class="docutils literal notranslate"><span class="pre">ConvQ.feature_map_dropout</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.residual_convolution"><code class="docutils literal notranslate"><span class="pre">ConvQ.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.forward_triples"><code class="docutils literal notranslate"><span class="pre">ConvQ.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvQ.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">ConvQ.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id40"><code class="docutils literal notranslate"><span class="pre">ConvQ.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id41"><code class="docutils literal notranslate"><span class="pre">ConvQ.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id42"><code class="docutils literal notranslate"><span class="pre">ConvQ.forward_k_vs_all()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.ConvO"><code class="docutils literal notranslate"><span class="pre">ConvO</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.name"><code class="docutils literal notranslate"><span class="pre">ConvO.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.conv2d"><code class="docutils literal notranslate"><span class="pre">ConvO.conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.fc_num_input"><code class="docutils literal notranslate"><span class="pre">ConvO.fc_num_input</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.fc1"><code class="docutils literal notranslate"><span class="pre">ConvO.fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.bn_conv2d"><code class="docutils literal notranslate"><span class="pre">ConvO.bn_conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.norm_fc1"><code class="docutils literal notranslate"><span class="pre">ConvO.norm_fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.feature_map_dropout"><code class="docutils literal notranslate"><span class="pre">ConvO.feature_map_dropout</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.octonion_normalizer"><code class="docutils literal notranslate"><span class="pre">ConvO.octonion_normalizer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.residual_convolution"><code class="docutils literal notranslate"><span class="pre">ConvO.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.forward_triples"><code class="docutils literal notranslate"><span class="pre">ConvO.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConvO.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">ConvO.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id43"><code class="docutils literal notranslate"><span class="pre">ConvO.octonion_normalizer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id44"><code class="docutils literal notranslate"><span class="pre">ConvO.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id45"><code class="docutils literal notranslate"><span class="pre">ConvO.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id46"><code class="docutils literal notranslate"><span class="pre">ConvO.forward_k_vs_all()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.ConEx"><code class="docutils literal notranslate"><span class="pre">ConEx</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.name"><code class="docutils literal notranslate"><span class="pre">ConEx.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.conv2d"><code class="docutils literal notranslate"><span class="pre">ConEx.conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.fc1"><code class="docutils literal notranslate"><span class="pre">ConEx.fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.norm_fc1"><code class="docutils literal notranslate"><span class="pre">ConEx.norm_fc1</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.bn_conv2d"><code class="docutils literal notranslate"><span class="pre">ConEx.bn_conv2d</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.feature_map_dropout"><code class="docutils literal notranslate"><span class="pre">ConEx.feature_map_dropout</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.residual_convolution"><code class="docutils literal notranslate"><span class="pre">ConEx.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">ConEx.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.forward_triples"><code class="docutils literal notranslate"><span class="pre">ConEx.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.ConEx.forward_k_vs_sample"><code class="docutils literal notranslate"><span class="pre">ConEx.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id47"><code class="docutils literal notranslate"><span class="pre">ConEx.residual_convolution()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id48"><code class="docutils literal notranslate"><span class="pre">ConEx.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id49"><code class="docutils literal notranslate"><span class="pre">ConEx.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id50"><code class="docutils literal notranslate"><span class="pre">ConEx.forward_k_vs_sample()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.QMult"><code class="docutils literal notranslate"><span class="pre">QMult</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QMult.name"><code class="docutils literal notranslate"><span class="pre">QMult.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QMult.quaternion_normalizer"><code class="docutils literal notranslate"><span class="pre">QMult.quaternion_normalizer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QMult.score"><code class="docutils literal notranslate"><span class="pre">QMult.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QMult.k_vs_all_score"><code class="docutils literal notranslate"><span class="pre">QMult.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QMult.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">QMult.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QMult.forward_k_vs_sample"><code class="docutils literal notranslate"><span class="pre">QMult.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QMult.quaternion_multiplication_followed_by_inner_product"><code class="docutils literal notranslate"><span class="pre">QMult.quaternion_multiplication_followed_by_inner_product()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id51"><code class="docutils literal notranslate"><span class="pre">QMult.quaternion_multiplication_followed_by_inner_product()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id52"><code class="docutils literal notranslate"><span class="pre">QMult.quaternion_normalizer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id53"><code class="docutils literal notranslate"><span class="pre">QMult.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id54"><code class="docutils literal notranslate"><span class="pre">QMult.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id55"><code class="docutils literal notranslate"><span class="pre">QMult.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id56"><code class="docutils literal notranslate"><span class="pre">QMult.forward_k_vs_sample()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.OMult"><code class="docutils literal notranslate"><span class="pre">OMult</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.OMult.name"><code class="docutils literal notranslate"><span class="pre">OMult.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.OMult.octonion_normalizer"><code class="docutils literal notranslate"><span class="pre">OMult.octonion_normalizer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.OMult.score"><code class="docutils literal notranslate"><span class="pre">OMult.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.OMult.k_vs_all_score"><code class="docutils literal notranslate"><span class="pre">OMult.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.OMult.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">OMult.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id57"><code class="docutils literal notranslate"><span class="pre">OMult.octonion_normalizer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id58"><code class="docutils literal notranslate"><span class="pre">OMult.score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id59"><code class="docutils literal notranslate"><span class="pre">OMult.k_vs_all_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id60"><code class="docutils literal notranslate"><span class="pre">OMult.forward_k_vs_all()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.Shallom"><code class="docutils literal notranslate"><span class="pre">Shallom</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Shallom.name"><code class="docutils literal notranslate"><span class="pre">Shallom.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Shallom.shallom"><code class="docutils literal notranslate"><span class="pre">Shallom.shallom</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Shallom.get_embeddings"><code class="docutils literal notranslate"><span class="pre">Shallom.get_embeddings()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Shallom.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">Shallom.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Shallom.forward_triples"><code class="docutils literal notranslate"><span class="pre">Shallom.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id61"><code class="docutils literal notranslate"><span class="pre">Shallom.get_embeddings()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id62"><code class="docutils literal notranslate"><span class="pre">Shallom.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id63"><code class="docutils literal notranslate"><span class="pre">Shallom.forward_triples()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.LFMult"><code class="docutils literal notranslate"><span class="pre">LFMult</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.forward_triples"><code class="docutils literal notranslate"><span class="pre">LFMult.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.construct_multi_coeff"><code class="docutils literal notranslate"><span class="pre">LFMult.construct_multi_coeff()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.poly_NN"><code class="docutils literal notranslate"><span class="pre">LFMult.poly_NN()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.linear"><code class="docutils literal notranslate"><span class="pre">LFMult.linear()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.scalar_batch_NN"><code class="docutils literal notranslate"><span class="pre">LFMult.scalar_batch_NN()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.tri_score"><code class="docutils literal notranslate"><span class="pre">LFMult.tri_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.vtp_score"><code class="docutils literal notranslate"><span class="pre">LFMult.vtp_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.comp_func"><code class="docutils literal notranslate"><span class="pre">LFMult.comp_func()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.polynomial"><code class="docutils literal notranslate"><span class="pre">LFMult.polynomial()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.LFMult.pop"><code class="docutils literal notranslate"><span class="pre">LFMult.pop()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.PykeenKGE"><code class="docutils literal notranslate"><span class="pre">PykeenKGE</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.name"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.name</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.model"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.model</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.loss_history"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.loss_history</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.args"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.args</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.entity_embeddings"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.entity_embeddings</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.relation_embeddings"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.relation_embeddings</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.interaction"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.interaction</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.forward_triples"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.PykeenKGE.forward_k_vs_sample"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id64"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id65"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id66"><code class="docutils literal notranslate"><span class="pre">PykeenKGE.forward_k_vs_sample()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.BytE"><code class="docutils literal notranslate"><span class="pre">BytE</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BytE.loss_function"><code class="docutils literal notranslate"><span class="pre">BytE.loss_function()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BytE.forward"><code class="docutils literal notranslate"><span class="pre">BytE.forward()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BytE.generate"><code class="docutils literal notranslate"><span class="pre">BytE.generate()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BytE.training_step"><code class="docutils literal notranslate"><span class="pre">BytE.training_step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.BaseKGE"><code class="docutils literal notranslate"><span class="pre">BaseKGE</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.forward_byte_pair_encoded_k_vs_all"><code class="docutils literal notranslate"><span class="pre">BaseKGE.forward_byte_pair_encoded_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.forward_byte_pair_encoded_triple"><code class="docutils literal notranslate"><span class="pre">BaseKGE.forward_byte_pair_encoded_triple()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.init_params_with_sanity_checking"><code class="docutils literal notranslate"><span class="pre">BaseKGE.init_params_with_sanity_checking()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.forward"><code class="docutils literal notranslate"><span class="pre">BaseKGE.forward()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.forward_triples"><code class="docutils literal notranslate"><span class="pre">BaseKGE.forward_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.forward_k_vs_all"><code class="docutils literal notranslate"><span class="pre">BaseKGE.forward_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.forward_k_vs_sample"><code class="docutils literal notranslate"><span class="pre">BaseKGE.forward_k_vs_sample()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.get_triple_representation"><code class="docutils literal notranslate"><span class="pre">BaseKGE.get_triple_representation()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.get_head_relation_representation"><code class="docutils literal notranslate"><span class="pre">BaseKGE.get_head_relation_representation()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.get_sentence_representation"><code class="docutils literal notranslate"><span class="pre">BaseKGE.get_sentence_representation()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.get_bpe_head_and_relation_representation"><code class="docutils literal notranslate"><span class="pre">BaseKGE.get_bpe_head_and_relation_representation()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BaseKGE.get_embeddings"><code class="docutils literal notranslate"><span class="pre">BaseKGE.get_embeddings()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.create_recipriocal_triples"><code class="docutils literal notranslate"><span class="pre">create_recipriocal_triples()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.get_er_vocab"><code class="docutils literal notranslate"><span class="pre">get_er_vocab()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.get_re_vocab"><code class="docutils literal notranslate"><span class="pre">get_re_vocab()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.get_ee_vocab"><code class="docutils literal notranslate"><span class="pre">get_ee_vocab()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.timeit"><code class="docutils literal notranslate"><span class="pre">timeit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.save_pickle"><code class="docutils literal notranslate"><span class="pre">save_pickle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.load_pickle"><code class="docutils literal notranslate"><span class="pre">load_pickle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.select_model"><code class="docutils literal notranslate"><span class="pre">select_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.load_model_ensemble"><code class="docutils literal notranslate"><span class="pre">load_model_ensemble()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.save_numpy_ndarray"><code class="docutils literal notranslate"><span class="pre">save_numpy_ndarray()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.numpy_data_type_changer"><code class="docutils literal notranslate"><span class="pre">numpy_data_type_changer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.save_checkpoint_model"><code class="docutils literal notranslate"><span class="pre">save_checkpoint_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.store"><code class="docutils literal notranslate"><span class="pre">store()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.add_noisy_triples"><code class="docutils literal notranslate"><span class="pre">add_noisy_triples()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.read_or_load_kg"><code class="docutils literal notranslate"><span class="pre">read_or_load_kg()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.intialize_model"><code class="docutils literal notranslate"><span class="pre">intialize_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.load_json"><code class="docutils literal notranslate"><span class="pre">load_json()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.save_embeddings"><code class="docutils literal notranslate"><span class="pre">save_embeddings()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.random_prediction"><code class="docutils literal notranslate"><span class="pre">random_prediction()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.deploy_triple_prediction"><code class="docutils literal notranslate"><span class="pre">deploy_triple_prediction()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.deploy_tail_entity_prediction"><code class="docutils literal notranslate"><span class="pre">deploy_tail_entity_prediction()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.deploy_head_entity_prediction"><code class="docutils literal notranslate"><span class="pre">deploy_head_entity_prediction()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.deploy_relation_prediction"><code class="docutils literal notranslate"><span class="pre">deploy_relation_prediction()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.vocab_to_parquet"><code class="docutils literal notranslate"><span class="pre">vocab_to_parquet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.create_experiment_folder"><code class="docutils literal notranslate"><span class="pre">create_experiment_folder()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.continual_training_setup_executor"><code class="docutils literal notranslate"><span class="pre">continual_training_setup_executor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.exponential_function"><code class="docutils literal notranslate"><span class="pre">exponential_function()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.load_numpy"><code class="docutils literal notranslate"><span class="pre">load_numpy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.evaluate"><code class="docutils literal notranslate"><span class="pre">evaluate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.download_file"><code class="docutils literal notranslate"><span class="pre">download_file()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.download_files_from_url"><code class="docutils literal notranslate"><span class="pre">download_files_from_url()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.download_pretrained_model"><code class="docutils literal notranslate"><span class="pre">download_pretrained_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.DICE_Trainer"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.report"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.report</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.trainer"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.trainer</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.form_of_labelling"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.form_of_labelling</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.continual_start"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.continual_start()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.initialize_trainer"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.initialize_trainer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.initialize_or_load_model"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.initialize_or_load_model()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.initialize_dataloader"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.initialize_dataloader()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.initialize_dataset"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.initialize_dataset()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.start"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.start()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.DICE_Trainer.k_fold_cross_validation"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.k_fold_cross_validation()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id67"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.continual_start()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id68"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.initialize_trainer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id69"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.initialize_or_load_model()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id70"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.initialize_dataloader()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id71"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.initialize_dataset()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id72"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.start()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#id73"><code class="docutils literal notranslate"><span class="pre">DICE_Trainer.k_fold_cross_validation()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.KGE"><code class="docutils literal notranslate"><span class="pre">KGE</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.get_transductive_entity_embeddings"><code class="docutils literal notranslate"><span class="pre">KGE.get_transductive_entity_embeddings()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.create_vector_database"><code class="docutils literal notranslate"><span class="pre">KGE.create_vector_database()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.generate"><code class="docutils literal notranslate"><span class="pre">KGE.generate()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.__str__"><code class="docutils literal notranslate"><span class="pre">KGE.__str__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.eval_lp_performance"><code class="docutils literal notranslate"><span class="pre">KGE.eval_lp_performance()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.predict_missing_head_entity"><code class="docutils literal notranslate"><span class="pre">KGE.predict_missing_head_entity()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.predict_missing_relations"><code class="docutils literal notranslate"><span class="pre">KGE.predict_missing_relations()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.predict_missing_tail_entity"><code class="docutils literal notranslate"><span class="pre">KGE.predict_missing_tail_entity()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.predict"><code class="docutils literal notranslate"><span class="pre">KGE.predict()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.predict_topk"><code class="docutils literal notranslate"><span class="pre">KGE.predict_topk()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.triple_score"><code class="docutils literal notranslate"><span class="pre">KGE.triple_score()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.t_norm"><code class="docutils literal notranslate"><span class="pre">KGE.t_norm()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.tensor_t_norm"><code class="docutils literal notranslate"><span class="pre">KGE.tensor_t_norm()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.t_conorm"><code class="docutils literal notranslate"><span class="pre">KGE.t_conorm()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.negnorm"><code class="docutils literal notranslate"><span class="pre">KGE.negnorm()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.return_multi_hop_query_results"><code class="docutils literal notranslate"><span class="pre">KGE.return_multi_hop_query_results()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.single_hop_query_answering"><code class="docutils literal notranslate"><span class="pre">KGE.single_hop_query_answering()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.answer_multi_hop_query"><code class="docutils literal notranslate"><span class="pre">KGE.answer_multi_hop_query()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.find_missing_triples"><code class="docutils literal notranslate"><span class="pre">KGE.find_missing_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.deploy"><code class="docutils literal notranslate"><span class="pre">KGE.deploy()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.train_triples"><code class="docutils literal notranslate"><span class="pre">KGE.train_triples()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.train_k_vs_all"><code class="docutils literal notranslate"><span class="pre">KGE.train_k_vs_all()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KGE.train"><code class="docutils literal notranslate"><span class="pre">KGE.train()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.Execute"><code class="docutils literal notranslate"><span class="pre">Execute</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Execute.read_or_load_kg"><code class="docutils literal notranslate"><span class="pre">Execute.read_or_load_kg()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Execute.read_preprocess_index_serialize_data"><code class="docutils literal notranslate"><span class="pre">Execute.read_preprocess_index_serialize_data()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Execute.load_indexed_data"><code class="docutils literal notranslate"><span class="pre">Execute.load_indexed_data()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Execute.save_trained_model"><code class="docutils literal notranslate"><span class="pre">Execute.save_trained_model()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Execute.end"><code class="docutils literal notranslate"><span class="pre">Execute.end()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Execute.write_report"><code class="docutils literal notranslate"><span class="pre">Execute.write_report()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.Execute.start"><code class="docutils literal notranslate"><span class="pre">Execute.start()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.mapping_from_first_two_cols_to_third"><code class="docutils literal notranslate"><span class="pre">mapping_from_first_two_cols_to_third()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id89"><code class="docutils literal notranslate"><span class="pre">timeit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id90"><code class="docutils literal notranslate"><span class="pre">load_pickle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.reload_dataset"><code class="docutils literal notranslate"><span class="pre">reload_dataset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.construct_dataset"><code class="docutils literal notranslate"><span class="pre">construct_dataset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.BPE_NegativeSamplingDataset"><code class="docutils literal notranslate"><span class="pre">BPE_NegativeSamplingDataset</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BPE_NegativeSamplingDataset.__len__"><code class="docutils literal notranslate"><span class="pre">BPE_NegativeSamplingDataset.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BPE_NegativeSamplingDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">BPE_NegativeSamplingDataset.__getitem__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.BPE_NegativeSamplingDataset.collate_fn"><code class="docutils literal notranslate"><span class="pre">BPE_NegativeSamplingDataset.collate_fn()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.MultiLabelDataset"><code class="docutils literal notranslate"><span class="pre">MultiLabelDataset</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.MultiLabelDataset.__len__"><code class="docutils literal notranslate"><span class="pre">MultiLabelDataset.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.MultiLabelDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">MultiLabelDataset.__getitem__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.MultiClassClassificationDataset"><code class="docutils literal notranslate"><span class="pre">MultiClassClassificationDataset</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.MultiClassClassificationDataset.__len__"><code class="docutils literal notranslate"><span class="pre">MultiClassClassificationDataset.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.MultiClassClassificationDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">MultiClassClassificationDataset.__getitem__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.OnevsAllDataset"><code class="docutils literal notranslate"><span class="pre">OnevsAllDataset</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.OnevsAllDataset.__len__"><code class="docutils literal notranslate"><span class="pre">OnevsAllDataset.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.OnevsAllDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">OnevsAllDataset.__getitem__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.KvsAll"><code class="docutils literal notranslate"><span class="pre">KvsAll</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KvsAll.__len__"><code class="docutils literal notranslate"><span class="pre">KvsAll.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KvsAll.__getitem__"><code class="docutils literal notranslate"><span class="pre">KvsAll.__getitem__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.AllvsAll"><code class="docutils literal notranslate"><span class="pre">AllvsAll</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AllvsAll.__len__"><code class="docutils literal notranslate"><span class="pre">AllvsAll.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.AllvsAll.__getitem__"><code class="docutils literal notranslate"><span class="pre">AllvsAll.__getitem__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.KvsSampleDataset"><code class="docutils literal notranslate"><span class="pre">KvsSampleDataset</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KvsSampleDataset.__len__"><code class="docutils literal notranslate"><span class="pre">KvsSampleDataset.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.KvsSampleDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">KvsSampleDataset.__getitem__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.NegSampleDataset"><code class="docutils literal notranslate"><span class="pre">NegSampleDataset</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.NegSampleDataset.__len__"><code class="docutils literal notranslate"><span class="pre">NegSampleDataset.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.NegSampleDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">NegSampleDataset.__getitem__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.TriplePredictionDataset"><code class="docutils literal notranslate"><span class="pre">TriplePredictionDataset</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.TriplePredictionDataset.__len__"><code class="docutils literal notranslate"><span class="pre">TriplePredictionDataset.__len__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.TriplePredictionDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">TriplePredictionDataset.__getitem__()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.TriplePredictionDataset.collate_fn"><code class="docutils literal notranslate"><span class="pre">TriplePredictionDataset.collate_fn()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.CVDataModule"><code class="docutils literal notranslate"><span class="pre">CVDataModule</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CVDataModule.train_dataloader"><code class="docutils literal notranslate"><span class="pre">CVDataModule.train_dataloader()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CVDataModule.setup"><code class="docutils literal notranslate"><span class="pre">CVDataModule.setup()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CVDataModule.transfer_batch_to_device"><code class="docutils literal notranslate"><span class="pre">CVDataModule.transfer_batch_to_device()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.CVDataModule.prepare_data"><code class="docutils literal notranslate"><span class="pre">CVDataModule.prepare_data()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.QueryGenerator"><code class="docutils literal notranslate"><span class="pre">QueryGenerator</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.list2tuple"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.list2tuple()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.tuple2list"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.tuple2list()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.set_global_seed"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.set_global_seed()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.construct_graph"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.construct_graph()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.fill_query"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.fill_query()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.achieve_answer"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.achieve_answer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.write_links"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.write_links()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.ground_queries"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.ground_queries()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.unmap"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.unmap()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.unmap_query"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.unmap_query()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.generate_queries"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.generate_queries()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.save_queries"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.save_queries()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.load_queries"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.load_queries()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.get_queries"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.get_queries()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.save_queries_and_answers"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.save_queries_and_answers()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#dicee.QueryGenerator.load_queries_and_answers"><code class="docutils literal notranslate"><span class="pre">QueryGenerator.load_queries_and_answers()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#dicee.__version__"><code class="docutils literal notranslate"><span class="pre">__version__</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DICE Embeddings</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee</span></code></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/autoapi/dicee/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-dicee">
<span id="dicee"></span><h1><a class="reference internal" href="#module-dicee" title="dicee"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee</span></code></a><a class="headerlink" href="#module-dicee" title="Link to this heading"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Link to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="models/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="models/base_model/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.base_model</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/clifford/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.clifford</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/complex/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.complex</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/function_space/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.function_space</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/octonion/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.octonion</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/pykeen_models/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.pykeen_models</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/quaternion/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.quaternion</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/real/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.real</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.static_funcs</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="models/transformers/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.models.transformers</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="read_preprocess_save_load_kg/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.read_preprocess_save_load_kg</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="read_preprocess_save_load_kg/preprocess/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.read_preprocess_save_load_kg.preprocess</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="read_preprocess_save_load_kg/read_from_disk/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.read_preprocess_save_load_kg.read_from_disk</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="read_preprocess_save_load_kg/save_load_disk/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.read_preprocess_save_load_kg.save_load_disk</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="read_preprocess_save_load_kg/util/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.read_preprocess_save_load_kg.util</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="scripts/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.scripts</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="scripts/index/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.scripts.index</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="scripts/run/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.scripts.run</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="scripts/serve/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.scripts.serve</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="trainer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.trainer</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="trainer/dice_trainer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.trainer.dice_trainer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="trainer/torch_trainer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.trainer.torch_trainer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="trainer/torch_trainer_ddp/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.trainer.torch_trainer_ddp</span></code></a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="abstracts/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.abstracts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="analyse_experiments/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.analyse_experiments</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="callbacks/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.callbacks</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="config/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.config</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_classes/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.dataset_classes</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="eval_static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.eval_static_funcs</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.evaluator</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="executer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.executer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="knowledge_graph/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.knowledge_graph</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="knowledge_graph_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.knowledge_graph_embeddings</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="query_generator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.query_generator</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="sanity_checkers/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.sanity_checkers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_funcs</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="static_funcs_training/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_funcs_training</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="static_preprocess_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_preprocess_funcs</span></code></a></li>
</ul>
</div>
</section>
<section id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Link to this heading"></a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Link to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.CMult" title="dicee.CMult"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CMult</span></code></a></p></td>
<td><p>The CMult class represents a specific kind of mathematical object used in knowledge graph embeddings,</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.Pyke" title="dicee.Pyke"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Pyke</span></code></a></p></td>
<td><p>Pyke is a physical embedding model for knowledge graphs, emphasizing the geometric relationships</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.DistMult" title="dicee.DistMult"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DistMult</span></code></a></p></td>
<td><p>DistMult model for learning and inference in knowledge bases. It represents both entities</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.KeciBase" title="dicee.KeciBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KeciBase</span></code></a></p></td>
<td><p>Without learning dimension scaling</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.Keci" title="dicee.Keci"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Keci</span></code></a></p></td>
<td><p>The Keci class is a knowledge graph embedding model that incorporates Clifford algebra for embeddings.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.TransE" title="dicee.TransE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TransE</span></code></a></p></td>
<td><p>TransE model for learning embeddings in multi-relational data. It is based on the idea of translating</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.DeCaL" title="dicee.DeCaL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DeCaL</span></code></a></p></td>
<td><p>Base class for all neural network modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.ComplEx" title="dicee.ComplEx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplEx</span></code></a></p></td>
<td><p>ComplEx (Complex Embeddings for Knowledge Graphs) is a model that extends</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.AConEx" title="dicee.AConEx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AConEx</span></code></a></p></td>
<td><p>AConEx (Additive Convolutional ComplEx) extends the ConEx model by incorporating</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.AConvO" title="dicee.AConvO"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AConvO</span></code></a></p></td>
<td><p>Additive Convolutional Octonion(AConvO) extends the base knowledge graph embedding model by integrating additive convolutional</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.AConvQ" title="dicee.AConvQ"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AConvQ</span></code></a></p></td>
<td><p>Additive Convolutional Quaternion Knowledge Graph Embeddings (AConvQ) model integrates</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.ConvQ" title="dicee.ConvQ"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConvQ</span></code></a></p></td>
<td><p>Convolutional Quaternion Knowledge Graph Embeddings (ConvQ) is a model that extends</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.ConvO" title="dicee.ConvO"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConvO</span></code></a></p></td>
<td><p>ConvO extends the base knowledge graph embedding model by integrating convolutional</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.ConEx" title="dicee.ConEx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConEx</span></code></a></p></td>
<td><p>ConEx (Convolutional ComplEx) is a Knowledge Graph Embedding model that extends ComplEx embeddings with convolutional layers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.QMult" title="dicee.QMult"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QMult</span></code></a></p></td>
<td><p>QMult extends the base knowledge graph embedding model by integrating quaternion</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.OMult" title="dicee.OMult"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OMult</span></code></a></p></td>
<td><p>OMult extends the base knowledge graph embedding model by integrating octonion</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.Shallom" title="dicee.Shallom"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Shallom</span></code></a></p></td>
<td><p>Shallom is a shallow neural model designed for relation prediction in knowledge graphs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.LFMult" title="dicee.LFMult"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LFMult</span></code></a></p></td>
<td><p>Embedding with polynomial functions. We represent all entities and relations in the polynomial space as:</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.PykeenKGE" title="dicee.PykeenKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PykeenKGE</span></code></a></p></td>
<td><p>A class for using knowledge graph embedding models implemented in Pykeen.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.BytE" title="dicee.BytE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BytE</span></code></a></p></td>
<td><p>Base class for all neural network modules.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.BaseKGE" title="dicee.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseKGE</span></code></a></p></td>
<td><p>Base class for all neural network modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.DICE_Trainer" title="dicee.DICE_Trainer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DICE_Trainer</span></code></a></p></td>
<td><p>Implements a training framework for knowledge graph embedding models using [PyTorch Lightning](<a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html</a>),</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.KGE" title="dicee.KGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KGE</span></code></a></p></td>
<td><p>Knowledge Graph Embedding Class for interactive usage of pre-trained models</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.Execute" title="dicee.Execute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Execute</span></code></a></p></td>
<td><p>A class for Training, Retraining and Evaluation a model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.BPE_NegativeSamplingDataset" title="dicee.BPE_NegativeSamplingDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BPE_NegativeSamplingDataset</span></code></a></p></td>
<td><p>An abstract class representing a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.MultiLabelDataset" title="dicee.MultiLabelDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiLabelDataset</span></code></a></p></td>
<td><p>An abstract class representing a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.MultiClassClassificationDataset" title="dicee.MultiClassClassificationDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiClassClassificationDataset</span></code></a></p></td>
<td><p>Dataset for the 1vsALL training strategy</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.OnevsAllDataset" title="dicee.OnevsAllDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OnevsAllDataset</span></code></a></p></td>
<td><p>Dataset for the 1vsALL training strategy</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.KvsAll" title="dicee.KvsAll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KvsAll</span></code></a></p></td>
<td><p>Creates a dataset for KvsAll training by inheriting from torch.utils.data.Dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.AllvsAll" title="dicee.AllvsAll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AllvsAll</span></code></a></p></td>
<td><p>Creates a dataset for AllvsAll training by inheriting from torch.utils.data.Dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.KvsSampleDataset" title="dicee.KvsSampleDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KvsSampleDataset</span></code></a></p></td>
<td><p>KvsSample a Dataset:</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.NegSampleDataset" title="dicee.NegSampleDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NegSampleDataset</span></code></a></p></td>
<td><p>An abstract class representing a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.TriplePredictionDataset" title="dicee.TriplePredictionDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TriplePredictionDataset</span></code></a></p></td>
<td><p>Triple Dataset</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.CVDataModule" title="dicee.CVDataModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CVDataModule</span></code></a></p></td>
<td><p>Create a Dataset for cross validation</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.QueryGenerator" title="dicee.QueryGenerator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QueryGenerator</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Link to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.create_recipriocal_triples" title="dicee.create_recipriocal_triples"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_recipriocal_triples</span></code></a>(x)</p></td>
<td><p>Add inverse triples into dask dataframe</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.get_er_vocab" title="dicee.get_er_vocab"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_er_vocab</span></code></a>(data[,file_path])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.get_re_vocab" title="dicee.get_re_vocab"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_re_vocab</span></code></a>(data[,file_path])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.get_ee_vocab" title="dicee.get_ee_vocab"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_ee_vocab</span></code></a>(data[,file_path])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id89" title="dicee.timeit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">timeit</span></code></a>(func)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.save_pickle" title="dicee.save_pickle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_pickle</span></code></a>(*[,data,file_path])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id90" title="dicee.load_pickle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_pickle</span></code></a>([file_path])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.select_model" title="dicee.select_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">select_model</span></code></a>(args[,is_continual_training,storage_path])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.load_model" title="dicee.load_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_model</span></code></a>(Tuple[object,Tuple[dict,dict]])</p></td>
<td><p>Load weights and initialize pytorch module from namespace arguments</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.load_model_ensemble" title="dicee.load_model_ensemble"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_model_ensemble</span></code></a>(...)</p></td>
<td><p>Construct Ensemble Of weights and initialize pytorch module from namespace arguments</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.save_numpy_ndarray" title="dicee.save_numpy_ndarray"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_numpy_ndarray</span></code></a>(*,data,file_path)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.numpy_data_type_changer" title="dicee.numpy_data_type_changer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy_data_type_changer</span></code></a>(numpy.ndarray)</p></td>
<td><p>Detect most efficient data type for a given triples</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.save_checkpoint_model" title="dicee.save_checkpoint_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_checkpoint_model</span></code></a>(None)</p></td>
<td><p>Store Pytorch model into disk</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.store" title="dicee.store"><code class="xref py py-obj docutils literal notranslate"><span class="pre">store</span></code></a>(None)</p></td>
<td><p>Store trained_model model and save embeddings into csv file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.add_noisy_triples" title="dicee.add_noisy_triples"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_noisy_triples</span></code></a>(pandas.DataFrame)</p></td>
<td><p>Add randomly constructed triples</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.read_or_load_kg" title="dicee.read_or_load_kg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read_or_load_kg</span></code></a>(args,cls)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.intialize_model" title="dicee.intialize_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">intialize_model</span></code></a>(Tuple[object,str])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.load_json" title="dicee.load_json"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_json</span></code></a>(dict)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.save_embeddings" title="dicee.save_embeddings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_embeddings</span></code></a>(None)</p></td>
<td><p>Save it as CSV if memory allows.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.random_prediction" title="dicee.random_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">random_prediction</span></code></a>(pre_trained_kge)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.deploy_triple_prediction" title="dicee.deploy_triple_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">deploy_triple_prediction</span></code></a>(pre_trained_kge,str_subject,...)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.deploy_tail_entity_prediction" title="dicee.deploy_tail_entity_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">deploy_tail_entity_prediction</span></code></a>(pre_trained_kge,...)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.deploy_head_entity_prediction" title="dicee.deploy_head_entity_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">deploy_head_entity_prediction</span></code></a>(pre_trained_kge,...)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.deploy_relation_prediction" title="dicee.deploy_relation_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">deploy_relation_prediction</span></code></a>(pre_trained_kge,...)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.vocab_to_parquet" title="dicee.vocab_to_parquet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vocab_to_parquet</span></code></a>(vocab_to_idx,name,...)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.create_experiment_folder" title="dicee.create_experiment_folder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_experiment_folder</span></code></a>([folder_name])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.continual_training_setup_executor" title="dicee.continual_training_setup_executor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">continual_training_setup_executor</span></code></a>(None)</p></td>
<td><p>storage_path:str A path leading to a parent directory, where a subdirectory containing KGE related data</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.exponential_function" title="dicee.exponential_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">exponential_function</span></code></a>(torch.FloatTensor)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.load_numpy" title="dicee.load_numpy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_numpy</span></code></a>(numpy.ndarray)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.evaluate" title="dicee.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(entity_to_idx,scores,easy_answers,hard_answers)</p></td>
<td><p># &#64;TODO: CD: Renamed this function</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.download_file" title="dicee.download_file"><code class="xref py py-obj docutils literal notranslate"><span class="pre">download_file</span></code></a>(url[,destination_folder])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.download_files_from_url" title="dicee.download_files_from_url"><code class="xref py py-obj docutils literal notranslate"><span class="pre">download_files_from_url</span></code></a>(None)</p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">param base_url<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.download_pretrained_model" title="dicee.download_pretrained_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">download_pretrained_model</span></code></a>(str)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.mapping_from_first_two_cols_to_third" title="dicee.mapping_from_first_two_cols_to_third"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mapping_from_first_two_cols_to_third</span></code></a>(train_set_idx)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id89" title="dicee.timeit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">timeit</span></code></a>(func)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id90" title="dicee.load_pickle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_pickle</span></code></a>([file_path])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.reload_dataset" title="dicee.reload_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reload_dataset</span></code></a>(path,form_of_labelling,...)</p></td>
<td><p>Reload the files from disk to construct the Pytorch dataset</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.construct_dataset" title="dicee.construct_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">construct_dataset</span></code></a>(torch.utils.data.Dataset)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="attributes">
<h3>Attributes<a class="headerlink" href="#attributes" title="Link to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.__version__" title="dicee.__version__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__version__</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="dicee.CMult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">CMult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.CMult" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>The CMult class represents a specific kind of mathematical object used in knowledge graph embeddings,
involving Clifford algebra multiplication. It defines several algebraic structures based on the signature (p, q),
such as Real Numbers, Complex Numbers, Quaternions, and others. The class provides functionality for
performing Clifford multiplication, a generalization of the geometric product for vectors in a Clifford algebra.</p>
<p>TODO: Add mathematical format for sphinx.</p>
<p>Cl_(0,0) =&gt; Real Numbers</p>
<dl>
<dt>Cl_(0,1) =&gt;</dt><dd><p>A multivector mathbf{a} = a_0 + a_1 e_1
A multivector mathbf{b} = b_0 + b_1 e_1</p>
<p>multiplication is isomorphic to the product of two complex numbers</p>
<dl class="simple">
<dt>mathbf{a}      imes mathbf{b} = a_0 b_0 + a_0b_1 e1 + a_1 b_1 e_1 e_1</dt><dd><p>= (a_0 b_0 - a_1 b_1) + (a_0 b_1 + a_1 b_0) e_1</p>
</dd>
</dl>
</dd>
<dt>Cl_(2,0) =&gt;</dt><dd><p>A multivector mathbf{a} = a_0 + a_1 e_1 + a_2 e_2 + a_{12} e_1 e_2
A multivector mathbf{b} = b_0 + b_1 e_1 + b_2 e_2 + b_{12} e_1 e_2</p>
<dl class="simple">
<dt>mathbf{a}      imes mathbf{b} = a_0b_0 + a_0b_1 e_1 + a_0b_2e_2 + a_0 b_12 e_1 e_2</dt><dd><ul class="simple">
<li><p>a_1 b_0 e_1 + a_1b_1 e_1_e1 ..</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p>Cl_(0,2) =&gt; Quaternions</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.CMult.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.CMult.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the CMult class.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.CMult.entity_embeddings">
<span class="sig-name descname"><span class="pre">entity_embeddings</span></span><a class="headerlink" href="#dicee.CMult.entity_embeddings" title="Link to this definition"></a></dt>
<dd><p>Embedding layer for entities in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.CMult.relation_embeddings">
<span class="sig-name descname"><span class="pre">relation_embeddings</span></span><a class="headerlink" href="#dicee.CMult.relation_embeddings" title="Link to this definition"></a></dt>
<dd><p>Embedding layer for relations in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.CMult.p">
<span class="sig-name descname"><span class="pre">p</span></span><a class="headerlink" href="#dicee.CMult.p" title="Link to this definition"></a></dt>
<dd><p>Non-negative integer representing the number of positive square terms in the Clifford algebra.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.CMult.q">
<span class="sig-name descname"><span class="pre">q</span></span><a class="headerlink" href="#dicee.CMult.q" title="Link to this definition"></a></dt>
<dd><p>Non-negative integer representing the number of negative square terms in the Clifford algebra.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.CMult.clifford_mul">
<span class="sig-name descname"><span class="pre">clifford_mul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#dicee.CMult.clifford_mul" title="Link to this definition"></a></dt>
<dd><p>Performs Clifford multiplication based on the given signature (p, q).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.CMult.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.CMult.score" title="Link to this definition"></a></dt>
<dd><p>Computes a scoring function for a head entity, relation, and tail entity embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.CMult.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.CMult.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.CMult.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.CMult.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples against all entities in the knowledge graph.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">clifford_mul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><blockquote>
<div><p>Performs Clifford multiplication in the Clifford algebra Cl_{p,q}. This method generalizes the geometric product
of vectors in a Clifford algebra, handling different algebraic structures like real numbers, complex numbers,
quaternions, etc., based on the signature (p, q).</p>
<p>Clifford multiplication Cl_{p,q} (mathbb{R})</p>
<p>ei ^2 = +1     for i =&lt; i =&lt; p
ej ^2 = -1     for p &lt; j =&lt; p+q
ei ej = -eje1  for i</p>
</div></blockquote>
<p>eq j</p>
<blockquote>
<div><dl class="simple">
<dt>x<span class="classifier">torch.FloatTensor</span></dt><dd><p>The first multivector operand with shape (n, d).</p>
</dd>
<dt>y<span class="classifier">torch.FloatTensor</span></dt><dd><p>The second multivector operand with shape (n, d).</p>
</dd>
<dt>p<span class="classifier">int</span></dt><dd><p>A non-negative integer representing the number of positive square terms in the Clifford algebra.</p>
</dd>
<dt>q<span class="classifier">int</span></dt><dd><p>A non-negative integer representing the number of negative square terms in the Clifford algebra.</p>
</dd>
</dl>
<dl class="simple">
<dt>tuple</dt><dd><p>The result of Clifford multiplication, a tuple of tensors representing the components of the resulting multivector.</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id1" title="Link to this definition"></a></dt>
<dd><p>Computes a scoring function for a given triple of head entity, relation, and tail entity embeddings.
The method involves Clifford multiplication of the head entity and relation embeddings, followed by
a calculation of the score with the tail entity embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>head_ent_emb</strong> (<em>torch.FloatTensor</em>)  Embedding of the head entity.</p></li>
<li><p><strong>rel_ent_emb</strong> (<em>torch.FloatTensor</em>)  Embedding of the relation.</p></li>
<li><p><strong>tail_ent_emb</strong> (<em>torch.FloatTensor</em>)  Embedding of the tail entity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor representing the score of the given triple.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id2">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id2" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples. This method is typically used in training or evaluation
of knowledge graph embedding models. It applies Clifford multiplication to the embeddings of head
entities and relations and then calculates the score with respect to the tail entity embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.LongTensor</em>)  A tensor with shape (n, 3) representing a batch of triples, where each triple consists of indices
for a head entity, a relation, and a tail entity.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor with shape (n,) containing the scores for each triple in the batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id3" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples against all entities in the knowledge graph, often used in KvsAll evaluation.
This method retrieves embeddings for heads and relations, performs Clifford multiplication, and then computes the
inner product with all entity embeddings to get scores for every possible triple involving the given heads and relations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor with shape (n, 3) representing a batch of triples, where each triple consists of indices
for a head entity and a relation. The tail entity is to be compared against all possible entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor with shape (n,) containing scores for each triple against all possible tail entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.Pyke">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">Pyke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.Pyke" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>Pyke is a physical embedding model for knowledge graphs, emphasizing the geometric relationships
in the embedding space. The model aims to represent entities and relations in a way that captures
the underlying structure of the knowledge graph.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Pyke.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.Pyke.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the Pyke model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Pyke.dist_func">
<span class="sig-name descname"><span class="pre">dist_func</span></span><a class="headerlink" href="#dicee.Pyke.dist_func" title="Link to this definition"></a></dt>
<dd><p>A pairwise distance function to compute distances in the embedding space.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.PairwiseDistance</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Pyke.margin">
<span class="sig-name descname"><span class="pre">margin</span></span><a class="headerlink" href="#dicee.Pyke.margin" title="Link to this definition"></a></dt>
<dd><p>The margin value used in the scoring function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Pyke.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Pyke.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples based on the physical embedding approach.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id4">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id4" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples based on the physical embedding approach.</p>
<p>The method calculates the Euclidean distance between the head and relation embeddings,
and between the relation and tail embeddings. The average of these distances is subtracted
from the margin to compute the score for each triple.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.LongTensor</em>)  A tensor containing indices for head entities, relations, and tail entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for the given batch of triples. Lower scores indicate more likely triples
according to the geometric arrangement of embeddings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.DistMult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">DistMult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DistMult" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>DistMult model for learning and inference in knowledge bases. It represents both entities
and relations using embeddings and uses a simple bilinear form to compute scores for triples.</p>
<p>This implementation of the DistMult model is based on the paper:
Embedding Entities and Relations for Learning and Inference in Knowledge Bases
(<a class="reference external" href="https://arxiv.org/abs/1412.6575">https://arxiv.org/abs/1412.6575</a>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.DistMult.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.DistMult.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the DistMult model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DistMult.k_vs_all_score">
<span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_E</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.DistMult.k_vs_all_score" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using embeddings for a batch of head entities and relations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DistMult.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.DistMult.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities given a batch of head entities and relations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DistMult.forward_k_vs_sample">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.DistMult.forward_k_vs_sample" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a sampled subset of entities given a batch of head entities and relations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DistMult.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.DistMult.score" title="Link to this definition"></a></dt>
<dd><p>Computes the score of triples using DistMults scoring function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_E</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id5" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using embeddings for a batch of head entities and relations.</p>
<p>This method multiplies the head entity and relation embeddings, applies a dropout and a normalization,
and then computes the dot product with all tail entity embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>emb_h</strong> (<em>torch.FloatTensor</em>)  Embeddings of head entities.</p></li>
<li><p><strong>emb_r</strong> (<em>torch.FloatTensor</em>)  Embeddings of relations.</p></li>
<li><p><strong>emb_E</strong> (<em>torch.FloatTensor</em>)  Embeddings of all entities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all possible triples formed with the given head entities and relations against all entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id6">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id6" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities given a batch of head entities and relations.</p>
<p>This method is used for K-vs-All scoring, where the model predicts the likelihood of each entity
being the tail entity in a triple with each head entity and relation pair in the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.LongTensor</em>)  Tensor containing indices for head entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all entities for each head entity and relation pair in the batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id7" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a sampled subset of entities given a batch of head entities and relations.</p>
<p>This method is particularly useful when the full set of entities is too large to score
with every batch and only a subset of entities is required.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.LongTensor</em>)  Tensor containing indices for head entities and relations.</p></li>
<li><p><strong>target_entity_idx</strong> (<em>torch.LongTensor</em>)  Indices of the target entities against which the scores are to be computed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for each head entity and relation pair against the sampled subset of entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id8">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id8" title="Link to this definition"></a></dt>
<dd><p>Computes the score of triples using DistMults scoring function.</p>
<p>The scoring function multiplies head entity and relation embeddings, applies dropout and normalization,
and computes the dot product with the tail entity embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>torch.FloatTensor</em>)  Embedding of the head entity.</p></li>
<li><p><strong>r</strong> (<em>torch.FloatTensor</em>)  Embedding of the relation.</p></li>
<li><p><strong>t</strong> (<em>torch.FloatTensor</em>)  Embedding of the tail entity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The score of the triple.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.KeciBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">KeciBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KeciBase" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#dicee.Keci" title="dicee.Keci"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Keci</span></code></a></p>
<p>Without learning dimension scaling</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.Keci">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">Keci</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.Keci" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>The Keci class is a knowledge graph embedding model that incorporates Clifford algebra for embeddings.
It supports different dimensions of Clifford algebra by setting the parameters p and q. The class
utilizes Clifford multiplication for embedding interactions and computes scores for knowledge graph triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Keci.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.Keci.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the Keci class.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Keci.p">
<span class="sig-name descname"><span class="pre">p</span></span><a class="headerlink" href="#dicee.Keci.p" title="Link to this definition"></a></dt>
<dd><p>The parameter p in Clifford algebra, representing the number of positive square terms.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Keci.q">
<span class="sig-name descname"><span class="pre">q</span></span><a class="headerlink" href="#dicee.Keci.q" title="Link to this definition"></a></dt>
<dd><p>The parameter q in Clifford algebra, representing the number of negative square terms.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Keci.r">
<span class="sig-name descname"><span class="pre">r</span></span><a class="headerlink" href="#dicee.Keci.r" title="Link to this definition"></a></dt>
<dd><p>A derived attribute for dimension scaling based on p and q.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Keci.p_coefficients">
<span class="sig-name descname"><span class="pre">p_coefficients</span></span><a class="headerlink" href="#dicee.Keci.p_coefficients" title="Link to this definition"></a></dt>
<dd><p>Embedding for scaling coefficients of p terms, if p &gt; 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding (optional)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Keci.q_coefficients">
<span class="sig-name descname"><span class="pre">q_coefficients</span></span><a class="headerlink" href="#dicee.Keci.q_coefficients" title="Link to this definition"></a></dt>
<dd><p>Embedding for scaling coefficients of q terms, if q &gt; 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding (optional)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.compute_sigma_pp">
<span class="sig-name descname"><span class="pre">compute_sigma_pp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.Keci.compute_sigma_pp" title="Link to this definition"></a></dt>
<dd><p>Computes the sigma_pp component in Clifford multiplication.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.compute_sigma_qq">
<span class="sig-name descname"><span class="pre">compute_sigma_qq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.Keci.compute_sigma_qq" title="Link to this definition"></a></dt>
<dd><p>Computes the sigma_qq component in Clifford multiplication.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.compute_sigma_pq">
<span class="sig-name descname"><span class="pre">compute_sigma_pq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.Keci.compute_sigma_pq" title="Link to this definition"></a></dt>
<dd><p>Computes the sigma_pq component in Clifford multiplication.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.apply_coefficients">
<span class="sig-name descname"><span class="pre">apply_coefficients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#dicee.Keci.apply_coefficients" title="Link to this definition"></a></dt>
<dd><p>Applies scaling coefficients to the base vectors in Clifford algebra.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.clifford_multiplication">
<span class="sig-name descname"><span class="pre">clifford_multiplication</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#dicee.Keci.clifford_multiplication" title="Link to this definition"></a></dt>
<dd><p>Performs Clifford multiplication of head and relation embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.construct_cl_multivector">
<span class="sig-name descname"><span class="pre">construct_cl_multivector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#dicee.Keci.construct_cl_multivector" title="Link to this definition"></a></dt>
<dd><p>Constructs a multivector in Clifford algebra Cl_{p,q}(mathbb{R}^d).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.forward_k_vs_with_explicit">
<span class="sig-name descname"><span class="pre">forward_k_vs_with_explicit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Keci.forward_k_vs_with_explicit" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples against all entities using explicit Clifford multiplication.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.k_vs_all_score">
<span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bpe_head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bpe_rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Keci.k_vs_all_score" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all triples using Clifford multiplication in a K-vs-All setup.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Keci.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Wrapper function for K-vs-All scoring.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.forward_k_vs_sample">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Keci.forward_k_vs_sample" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a sampled subset of entities.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Keci.score" title="Link to this definition"></a></dt>
<dd><p>Computes the score for a given triple using Clifford multiplication.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Keci.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Keci.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>The class is designed to work with embeddings in the context of knowledge graph completion tasks,
leveraging the properties of Clifford algebra for embedding interactions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="id9">
<span class="sig-name descname"><span class="pre">compute_sigma_pp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id9" title="Link to this definition"></a></dt>
<dd><p>Computes the sigma_pp component in Clifford multiplication, representing the interactions
between the positive square terms in the Clifford algebra.</p>
<p>sigma_{pp} = sum_{i=1}^{p-1} sum_{k=i+1}^p (h_i r_k - h_k r_i) e_i e_k, TODO: Add mathematical format for sphinx.</p>
<p>sigma_{pp} captures the interactions between along p bases
For instance, let p e_1, e_2, e_3, we compute interactions between e_1 e_2, e_1 e_3 , and e_2 e_3
This can be implemented with a nested two for loops</p>
<blockquote>
<div><p>results = []
for i in range(p - 1):</p>
<blockquote>
<div><dl class="simple">
<dt>for k in range(i + 1, p):</dt><dd><p>results.append(hp[:, :, i] * rp[:, :, k] - hp[:, :, k] * rp[:, :, i])</p>
</dd>
</dl>
</div></blockquote>
<p>sigma_pp = torch.stack(results, dim=2)
assert sigma_pp.shape == (b, r, int((p * (p - 1)) / 2))</p>
</div></blockquote>
<p>Yet, this computation would be quite inefficient. Instead, we compute interactions along all p,
e.g., e1e1, e1e2, e1e3,</p>
<blockquote>
<div><p>e2e1, e2e2, e2e3,
e3e1, e3e2, e3e3</p>
</div></blockquote>
<p>Then select the triangular matrix without diagonals: e1e2, e1e3, e2e3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hp</strong> (<em>torch.Tensor</em>)  The p part of the head entity embedding in Clifford algebra.</p></li>
<li><p><strong>rp</strong> (<em>torch.Tensor</em>)  The p part of the relation embedding in Clifford algebra.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>sigma_pp</strong>  The sigma_pp component of the Clifford multiplication.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id10">
<span class="sig-name descname"><span class="pre">compute_sigma_qq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id10" title="Link to this definition"></a></dt>
<dd><p>Computes the sigma_qq component in Clifford multiplication, representing the interactions
between the negative square terms in the Clifford algebra.</p>
<p>TODO: Add mathematical format for sphinx.</p>
<p>sigma_{qq} = sum_{j=1}^{p+q-1} sum_{k=j+1}^{p+q} (h_j r_k - h_k r_j) e_j e_k
sigma_{q} captures the interactions between along q bases
For instance, let q e_1, e_2, e_3, we compute interactions between e_1 e_2, e_1 e_3 , and e_2 e_3
This can be implemented with a nested two for loops</p>
<blockquote>
<div><p>results = []
for j in range(q - 1):</p>
<blockquote>
<div><dl class="simple">
<dt>for k in range(j + 1, q):</dt><dd><p>results.append(hq[:, :, j] * rq[:, :, k] - hq[:, :, k] * rq[:, :, j])</p>
</dd>
</dl>
</div></blockquote>
<p>sigma_qq = torch.stack(results, dim=2)
assert sigma_qq.shape == (b, r, int((q * (q - 1)) / 2))</p>
</div></blockquote>
<p>Yet, this computation would be quite inefficient. Instead, we compute interactions along all p,
e.g., e1e1, e1e2, e1e3,</p>
<blockquote>
<div><p>e2e1, e2e2, e2e3,
e3e1, e3e2, e3e3</p>
</div></blockquote>
<p>Then select the triangular matrix without diagonals: e1e2, e1e3, e2e3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hq</strong> (<em>torch.Tensor</em>)  The q part of the head entity embedding in Clifford algebra.</p></li>
<li><p><strong>rq</strong> (<em>torch.Tensor</em>)  The q part of the relation embedding in Clifford algebra.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>sigma_qq</strong>  The sigma_qq component of the Clifford multiplication.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id11">
<span class="sig-name descname"><span class="pre">compute_sigma_pq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id11" title="Link to this definition"></a></dt>
<dd><p>Computes the sigma_pq component in Clifford multiplication, representing the interactions
between the positive and negative square terms in the Clifford algebra.</p>
<p>TODO: Add mathematical format for sphinx.</p>
<p>sum_{i=1}^{p} sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j</p>
<p># results = []
# sigma_pq = torch.zeros(b, r, p, q)
# for i in range(p):
#     for j in range(q):
#         sigma_pq[:, :, i, j] = hp[:, :, i] * rq[:, :, j] - hq[:, :, j] * rp[:, :, i]
# print(sigma_pq.shape)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hp</strong> (<em>torch.Tensor</em>)  The p part of the head entity embedding in Clifford algebra.</p></li>
<li><p><strong>hq</strong> (<em>torch.Tensor</em>)  The q part of the head entity embedding in Clifford algebra.</p></li>
<li><p><strong>rp</strong> (<em>torch.Tensor</em>)  The p part of the relation embedding in Clifford algebra.</p></li>
<li><p><strong>rq</strong> (<em>torch.Tensor</em>)  The q part of the relation embedding in Clifford algebra.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>sigma_pq</strong>  The sigma_pq component of the Clifford multiplication.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id12">
<span class="sig-name descname"><span class="pre">apply_coefficients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id12" title="Link to this definition"></a></dt>
<dd><p>Applies scaling coefficients to the base vectors in the Clifford algebra.
This method is used for adjusting the contributions of different components in the algebra.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h0</strong> (<em>torch.Tensor</em>)  The scalar part of the head entity embedding.</p></li>
<li><p><strong>hp</strong> (<em>torch.Tensor</em>)  The p part of the head entity embedding.</p></li>
<li><p><strong>hq</strong> (<em>torch.Tensor</em>)  The q part of the head entity embedding.</p></li>
<li><p><strong>r0</strong> (<em>torch.Tensor</em>)  The scalar part of the relation embedding.</p></li>
<li><p><strong>rp</strong> (<em>torch.Tensor</em>)  The p part of the relation embedding.</p></li>
<li><p><strong>rq</strong> (<em>torch.Tensor</em>)  The q part of the relation embedding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing the scaled components of the head and relation embeddings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id13">
<span class="sig-name descname"><span class="pre">clifford_multiplication</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id13" title="Link to this definition"></a></dt>
<dd><blockquote>
<div><p>Performs Clifford multiplication of head and relation embeddings. This method computes the
various components of the Clifford product, combining the scalar, p, and q parts of the embeddings.</p>
<p>TODO: Add mathematical format for sphinx.</p>
<p>h = h_0 + sum_{i=1}^p h_i e_i + sum_{j=p+1}^{p+q} h_j e_j
r = r_0 + sum_{i=1}^p r_i e_i + sum_{j=p+1}^{p+q} r_j e_j</p>
<p>ei ^2 = +1     for i =&lt; i =&lt; p
ej ^2 = -1     for p &lt; j =&lt; p+q
ei ej = -eje1  for i</p>
</div></blockquote>
<p>eq j</p>
<blockquote>
<div><p>h r =   sigma_0 + sigma_p + sigma_q + sigma_{pp} + sigma_{q}+ sigma_{pq}
where</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>sigma_0 = h_0 r_0 + sum_{i=1}^p (h_0 r_i) e_i - sum_{j=p+1}^{p+q} (h_j r_j) e_j</p></li>
<li><p>sigma_p = sum_{i=1}^p (h_0 r_i + h_i r_0) e_i</p></li>
<li><p>sigma_q = sum_{j=p+1}^{p+q} (h_0 r_j + h_j r_0) e_j</p></li>
<li><p>sigma_{pp} = sum_{i=1}^{p-1} sum_{k=i+1}^p (h_i r_k - h_k r_i) e_i e_k</p></li>
<li><p>sigma_{qq} = sum_{j=1}^{p+q-1} sum_{k=j+1}^{p+q} (h_j r_k - h_k r_j) e_j e_k</p></li>
<li><p>sigma_{pq} = sum_{i=1}^{p} sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j</p></li>
</ol>
</div></blockquote>
<dl class="simple">
<dt>h0<span class="classifier">torch.Tensor</span></dt><dd><p>The scalar part of the head entity embedding.</p>
</dd>
<dt>hp<span class="classifier">torch.Tensor</span></dt><dd><p>The p part of the head entity embedding.</p>
</dd>
<dt>hq<span class="classifier">torch.Tensor</span></dt><dd><p>The q part of the head entity embedding.</p>
</dd>
<dt>r0<span class="classifier">torch.Tensor</span></dt><dd><p>The scalar part of the relation embedding.</p>
</dd>
<dt>rp<span class="classifier">torch.Tensor</span></dt><dd><p>The p part of the relation embedding.</p>
</dd>
<dt>rq<span class="classifier">torch.Tensor</span></dt><dd><p>The q part of the relation embedding.</p>
</dd>
</dl>
<dl class="simple">
<dt>tuple</dt><dd><p>Tuple containing the components of the Clifford product.</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id14">
<span class="sig-name descname"><span class="pre">construct_cl_multivector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id14" title="Link to this definition"></a></dt>
<dd><p>Construct a batch of multivectors Cl_{p,q}(mathbb{R}^d)</p>
<section id="parameter">
<h4>Parameter<a class="headerlink" href="#parameter" title="Link to this heading"></a></h4>
<dl class="simple">
<dt>x<span class="classifier">torch.FloatTensor</span></dt><dd><p>The embedding vector with shape (n, d).</p>
</dd>
<dt>r<span class="classifier">int</span></dt><dd><p>The dimension of the scalar part.</p>
</dd>
<dt>p<span class="classifier">int</span></dt><dd><p>The number of positive square terms.</p>
</dd>
<dt>q<span class="classifier">int</span></dt><dd><p>The number of negative square terms.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a0</strong> (<em>torch.FloatTensor</em>)  Tensor with (n,r) shape</p></li>
<li><p><strong>ap</strong> (<em>torch.FloatTensor</em>)  Tensor with (n,r,p) shape</p></li>
<li><p><strong>aq</strong> (<em>torch.FloatTensor</em>)  Tensor with (n,r,q) shape</p></li>
</ul>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id15">
<span class="sig-name descname"><span class="pre">forward_k_vs_with_explicit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id15" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples against all entities using explicit Clifford multiplication.
This method is used for K-vs-All training and evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  Tensor representing a batch of head entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing scores for each triple against all entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id16">
<span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bpe_head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bpe_rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id16" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all triples using Clifford multiplication in a K-vs-All setup. This method involves constructing
multivectors for head entities and relations in Clifford algebra, applying coefficients, and computing interaction
scores based on different components of the Clifford algebra.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bpe_head_ent_emb</strong> (<em>torch.Tensor</em>)  Batch of head entity embeddings in BPE (Byte Pair Encoding) format. Tensor shape: (batch_size, embedding_dim).</p></li>
<li><p><strong>bpe_rel_ent_emb</strong> (<em>torch.Tensor</em>)  Batch of relation embeddings in BPE format. Tensor shape: (batch_size, embedding_dim).</p></li>
<li><p><strong>E</strong> (<em>torch.Tensor</em>)  Tensor containing all entity embeddings. Tensor shape: (num_entities, embedding_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor containing the scores for each triple in the K-vs-All setting. Tensor shape: (batch_size, num_entities).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method computes scores based on the basis of 1 (scalar part), the bases of p (positive square terms),
and the bases of q (negative square terms). Additional computations involve sigma_pp, sigma_qq, and sigma_pq
components in Clifford multiplication, corresponding to different interaction terms.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id17">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id17" title="Link to this definition"></a></dt>
<dd><p>TODO: Add mathematical format for sphinx.
Performs the forward pass for K-vs-All training and evaluation in knowledge graph embeddings.
This method involves retrieving real-valued embedding vectors for head entities and relations mathbb{R}^d,
constructing Clifford algebra multivectors for these embeddings according to Cl_{p,q}(mathbb{R}^d), performing Clifford multiplication,
and computing the inner product with all entity embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of head entities and relations for the K-vs-All evaluation.
Expected tensor shape: (n, 2), where n is the batch size and 2 represents head entity
and relation pairs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each head entity and relation pair against all possible
tail entities in the knowledge graph. Tensor shape: (n, <a href="#id93"><span class="problematic" id="id94">|E|</span></a>), where <a href="#id95"><span class="problematic" id="id96">|E|</span></a> is the number
of entities in the knowledge graph.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This method is similar to the forward_k_vs_with_explicit function in functionality. It is
typically used in scenarios where every possible combination of a head entity and a relation
is scored against all tail entities, commonly used in knowledge graph completion tasks.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id18">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id18" title="Link to this definition"></a></dt>
<dd><p>TODO: Add mathematical format for sphinx.</p>
<p>Performs the forward pass for K-vs-Sample training in knowledge graph embeddings. This method involves
retrieving real-valued embedding vectors for head entities and relations mathbb{R}^d, constructing Clifford algebra
multivectors for these embeddings according to Cl_{p,q}(mathbb{R}^d), performing Clifford multiplication,
and computing the inner product with a sampled subset of entity embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.LongTensor</em>)  A tensor representing a batch of head entities and relations for the K-vs-Sample evaluation.
Expected tensor shape: (n, 2), where n is the batch size and 2 represents head entity
and relation pairs.</p></li>
<li><p><strong>target_entity_idx</strong> (<em>torch.LongTensor</em>)  A tensor of target entity indices for sampling in the K-vs-Sample evaluation.
Tensor shape: (n, sample_size), where sample_size is the number of entities sampled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each head entity and relation pair against the sampled
subset of tail entities. Tensor shape: (n, sample_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This method is used in scenarios where every possible combination of a head entity and a relation
is scored against a sampled subset of tail entities, commonly used in knowledge graph completion tasks
with a large number of entities.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id19">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id19" title="Link to this definition"></a></dt>
<dd><p>Computes the score for a given triple using Clifford multiplication in the context of knowledge graph embeddings.
This method involves constructing Clifford algebra multivectors for head entities, relations, and tail entities,
applying coefficients, and computing interaction scores based on different components of the Clifford algebra.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>torch.Tensor</em>)  Tensor representing the embeddings of head entities. Expected shape: (n, d), where n is the number of triples
and d is the embedding dimension.</p></li>
<li><p><strong>r</strong> (<em>torch.Tensor</em>)  Tensor representing the embeddings of relations. Expected shape: (n, d).</p></li>
<li><p><strong>t</strong> (<em>torch.Tensor</em>)  Tensor representing the embeddings of tail entities. Expected shape: (n, d).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor containing the scores for each triple. Tensor shape: (n,).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method computes scores based on the scalar part, the bases of p (positive square terms),
and the bases of q (negative square terms) in Clifford algebra. It includes additional computations
involving sigma_pp, sigma_qq, and sigma_pq components, which correspond to different interaction terms
in the Clifford product.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id20">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id20" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using Clifford multiplication.
This method is involved in the forward pass of the model during training or evaluation.
It retrieves embeddings for head entities, relations, and tail entities, constructs Clifford algebra multivectors,
applies coefficients, and computes interaction scores based on different components of Clifford algebra.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of triples. Each triple consists of indices for a head entity, a relation, and a tail entity.
Expected tensor shape: (n, 3), where n is the number of triples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each triple in the batch. Tensor shape: (n,), where n is the number of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method computes scores based on the scalar part, the bases of p (positive square terms), and the bases of q (negative square terms) in Clifford algebra.
It includes additional computations involving sigma_pp, sigma_qq, and sigma_pq components, corresponding to different interaction terms in the Clifford product.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.TransE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">TransE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.TransE" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>TransE model for learning embeddings in multi-relational data. It is based on the idea of translating
embeddings for head entities by the relation vector to approach the tail entity embeddings in the embedding space.</p>
<p>This implementation of TransE is based on the paper:
Translating Embeddings for Modeling Multi-relational Data
(<a class="reference external" href="https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf">https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf</a>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.TransE.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.TransE.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the TransE model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.TransE._norm">
<span class="sig-name descname"><span class="pre">_norm</span></span><a class="headerlink" href="#dicee.TransE._norm" title="Link to this definition"></a></dt>
<dd><p>The norm used for computing pairwise distances in the embedding space.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.TransE.margin">
<span class="sig-name descname"><span class="pre">margin</span></span><a class="headerlink" href="#dicee.TransE.margin" title="Link to this definition"></a></dt>
<dd><p>The margin value used in the scoring function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.TransE.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.TransE.score" title="Link to this definition"></a></dt>
<dd><p>Computes the score of triples using the TransE scoring function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.TransE.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.TransE.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities given a head entity and a relation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id21">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id21" title="Link to this definition"></a></dt>
<dd><p>Computes the score of triples using the TransE scoring function.</p>
<p>The scoring function computes the L2 distance between the translated head entity
and the tail entity embeddings and subtracts this distance from the margin.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>head_ent_emb</strong> (<em>torch.Tensor</em>)  Embedding of the head entity.</p></li>
<li><p><strong>rel_ent_emb</strong> (<em>torch.Tensor</em>)  Embedding of the relation.</p></li>
<li><p><strong>tail_ent_emb</strong> (<em>torch.Tensor</em>)  Embedding of the tail entity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The score of the triple.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id22">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id22" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities given a head entity and a relation.</p>
<p>This method is used for K-vs-All scoring, where the model predicts the likelihood of each entity
being the tail entity in a triple with each head entity and relation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  Tensor containing indices for head entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all entities for each head entity and relation pair.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.DeCaL">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">DeCaL</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code class="xref py py-meth docutils literal notranslate"><span class="pre">to()</span></code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> call to the parent class
must be made before assignment on the child.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>training</strong> (<em>bool</em>)  Boolean represents whether this module is in training or
evaluation mode.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.DeCaL.forward_triples" title="Link to this definition"></a></dt>
<dd><section id="id23">
<h4>Parameter<a class="headerlink" href="#id23" title="Link to this heading"></a></h4>
<p>x: torch.LongTensor with (n,3) shape</p>
<dl class="field-list simple">
<dt class="field-odd">rtype<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor with (n) shape</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.cl_pqr">
<span class="sig-name descname"><span class="pre">cl_pqr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.cl_pqr" title="Link to this definition"></a></dt>
<dd><p>Input: tensor(batch_size, emb_dim) -&gt; output: tensor with 1+p+q+r components with size (batch_size, emb_dim/(1+p+q+r)) each.</p>
<p>1) takes a tensor of size (batch_size, emb_dim), split it into 1 + p + q +r components, hence 1+p+q+r must be a divisor
of the emb_dim.
2) Return a list of the 1+p+q+r components vectors, each are tensors of size (batch_size, emb_dim/(1+p+q+r))</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.compute_sigmas_single">
<span class="sig-name descname"><span class="pre">compute_sigmas_single</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_h_emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_r_emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_t_emb</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.compute_sigmas_single" title="Link to this definition"></a></dt>
<dd><p>here we compute all the sums with no others vectors interaction taken with the scalar product with t, that is,
1) s0 = h_0r_0t_0
2) s1 = sum_{i=1}^{p}h_ir_it_0
3) s2 = sum_{j=p+1}^{p+q}h_jr_jt_0
4) s3 = sum_{i=1}^{q}(h_0r_it_i + h_ir_0t_i)
5) s4 = sum_{i=p+1}^{p+q}(h_0r_it_i + h_ir_0t_i)
5) s5 = sum_{i=p+q+1}^{p+q+r}(h_0r_it_i + h_ir_0t_i)</p>
<p>and return:</p>
<p><a href="#id24"><span class="problematic" id="id25">*</span></a>) sigma_0t = sigma_0 cdot t_0 = s0 + s1 -s2
<a href="#id26"><span class="problematic" id="id27">*</span></a>) s3, s4 and s5</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.compute_sigmas_multivect">
<span class="sig-name descname"><span class="pre">compute_sigmas_multivect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_h_emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_r_emb</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.compute_sigmas_multivect" title="Link to this definition"></a></dt>
<dd><p>Here we compute and return all the sums with vectors interaction for the same and different bases.</p>
<p>For same bases vectors interaction we have</p>
<ol class="arabic simple">
<li><p>sigma_pp = sum_{i=1}^{p-1}sum_{i=i+1}^{p}(h_ir_{i}-h_{i}r_i) (models the interactions between e_i and e_i for 1 &lt;= i, i &lt;= p)</p></li>
<li><p>sigma_qq = sum_{j=p+1}^{p+q-1}sum_{j=j+1}^{p+q}(h_jr_{j}-h_{j} (models the interactions between e_j and e_j for p+1 &lt;= j, j &lt;= p+q)</p></li>
<li><p>sigma_rr = sum_{k=p+q+1}^{p+q+r-1}sum_{k=k+1}^{p}(h_kr_{k}-h_{k}r_k) (models the interactions between e_k and e_k for p+q+1 &lt;= k, k &lt;= p+q+r)</p></li>
</ol>
<p>For different base vector interactions, we have</p>
<ol class="arabic simple" start="4">
<li><p>sigma_pq = sum_{i=1}^{p}sum_{j=p+1}^{p+q}(h_ir_j - h_jr_i) (interactionsn between e_i and e_j for 1&lt;=i &lt;=p and p+1&lt;= j &lt;= p+q)</p></li>
<li><p>sigma_pr = sum_{i=1}^{p}sum_{k=p+q+1}^{p+q+r}(h_ir_k - h_kr_i) (interactionsn between e_i and e_k for 1&lt;=i &lt;=p and p+q+1&lt;= k &lt;= p+q+r)</p></li>
<li><p>sigma_qr = sum_{j=p+1}^{p+q}sum_{j=p+q+1}^{p+q+r}(h_jr_k - h_kr_j) (interactionsn between e_j and e_k for p+1 &lt;= j &lt;=p+q and p+q+1&lt;= j &lt;= p+q+r)</p></li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.DeCaL.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Kvsall training</p>
<ol class="arabic simple">
<li><p>Retrieve real-valued embedding vectors for heads and relations mathbb{R}^d .</p></li>
<li><p>Construct head entity and relation embeddings according to Cl_{p,q}(mathbb{R}^d) .</p></li>
<li><p>Perform Cl multiplication</p></li>
<li><p>Inner product of (3) and all entity embeddings</p></li>
</ol>
<p>forward_k_vs_with_explicit and this funcitons are identical
Parameter

x: torch.LongTensor with (n,2) shape
:rtype: torch.FloatTensor with (n, <a href="#id97"><span class="problematic" id="id98">|E|</span></a>) shape</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.apply_coefficients">
<span class="sig-name descname"><span class="pre">apply_coefficients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rk</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.apply_coefficients" title="Link to this definition"></a></dt>
<dd><p>Multiplying a base vector with its scalar coefficient</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.construct_cl_multivector">
<span class="sig-name descname"><span class="pre">construct_cl_multivector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">re</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.DeCaL.construct_cl_multivector" title="Link to this definition"></a></dt>
<dd><p>Construct a batch of multivectors Cl_{p,q,r}(mathbb{R}^d)</p>
<section id="id28">
<h4>Parameter<a class="headerlink" href="#id28" title="Link to this heading"></a></h4>
<p>x: torch.FloatTensor with (n,d) shape</p>
<dl class="field-list simple">
<dt class="field-odd">returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a0</strong> (<em>torch.FloatTensor</em>)</p></li>
<li><p><strong>ap</strong> (<em>torch.FloatTensor</em>)</p></li>
<li><p><strong>aq</strong> (<em>torch.FloatTensor</em>)</p></li>
<li><p><strong>ar</strong> (<em>torch.FloatTensor</em>)</p></li>
</ul>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.compute_sigma_pp">
<span class="sig-name descname"><span class="pre">compute_sigma_pp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.compute_sigma_pp" title="Link to this definition"></a></dt>
<dd><p>sigma_{p,p}^* = sum_{i=1}^{p-1}sum_{i=i+1}^{p}(x_iy_{i}-x_{i}y_i)</p>
<p>sigma_{pp} captures the interactions between along p bases
For instance, let p e_1, e_2, e_3, we compute interactions between e_1 e_2, e_1 e_3 , and e_2 e_3
This can be implemented with a nested two for loops</p>
<blockquote>
<div><p>results = []
for i in range(p - 1):</p>
<blockquote>
<div><dl class="simple">
<dt>for k in range(i + 1, p):</dt><dd><p>results.append(hp[:, :, i] * rp[:, :, k] - hp[:, :, k] * rp[:, :, i])</p>
</dd>
</dl>
</div></blockquote>
<p>sigma_pp = torch.stack(results, dim=2)
assert sigma_pp.shape == (b, r, int((p * (p - 1)) / 2))</p>
</div></blockquote>
<p>Yet, this computation would be quite inefficient. Instead, we compute interactions along all p,
e.g., e1e1, e1e2, e1e3,</p>
<blockquote>
<div><p>e2e1, e2e2, e2e3,
e3e1, e3e2, e3e3</p>
</div></blockquote>
<p>Then select the triangular matrix without diagonals: e1e2, e1e3, e2e3.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.compute_sigma_qq">
<span class="sig-name descname"><span class="pre">compute_sigma_qq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.compute_sigma_qq" title="Link to this definition"></a></dt>
<dd><p>Compute  sigma_{q,q}^* = sum_{j=p+1}^{p+q-1}sum_{j=j+1}^{p+q}(x_jy_{j}-x_{j}y_j) Eq. 16
sigma_{q} captures the interactions between along q bases
For instance, let q e_1, e_2, e_3, we compute interactions between e_1 e_2, e_1 e_3 , and e_2 e_3
This can be implemented with a nested two for loops</p>
<blockquote>
<div><p>results = []
for j in range(q - 1):</p>
<blockquote>
<div><dl class="simple">
<dt>for k in range(j + 1, q):</dt><dd><p>results.append(hq[:, :, j] * rq[:, :, k] - hq[:, :, k] * rq[:, :, j])</p>
</dd>
</dl>
</div></blockquote>
<p>sigma_qq = torch.stack(results, dim=2)
assert sigma_qq.shape == (b, r, int((q * (q - 1)) / 2))</p>
</div></blockquote>
<p>Yet, this computation would be quite inefficient. Instead, we compute interactions along all p,
e.g., e1e1, e1e2, e1e3,</p>
<blockquote>
<div><p>e2e1, e2e2, e2e3,
e3e1, e3e2, e3e3</p>
</div></blockquote>
<p>Then select the triangular matrix without diagonals: e1e2, e1e3, e2e3.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.compute_sigma_rr">
<span class="sig-name descname"><span class="pre">compute_sigma_rr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rk</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.compute_sigma_rr" title="Link to this definition"></a></dt>
<dd><p>sigma_{r,r}^* = sum_{k=p+q+1}^{p+q+r-1}sum_{k=k+1}^{p}(x_ky_{k}-x_{k}y_k)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.compute_sigma_pq">
<span class="sig-name descname"><span class="pre">compute_sigma_pq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.compute_sigma_pq" title="Link to this definition"></a></dt>
<dd><p>sum_{i=1}^{p} sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j</p>
<p>results = []
sigma_pq = torch.zeros(b, r, p, q)
for i in range(p):</p>
<blockquote>
<div><dl class="simple">
<dt>for j in range(q):</dt><dd><p>sigma_pq[:, :, i, j] = hp[:, :, i] * rq[:, :, j] - hq[:, :, j] * rp[:, :, i]</p>
</dd>
</dl>
</div></blockquote>
<p>print(sigma_pq.shape)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.compute_sigma_pr">
<span class="sig-name descname"><span class="pre">compute_sigma_pr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rk</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.compute_sigma_pr" title="Link to this definition"></a></dt>
<dd><p>sum_{i=1}^{p} sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j</p>
<p>results = []
sigma_pq = torch.zeros(b, r, p, q)
for i in range(p):</p>
<blockquote>
<div><dl class="simple">
<dt>for j in range(q):</dt><dd><p>sigma_pq[:, :, i, j] = hp[:, :, i] * rq[:, :, j] - hq[:, :, j] * rp[:, :, i]</p>
</dd>
</dl>
</div></blockquote>
<p>print(sigma_pq.shape)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DeCaL.compute_sigma_qr">
<span class="sig-name descname"><span class="pre">compute_sigma_qr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rk</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DeCaL.compute_sigma_qr" title="Link to this definition"></a></dt>
<dd><p>sum_{i=1}^{p} sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j</p>
<p>results = []
sigma_pq = torch.zeros(b, r, p, q)
for i in range(p):</p>
<blockquote>
<div><dl class="simple">
<dt>for j in range(q):</dt><dd><p>sigma_pq[:, :, i, j] = hp[:, :, i] * rq[:, :, j] - hq[:, :, j] * rp[:, :, i]</p>
</dd>
</dl>
</div></blockquote>
<p>print(sigma_pq.shape)</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.ComplEx">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">ComplEx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.ComplEx" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>ComplEx (Complex Embeddings for Knowledge Graphs) is a model that extends
the base knowledge graph embedding approach by using complex-valued embeddings.
It emphasizes the interaction of real and imaginary components of embeddings
to capture the asymmetric relationships often found in knowledge graphs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model,
such as embedding dimensions, learning rate, and regularization methods.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ComplEx.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.ComplEx.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the ComplEx model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">score(head_ent_emb:</span> <span class="pre">torch.FloatTensor,</span> <span class="pre">rel_ent_emb:</span> <span class="pre">torch.FloatTensor,</span></span></dt>
<dd><blockquote>
<div><p>tail_ent_emb: torch.FloatTensor) -&gt; torch.FloatTensor</p>
</div></blockquote>
<p>Computes the score of a triple using the ComplEx scoring function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">k_vs_all_score(emb_h:</span> <span class="pre">torch.FloatTensor,</span> <span class="pre">emb_r:</span> <span class="pre">torch.FloatTensor,</span></span></dt>
<dd><blockquote>
<div><p>emb_E: torch.FloatTensor) -&gt; torch.FloatTensor</p>
</div></blockquote>
<p>Computes scores in a K-vs-All setting using complex-valued embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ComplEx.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.ComplEx.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Performs a forward pass for K-vs-All scoring, returning scores for all entities.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>ComplEx is particularly suited for modeling asymmetric relations and has been
shown to perform well on various knowledge graph benchmarks. The use of complex
numbers allows the model to encode additional information compared to real-valued models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.ComplEx.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.ComplEx.score" title="Link to this definition"></a></dt>
<dd><p>Compute the scoring function for a given triple using complex-valued embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>head_ent_emb</strong> (<em>torch.FloatTensor</em>)  The complex embedding of the head entity.</p></li>
<li><p><strong>rel_ent_emb</strong> (<em>torch.FloatTensor</em>)  The complex embedding of the relation.</p></li>
<li><p><strong>tail_ent_emb</strong> (<em>torch.FloatTensor</em>)  The complex embedding of the tail entity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The score of the triple calculated using the Hermitian dot product of complex embeddings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The scoring function exploits the complex vector space to model the interactions
between entities and relations. It involves element-wise multiplication and
summation of real and imaginary parts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ComplEx.k_vs_all_score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_E</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.ComplEx.k_vs_all_score" title="Link to this definition"></a></dt>
<dd><p>Compute scores for a head entity and relation against all entities in a K-vs-All scenario.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>emb_h</strong> (<em>torch.FloatTensor</em>)  The complex embedding of the head entity.</p></li>
<li><p><strong>emb_r</strong> (<em>torch.FloatTensor</em>)  The complex embedding of the relation.</p></li>
<li><p><strong>emb_E</strong> (<em>torch.FloatTensor</em>)  The complex embeddings of all possible tail entities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all possible triples formed with the given head entity and relation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This method is useful for tasks like link prediction where the model predicts
the likelihood of a relation between a given entity pair.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id29">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id29" title="Link to this definition"></a></dt>
<dd><p>Perform a forward pass for K-vs-all scoring using complex-valued embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.LongTensor</em>)  Tensor containing indices for head entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all triples formed with the given head entities and relations against all entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This method is typically used in training and evaluation of the model in a
link prediction setting, where the goal is to rank all possible tail entities
for a given head entity and relation.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.AConEx">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">AConEx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AConEx" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>AConEx (Additive Convolutional ComplEx) extends the ConEx model by incorporating
additive connections in the convolutional operations. This model integrates
convolutional neural networks with complex-valued embeddings, emphasizing
additive feature interactions for knowledge graph embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model,
such as embedding dimensions, kernel size, number of output channels, and dropout rates.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConEx.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.AConEx.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the AConEx model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConEx.conv2d">
<span class="sig-name descname"><span class="pre">conv2d</span></span><a class="headerlink" href="#dicee.AConEx.conv2d" title="Link to this definition"></a></dt>
<dd><p>A 2D convolutional layer used for processing complex-valued embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Conv2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConEx.fc_num_input">
<span class="sig-name descname"><span class="pre">fc_num_input</span></span><a class="headerlink" href="#dicee.AConEx.fc_num_input" title="Link to this definition"></a></dt>
<dd><p>The number of input features for the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConEx.fc1">
<span class="sig-name descname"><span class="pre">fc1</span></span><a class="headerlink" href="#dicee.AConEx.fc1" title="Link to this definition"></a></dt>
<dd><p>A fully connected linear layer for compressing the output of the
convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Linear</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConEx.norm_fc1">
<span class="sig-name descname"><span class="pre">norm_fc1</span></span><a class="headerlink" href="#dicee.AConEx.norm_fc1" title="Link to this definition"></a></dt>
<dd><p>Normalization layer applied after the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Normalizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConEx.bn_conv2d">
<span class="sig-name descname"><span class="pre">bn_conv2d</span></span><a class="headerlink" href="#dicee.AConEx.bn_conv2d" title="Link to this definition"></a></dt>
<dd><p>Batch normalization layer applied after the convolutional operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.BatchNorm2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConEx.feature_map_dropout">
<span class="sig-name descname"><span class="pre">feature_map_dropout</span></span><a class="headerlink" href="#dicee.AConEx.feature_map_dropout" title="Link to this definition"></a></dt>
<dd><p>Dropout layer applied to the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Dropout2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">residual_convolution(C_1:</span> <span class="pre">Tuple[torch.Tensor,</span> <span class="pre">torch.Tensor],</span></span></dt>
<dd><blockquote>
<div><p>C_2: Tuple[torch.Tensor, torch.Tensor]) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]</p>
</div></blockquote>
<p>Performs a residual convolution operation on two complex-valued embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConEx.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.AConEx.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using convolutional operations on embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConEx.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.AConEx.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConEx.forward_k_vs_sample">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AConEx.forward_k_vs_sample" title="Link to this definition"></a></dt>
<dd><p>Computes scores against a sampled subset of entities using convolutional operations.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>AConEx aims to enhance the modeling capabilities of knowledge graph embeddings
by adding more complex interaction patterns through convolutional layers, potentially
improving performance on tasks like link prediction.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConEx.residual_convolution">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.AConEx.residual_convolution" title="Link to this definition"></a></dt>
<dd><p>Computes the residual convolution of two complex-valued embeddings. This method
is a core part of the AConEx model, applying convolutional neural network techniques
to complex-valued embeddings to capture intricate relationships in the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C_1</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>torch.Tensor</em><em>]</em>)  A tuple of two PyTorch tensors representing the real and imaginary components
of the first complex-valued embedding.</p></li>
<li><p><strong>C_2</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>torch.Tensor</em><em>]</em>)  A tuple of two PyTorch tensors representing the real and imaginary components
of the second complex-valued embedding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple of four tensors, each representing a component of the convolutionally
transformed embeddings. These components correspond to the modified real
and imaginary parts of the input embeddings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method concatenates the real and imaginary components of the embeddings and
applies a 2D convolution, followed by batch normalization, ReLU activation, dropout,
and a fully connected layer. This convolutional process is designed to enhance
the models ability to capture complex patterns in knowledge graph embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id30">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id30" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using convolutional and additive operations on
complex-valued embeddings. This method evaluates the performance of the model by computing
scores for each head entity and relation pair against all possible tail entities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of head entities and relations. Expected tensor shape:
(batch_size, 2), where batch_size is the number of head entity and relation pairs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each head entity and relation pair against all possible
tail entities. Tensor shape: (batch_size, <a href="#id99"><span class="problematic" id="id100">|E|</span></a>), where <a href="#id101"><span class="problematic" id="id102">|E|</span></a> is the number of entities
in the knowledge graph.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method first retrieves embeddings for head entities and relations, splits them into real
and imaginary parts, and applies a convolutional operation. It then computes the Hermitian
inner product with all tail entity embeddings, using an additive approach that combines the
convolutional results with the original embeddings. This technique aims to capture complex
relational patterns in the knowledge graph.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id31">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id31" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations and additive connections
on complex-valued embeddings. This method is key for evaluating the models performance on
individual triples within the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of triples. Each triple consists of indices for a head entity,
a relation, and a tail entity. Expected tensor shape: (n, 3), where n is the number of triples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each triple in the batch. Tensor shape: (n,), where n
is the number of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method retrieves embeddings for head entities, relations, and tail entities, and splits them
into real and imaginary parts. It then applies a convolution operation on these embeddings and
computes the Hermitian inner product, enhanced with an additive connection. This approach allows
the model to capture complex relational patterns within the knowledge graph, potentially improving
prediction accuracy and interpretability.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id32">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id32" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of samples (entity pairs) given a batch of queries. This method is used
to predict the scores for different tail entities for a set of query triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of query triples. Each triple consists of indices for a head entity,
a relation, and a dummy tail entity (used for scoring). Expected tensor shape: (n, 3), where n is
the number of query triples.</p></li>
<li><p><strong>target_entity_idx</strong> (<em>torch.Tensor</em>)  A tensor containing the indices of the target tail entities for which scores are to be predicted.
Expected tensor shape: (n, m), where n is the number of queries and m is the number of target
entities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each query-triple and target-entity pair. Tensor shape: (n, m),
where n is the number of queries and m is the number of target entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This method retrieves embeddings for the head entities and relations in the query triples, splits them
into real and imaginary parts, and applies convolutional operations with additive connections to capture
complex patterns. It also retrieves embeddings for the target tail entities and computes Hermitian inner
products to obtain scores, allowing the model to rank the tail entities based on their relevance to the queries.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.AConvO">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">AConvO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AConvO" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>Additive Convolutional Octonion(AConvO) extends the base knowledge graph embedding model by integrating additive convolutional
operations with octonion algebra. This model applies convolutional neural networks to octonion-based
embeddings, capturing complex interactions in knowledge graphs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model,
such as embedding dimensions, number of output channels, kernel size, and dropout rates.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvO.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.AConvO.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the AConvO model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvO.conv2d">
<span class="sig-name descname"><span class="pre">conv2d</span></span><a class="headerlink" href="#dicee.AConvO.conv2d" title="Link to this definition"></a></dt>
<dd><p>A 2D convolutional layer used for processing octonion-based embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Conv2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvO.fc_num_input">
<span class="sig-name descname"><span class="pre">fc_num_input</span></span><a class="headerlink" href="#dicee.AConvO.fc_num_input" title="Link to this definition"></a></dt>
<dd><p>The number of input features for the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvO.fc1">
<span class="sig-name descname"><span class="pre">fc1</span></span><a class="headerlink" href="#dicee.AConvO.fc1" title="Link to this definition"></a></dt>
<dd><p>A fully connected linear layer for compressing the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Linear</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvO.bn_conv2d">
<span class="sig-name descname"><span class="pre">bn_conv2d</span></span><a class="headerlink" href="#dicee.AConvO.bn_conv2d" title="Link to this definition"></a></dt>
<dd><p>Batch normalization layer applied after the convolutional operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.BatchNorm2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvO.norm_fc1">
<span class="sig-name descname"><span class="pre">norm_fc1</span></span><a class="headerlink" href="#dicee.AConvO.norm_fc1" title="Link to this definition"></a></dt>
<dd><p>Normalization layer applied after the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Normalizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvO.feature_map_dropout">
<span class="sig-name descname"><span class="pre">feature_map_dropout</span></span><a class="headerlink" href="#dicee.AConvO.feature_map_dropout" title="Link to this definition"></a></dt>
<dd><p>Dropout layer applied to the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Dropout2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConvO.octonion_normalizer">
<span class="sig-name descname"><span class="pre">octonion_normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_rel_e0:</span> <span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e1:</span> <span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">...</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e7:</span> <span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.AConvO.octonion_normalizer" title="Link to this definition"></a></dt>
<dd><p>Normalizes octonion components to unit length.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConvO.residual_convolution">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">O_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">O_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.AConvO.residual_convolution" title="Link to this definition"></a></dt>
<dd><p>Performs a residual convolution operation on two octonion embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConvO.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.AConvO.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConvO.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AConvO.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores against a sampled subset of entities using convolutional operations.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>AConvO aims to enhance the modeling capabilities of knowledge graph embeddings by
adding more complex interaction patterns through convolutional layers, potentially
improving performance on tasks like link prediction.</p>
<dl class="py method">
<dt class="sig sig-object py" id="id33">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">octonion_normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_rel_e0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e3</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e4</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e5</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e6</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e7</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id33" title="Link to this definition"></a></dt>
<dd><p>Normalizes the components of an octonion to unit length.</p>
<p>Each component of the octonion is divided by the square root of the sum of
the squares of all components.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>emb_rel_e0</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>emb_rel_e1</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>...</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>emb_rel_e7</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized components of the octonion.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, ]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id34">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">O_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">O_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id34" title="Link to this definition"></a></dt>
<dd><p>Performs a residual convolution operation on two sets of octonion embeddings.</p>
<p>The method combines two octonion embeddings and applies a convolutional operation
followed by batch normalization, dropout, and a fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>O_1</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>...</em><em>]</em>)  The first set of octonion embeddings.</p></li>
<li><p><strong>O_2</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>...</em><em>]</em>)  The second set of octonion embeddings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The resulting octonion embeddings after the convolutional operation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, ]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id35">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id35" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations.</p>
<p>The method processes head, relation, and tail embeddings using convolutional
layers and computes the scores of the triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  Tensor containing indices for head entities, relations, and tail entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for the given batch of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id36">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id36" title="Link to this definition"></a></dt>
<dd><p>Compute scores for a head entity and a relation (h,r) against all entities in the knowledge graph.</p>
<p>Given a head entity and a relation (h, r), this method computes scores for (h, r, x) for all entities x in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor containing indices for head entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of scores representing the compatibility of (h, r, x) for all entities x in the knowledge graph.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This method supports batch processing, allowing the input tensor <cite>x</cite> to contain multiple head entities and relations.</p>
<p>The scores indicate how well each entity x in the knowledge graph fits the (h, r) pattern, with higher scores indicating better compatibility.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.AConvQ">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">AConvQ</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AConvQ" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>Additive Convolutional Quaternion Knowledge Graph Embeddings (AConvQ) model integrates
quaternion algebra with convolutional neural networks for knowledge graph embeddings.
This model is designed to capture complex interactions in knowledge graphs by applying
additive convolutions to quaternion-based entity and relation embeddings.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.AConvQ.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the AConvQ model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.entity_embeddings">
<span class="sig-name descname"><span class="pre">entity_embeddings</span></span><a class="headerlink" href="#dicee.AConvQ.entity_embeddings" title="Link to this definition"></a></dt>
<dd><p>Embedding layer for entities in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.relation_embeddings">
<span class="sig-name descname"><span class="pre">relation_embeddings</span></span><a class="headerlink" href="#dicee.AConvQ.relation_embeddings" title="Link to this definition"></a></dt>
<dd><p>Embedding layer for relations in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.conv2d">
<span class="sig-name descname"><span class="pre">conv2d</span></span><a class="headerlink" href="#dicee.AConvQ.conv2d" title="Link to this definition"></a></dt>
<dd><p>A 2D convolutional layer used for processing quaternion embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Conv2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.fc_num_input">
<span class="sig-name descname"><span class="pre">fc_num_input</span></span><a class="headerlink" href="#dicee.AConvQ.fc_num_input" title="Link to this definition"></a></dt>
<dd><p>The number of input features for the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.fc1">
<span class="sig-name descname"><span class="pre">fc1</span></span><a class="headerlink" href="#dicee.AConvQ.fc1" title="Link to this definition"></a></dt>
<dd><p>A fully connected linear layer for compressing the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Linear</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.bn_conv1">
<span class="sig-name descname"><span class="pre">bn_conv1</span></span><a class="headerlink" href="#dicee.AConvQ.bn_conv1" title="Link to this definition"></a></dt>
<dd><p>Batch normalization layer applied after the convolutional operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.BatchNorm2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.bn_conv2">
<span class="sig-name descname"><span class="pre">bn_conv2</span></span><a class="headerlink" href="#dicee.AConvQ.bn_conv2" title="Link to this definition"></a></dt>
<dd><p>Normalization layer applied after the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Normalizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.AConvQ.feature_map_dropout">
<span class="sig-name descname"><span class="pre">feature_map_dropout</span></span><a class="headerlink" href="#dicee.AConvQ.feature_map_dropout" title="Link to this definition"></a></dt>
<dd><p>Dropout layer applied to the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Dropout2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConvQ.residual_convolution">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Q_2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AConvQ.residual_convolution" title="Link to this definition"></a></dt>
<dd><p>Performs an additive residual convolution operation on two sets of quaternion embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConvQ.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indexed_triple</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.AConvQ.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using additive convolutional operations on quaternion embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AConvQ.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.AConvQ.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id37">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Q_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id37" title="Link to this definition"></a></dt>
<dd><p>Performs a residual convolution operation on two sets of quaternion embeddings.</p>
<p>The method combines two quaternion embeddings and applies a convolutional operation
followed by batch normalization, dropout, and a fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Q_1</strong> (<em>Tuple</em><em>[</em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>]</em>)  The first set of quaternion embeddings.</p></li>
<li><p><strong>Q_2</strong> (<em>Tuple</em><em>[</em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>]</em>)  The second set of quaternion embeddings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The resulting quaternion embeddings after the convolutional operation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id38">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indexed_triple</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id38" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations on quaternion embeddings.</p>
<p>The method processes head, relation, and tail embeddings using quaternion algebra and
convolutional layers and computes the scores of the triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indexed_triple</strong> (<em>torch.FloatTensor</em>)  Tensor containing indices for head entities, relations, and tail entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for the given batch of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id39">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id39" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.</p>
<p>This method retrieves embeddings for the head entities and relations from the input tensor <cite>x</cite>,
applies necessary dropout and normalization, and then computes scores against all entities in
the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.FloatTensor</em>)  A tensor containing indices for head entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all entities for the given batch of head entities and relations.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.ConvQ">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">ConvQ</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.ConvQ" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>Convolutional Quaternion Knowledge Graph Embeddings (ConvQ) is a model that extends
the base knowledge graph embedding approach by using quaternion algebra and convolutional
neural networks. This model aims to capture complex interactions in knowledge graphs
by applying convolutions to quaternion-based entity and relation embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model,
such as embedding dimensions, number of output channels, kernel size, and dropout rates.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.ConvQ.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the ConvQ model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.entity_embeddings">
<span class="sig-name descname"><span class="pre">entity_embeddings</span></span><a class="headerlink" href="#dicee.ConvQ.entity_embeddings" title="Link to this definition"></a></dt>
<dd><p>Embedding layer for entities in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.relation_embeddings">
<span class="sig-name descname"><span class="pre">relation_embeddings</span></span><a class="headerlink" href="#dicee.ConvQ.relation_embeddings" title="Link to this definition"></a></dt>
<dd><p>Embedding layer for relations in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.conv2d">
<span class="sig-name descname"><span class="pre">conv2d</span></span><a class="headerlink" href="#dicee.ConvQ.conv2d" title="Link to this definition"></a></dt>
<dd><p>A 2D convolutional layer used for processing quaternion embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Conv2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.fc_num_input">
<span class="sig-name descname"><span class="pre">fc_num_input</span></span><a class="headerlink" href="#dicee.ConvQ.fc_num_input" title="Link to this definition"></a></dt>
<dd><p>The number of input features for the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.fc1">
<span class="sig-name descname"><span class="pre">fc1</span></span><a class="headerlink" href="#dicee.ConvQ.fc1" title="Link to this definition"></a></dt>
<dd><p>A fully connected linear layer for compressing the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Linear</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.bn_conv1">
<span class="sig-name descname"><span class="pre">bn_conv1</span></span><a class="headerlink" href="#dicee.ConvQ.bn_conv1" title="Link to this definition"></a></dt>
<dd><p>First batch normalization layer applied after the convolutional operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.BatchNorm2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.bn_conv2">
<span class="sig-name descname"><span class="pre">bn_conv2</span></span><a class="headerlink" href="#dicee.ConvQ.bn_conv2" title="Link to this definition"></a></dt>
<dd><p>Second normalization layer applied after the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Normalizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvQ.feature_map_dropout">
<span class="sig-name descname"><span class="pre">feature_map_dropout</span></span><a class="headerlink" href="#dicee.ConvQ.feature_map_dropout" title="Link to this definition"></a></dt>
<dd><p>Dropout layer applied to the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Dropout2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConvQ.residual_convolution">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Q_2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.ConvQ.residual_convolution" title="Link to this definition"></a></dt>
<dd><p>Performs a residual convolution operation on two sets of quaternion embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConvQ.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indexed_triple</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.ConvQ.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations on quaternion embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConvQ.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.ConvQ.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>ConvQ leverages the properties of quaternions, a number system that extends complex numbers,
to represent and process the embeddings of entities and relations. The convolutional layers
aim to capture spatial relationships and complex patterns in the embeddings.</p>
<dl class="py method">
<dt class="sig sig-object py" id="id40">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Q_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id40" title="Link to this definition"></a></dt>
<dd><p>Performs a residual convolution operation on two sets of quaternion embeddings.</p>
<p>The method combines two quaternion embeddings and applies a convolutional operation
followed by batch normalization, dropout, and a fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Q_1</strong> (<em>Tuple</em><em>[</em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>]</em>)  The first set of quaternion embeddings.</p></li>
<li><p><strong>Q_2</strong> (<em>Tuple</em><em>[</em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>, </em><em>torch.FloatTensor</em><em>]</em>)  The second set of quaternion embeddings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The resulting quaternion embeddings after the convolutional operation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id41">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indexed_triple</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id41" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations on quaternion embeddings.</p>
<p>The method processes head, relation, and tail embeddings using quaternion algebra and
convolutional layers and computes the scores of the triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indexed_triple</strong> (<em>torch.FloatTensor</em>)  Tensor containing indices for head entities, relations, and tail entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for the given batch of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id42">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id42" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.</p>
<p>This method retrieves embeddings for the head entities and relations from the input tensor <cite>x</cite>,
applies necessary dropout and normalization, and then computes scores against all entities in
the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.FloatTensor</em>)  A tensor containing indices for head entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all entities for the given batch of head entities and relations.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.ConvO">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">ConvO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.ConvO" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>ConvO extends the base knowledge graph embedding model by integrating convolutional
operations with octonion algebra. This model applies convolutional neural networks
to octonion-based embeddings, capturing complex interactions in knowledge graphs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model,
such as embedding dimensions, number of output channels, kernel size, and dropout rates.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvO.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.ConvO.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the ConvO model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvO.conv2d">
<span class="sig-name descname"><span class="pre">conv2d</span></span><a class="headerlink" href="#dicee.ConvO.conv2d" title="Link to this definition"></a></dt>
<dd><p>A 2D convolutional layer used for processing octonion-based embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Conv2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvO.fc_num_input">
<span class="sig-name descname"><span class="pre">fc_num_input</span></span><a class="headerlink" href="#dicee.ConvO.fc_num_input" title="Link to this definition"></a></dt>
<dd><p>The number of input features for the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvO.fc1">
<span class="sig-name descname"><span class="pre">fc1</span></span><a class="headerlink" href="#dicee.ConvO.fc1" title="Link to this definition"></a></dt>
<dd><p>A fully connected linear layer for compressing the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Linear</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvO.bn_conv2d">
<span class="sig-name descname"><span class="pre">bn_conv2d</span></span><a class="headerlink" href="#dicee.ConvO.bn_conv2d" title="Link to this definition"></a></dt>
<dd><p>Batch normalization layer applied after the convolutional operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.BatchNorm2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvO.norm_fc1">
<span class="sig-name descname"><span class="pre">norm_fc1</span></span><a class="headerlink" href="#dicee.ConvO.norm_fc1" title="Link to this definition"></a></dt>
<dd><p>Normalization layer applied after the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Normalizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConvO.feature_map_dropout">
<span class="sig-name descname"><span class="pre">feature_map_dropout</span></span><a class="headerlink" href="#dicee.ConvO.feature_map_dropout" title="Link to this definition"></a></dt>
<dd><p>Dropout layer applied to the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Dropout2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConvO.octonion_normalizer">
<span class="sig-name descname"><span class="pre">octonion_normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_rel_e0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">...</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e7</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.ConvO.octonion_normalizer" title="Link to this definition"></a></dt>
<dd><p>Normalizes octonion components to unit length.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConvO.residual_convolution">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">O_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">O_2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.ConvO.residual_convolution" title="Link to this definition"></a></dt>
<dd><p>Performs a residual convolution operation on two octonion embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConvO.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.ConvO.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConvO.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.ConvO.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores against a sampled subset of entities using convolutional operations.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>ConvO aims to enhance the modeling capabilities of knowledge graph embeddings by
adding more complex interaction patterns through convolutional layers, potentially
improving performance on tasks like link prediction.</p>
<dl class="py method">
<dt class="sig sig-object py" id="id43">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">octonion_normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_rel_e0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e3</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e4</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e5</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e6</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e7</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id43" title="Link to this definition"></a></dt>
<dd><p>Normalizes the components of an octonion to unit length.</p>
<p>Each component of the octonion is divided by the square root of the sum of
the squares of all components.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>emb_rel_e0</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>emb_rel_e1</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>...</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>emb_rel_e7</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized components of the octonion.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, ]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id44">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">O_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">O_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id44" title="Link to this definition"></a></dt>
<dd><p>Performs a residual convolution operation on two sets of octonion embeddings.</p>
<p>The method combines two octonion embeddings and applies a convolutional operation
followed by batch normalization, dropout, and a fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>O_1</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>...</em><em>]</em>)  The first set of octonion embeddings.</p></li>
<li><p><strong>O_2</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>...</em><em>]</em>)  The second set of octonion embeddings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The resulting octonion embeddings after the convolutional operation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, ]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id45">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id45" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations.</p>
<p>The method processes head, relation, and tail embeddings using convolutional
layers and computes the scores of the triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  Tensor containing indices for head entities, relations, and tail entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for the given batch of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id46">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id46" title="Link to this definition"></a></dt>
<dd><p>Given a batch of head entities and relations (h,r), this method computes scores for all entities.
[score(h,r,x)|x in Entities] =&gt; [0.0,0.1,,0.8], shape=&gt; (1, <a href="#id103"><span class="problematic" id="id104">|Entities|</span></a>)
Given a batch of head entities and relations =&gt; shape (size of batch,| Entities|)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of input triples in the form of (head entities, relations).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for the input triples against all possible tail entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>The input <cite>x</cite> is a tensor of shape (batch_size, 2), where each row represents a pair of head entities and relations.</p></li>
<li><dl class="simple">
<dt>The method follows the following steps:</dt><dd><ol class="arabic simple">
<li><p>Retrieve embeddings &amp; Apply Dropout &amp; Normalization.</p></li>
<li><p>Split the embeddings into real and imaginary parts.</p></li>
<li><p>Apply convolution operation on the real and imaginary parts.</p></li>
<li><p>Perform quaternion multiplication.</p></li>
<li><p>Compute scores for all entities.</p></li>
</ol>
</dd>
</dl>
</li>
</ul>
<p>The method returns a tensor of shape (batch_size, num_entities) where each row contains scores for each entity in the knowledge graph.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.ConEx">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">ConEx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.ConEx" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>ConEx (Convolutional ComplEx) is a Knowledge Graph Embedding model that extends ComplEx embeddings with convolutional layers.
It integrates convolutional neural networks into the embedding process to capture complex patterns in the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model, such as embedding dimensions,
kernel size, number of output channels, and dropout rates.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConEx.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.ConEx.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the ConEx model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConEx.conv2d">
<span class="sig-name descname"><span class="pre">conv2d</span></span><a class="headerlink" href="#dicee.ConEx.conv2d" title="Link to this definition"></a></dt>
<dd><p>A 2D convolutional layer used for processing complex-valued embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Conv2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConEx.fc1">
<span class="sig-name descname"><span class="pre">fc1</span></span><a class="headerlink" href="#dicee.ConEx.fc1" title="Link to this definition"></a></dt>
<dd><p>A fully connected linear layer for compressing the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Linear</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConEx.norm_fc1">
<span class="sig-name descname"><span class="pre">norm_fc1</span></span><a class="headerlink" href="#dicee.ConEx.norm_fc1" title="Link to this definition"></a></dt>
<dd><p>Normalization layer applied after the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Normalizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConEx.bn_conv2d">
<span class="sig-name descname"><span class="pre">bn_conv2d</span></span><a class="headerlink" href="#dicee.ConEx.bn_conv2d" title="Link to this definition"></a></dt>
<dd><p>Batch normalization layer applied after the convolutional operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.BatchNorm2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.ConEx.feature_map_dropout">
<span class="sig-name descname"><span class="pre">feature_map_dropout</span></span><a class="headerlink" href="#dicee.ConEx.feature_map_dropout" title="Link to this definition"></a></dt>
<dd><p>Dropout layer applied to the output of the convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Dropout2d</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConEx.residual_convolution">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.ConEx.residual_convolution" title="Link to this definition"></a></dt>
<dd><p>Performs a residual convolution operation on two complex-valued embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConEx.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.ConEx.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using convolutional operations on embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConEx.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.ConEx.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.ConEx.forward_k_vs_sample">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.ConEx.forward_k_vs_sample" title="Link to this definition"></a></dt>
<dd><p>Computes scores against a sampled subset of entities using convolutional operations.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>ConEx combines complex-valued embeddings with convolutional neural networks to capture intricate patterns and interactions
in the knowledge graph, potentially leading to improved performance on tasks like link prediction.</p>
<dl class="py method">
<dt class="sig sig-object py" id="id47">
<span class="sig-name descname"><span class="pre">residual_convolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id47" title="Link to this definition"></a></dt>
<dd><p>Computes the residual score of two complex-valued embeddings by applying convolutional operations.
This method is a key component of the ConEx model, combining complex embeddings with convolutional neural networks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C_1</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>torch.Tensor</em><em>]</em>)  A tuple consisting of two PyTorch tensors representing the real and imaginary components of the first complex-valued embedding.</p></li>
<li><p><strong>C_2</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>torch.Tensor</em><em>]</em>)  A tuple consisting of two PyTorch tensors representing the real and imaginary components of the second complex-valued embedding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple of two tensors, representing the real and imaginary parts of the convolutionally transformed embeddings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.FloatTensor, torch.FloatTensor]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method involves concatenating the real and imaginary components of the embeddings, applying a 2D convolution,
followed by batch normalization, ReLU activation, dropout, and a fully connected layer. This process is intended to
capture complex interactions between the embeddings in a convolutional manner.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id48">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id48" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using convolutional operations on complex-valued embeddings.
This method is used for evaluating the performance of the model by computing scores for each head entity
and relation pair against all possible tail entities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of head entities and relations. Expected tensor shape: (n, 2),
where n is the batch size and 2 represents head entity and relation pairs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each head entity and relation pair against all possible tail entities.
Tensor shape: (n, <a href="#id105"><span class="problematic" id="id106">|E|</span></a>), where <a href="#id107"><span class="problematic" id="id108">|E|</span></a> is the number of entities in the knowledge graph.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method retrieves embeddings for head entities and relations, splits them into real and imaginary parts,
and applies a convolution operation. It then computes the Hermitian product of the transformed embeddings
with all tail entity embeddings to generate scores. This approach allows for capturing complex relational patterns
in the knowledge graph.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id49">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id49" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples using convolutional operations on complex-valued embeddings.
This method is crucial for evaluating the performance of the model on individual triples in the
knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of triples. Each triple consists of indices for a head entity,
a relation, and a tail entity. Expected tensor shape: (n, 3), where n is the number of triples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each triple in the batch. Tensor shape: (n,), where n
is the number of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method retrieves embeddings for head entities, relations, and tail entities, and splits them
into real and imaginary parts. It then applies a convolution operation on these embeddings and
computes the Hermitian inner product, which involves a combination of real and imaginary parts
of the embeddings. This process is designed to capture complex relational patterns and interactions
within the knowledge graph, leveraging the power of convolutional neural networks.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id50">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id50" title="Link to this definition"></a></dt>
<dd><p>Computes scores against a sampled subset of entities using convolutional operations
on complex-valued embeddings. This method is particularly useful for large knowledge graphs
where computing scores against all entities is computationally expensive.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor representing a batch of head entities and relations. Expected tensor shape:
(batch_size, 2), where batch_size is the number of head entity and relation pairs.</p></li>
<li><p><strong>target_entity_idx</strong> (<em>torch.Tensor</em>)  A tensor of target entity indices for sampling. Tensor shape:
(batch_size, num_selected_entities).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing the scores for each head entity and relation pair against the sampled
subset of tail entities. Tensor shape: (batch_size, num_selected_entities).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method first retrieves and processes the embeddings for head entities and relations. It then
applies a convolution operation and computes the Hermitian inner product with the embeddings of
the sampled tail entities. This process enables capturing complex relational patterns in a
computationally efficient manner.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.QMult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">QMult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QMult" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>QMult extends the base knowledge graph embedding model by integrating quaternion
algebra. This model leverages the properties of quaternions to represent and process
the embeddings of entities and relations in a knowledge graph, aiming to capture
complex interactions and patterns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model,
such as embedding dimensions and learning rate.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.QMult.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.QMult.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the QMult model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QMult.quaternion_normalizer">
<span class="sig-name descname"><span class="pre">quaternion_normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.QMult.quaternion_normalizer" title="Link to this definition"></a></dt>
<dd><p>Normalizes the length of relation vectors.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QMult.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.QMult.score" title="Link to this definition"></a></dt>
<dd><p>Computes the score of a triple using quaternion multiplication.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QMult.k_vs_all_score">
<span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bpe_head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bpe_rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.QMult.k_vs_all_score" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using quaternion embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QMult.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.QMult.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Performs a forward pass for K-vs-All scoring, returning scores for all entities.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QMult.forward_k_vs_sample">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.QMult.forward_k_vs_sample" title="Link to this definition"></a></dt>
<dd><p>Performs a forward pass for K-vs-Sample scoring, returning scores for the specified entities.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QMult.quaternion_multiplication_followed_by_inner_product">
<span class="sig-name descname"><span class="pre">quaternion_multiplication_followed_by_inner_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.QMult.quaternion_multiplication_followed_by_inner_product" title="Link to this definition"></a></dt>
<dd><p>Performs quaternion multiplication followed by inner product, returning triple scores.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id51">
<span class="sig-name descname"><span class="pre">quaternion_multiplication_followed_by_inner_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id51" title="Link to this definition"></a></dt>
<dd><p>Performs quaternion multiplication followed by inner product.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>torch.FloatTensor</em>)  The head representations. Shape: (<cite>*batch_dims</cite>, dim)</p></li>
<li><p><strong>r</strong> (<em>torch.FloatTensor</em>)  The relation representations. Shape: (<cite>*batch_dims</cite>, dim)</p></li>
<li><p><strong>t</strong> (<em>torch.FloatTensor</em>)  The tail representations. Shape: (<cite>*batch_dims</cite>, dim)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Triple scores.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id52">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">quaternion_normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id52" title="Link to this definition"></a></dt>
<dd><p>TODO: Add mathematical format for sphinx.
Normalize the length of relation vectors, if the forward constraint has not been applied yet.</p>
<p>The absolute value of a quaternion is calculated as follows:
.. math:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">|</span><span class="n">a</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">cj</span> <span class="o">+</span> <span class="n">dk</span><span class="o">|</span> <span class="o">=</span> \<span class="n">sqrt</span><span class="p">{</span><span class="n">a</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="n">b</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="n">c</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="n">d</span><span class="o">^</span><span class="mi">2</span><span class="p">}</span>
</pre></div>
</div>
<p>The L2 norm of a quaternion vector is computed as:
.. math:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>\<span class="o">|</span><span class="n">x</span>\<span class="o">|^</span><span class="mi">2</span> <span class="o">=</span> \<span class="n">sum_</span><span class="p">{</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">}</span><span class="o">^</span><span class="n">d</span> <span class="o">|</span><span class="n">x_i</span><span class="o">|^</span><span class="mi">2</span>
         <span class="o">=</span> \<span class="n">sum_</span><span class="p">{</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">}</span><span class="o">^</span><span class="n">d</span> <span class="p">(</span><span class="n">x_i</span><span class="o">.</span><span class="n">re</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x_i</span><span class="o">.</span><span class="n">im_1</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x_i</span><span class="o">.</span><span class="n">im_2</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x_i</span><span class="o">.</span><span class="n">im_3</span><span class="o">^</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.FloatTensor</em>)  The vector containing quaternion values.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized vector.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This function normalizes the length of relation vectors represented as quaternions. It ensures that
the absolute value of each quaternion in the vector is equal to 1, preserving the unit length.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id53">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id53" title="Link to this definition"></a></dt>
<dd><p>Compute scores for a batch of triples using octonion-based embeddings.</p>
<p>This method computes scores for a batch of triples using octonion-based embeddings of head entities,
relation embeddings, and tail entities. It supports both explicit and non-explicit scoring methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>head_ent_emb</strong> (<em>torch.FloatTensor</em>)  Tensor containing the octonion-based embeddings of head entities.</p></li>
<li><p><strong>rel_ent_emb</strong> (<em>torch.FloatTensor</em>)  Tensor containing the octonion-based embeddings of relations.</p></li>
<li><p><strong>tail_ent_emb</strong> (<em>torch.FloatTensor</em>)  Tensor containing the octonion-based embeddings of tail entities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for the given batch of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>If no normalization is set, this method applies quaternion normalization to relation embeddings.</p>
<p>If the scoring method is explicit, it computes the scores using quaternion multiplication followed by
an inner product of the real and imaginary parts of the resulting quaternions.</p>
<p>If the scoring method is non-explicit, it directly computes the inner product of the real and
imaginary parts of the octonion-based embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id54">
<span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bpe_head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bpe_rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id54" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using quaternion embeddings for a batch of head entities and relations.</p>
<p>This method involves splitting the head entity and relation embeddings into quaternion components,
optionally normalizing the relation embeddings, performing quaternion multiplication, and then
calculating the score by performing an inner product with all tail entity embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bpe_head_ent_emb</strong> (<em>torch.FloatTensor</em>)  Batched embeddings of head entities, each represented as a quaternion.</p></li>
<li><p><strong>bpe_rel_ent_emb</strong> (<em>torch.FloatTensor</em>)  Batched embeddings of relations, each represented as a quaternion.</p></li>
<li><p><strong>E</strong> (<em>torch.FloatTensor</em>)  Embeddings of all possible tail entities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all possible triples formed with the given head entities and relations against all entities.
The shape of the output is (size of batch, number of entities).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method is particularly useful in scenarios like link prediction, where the goal is to rank all possible
tail entities for a given head entity and relation. Quaternion algebra is used to enhance the interaction
modeling between entities and relations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id55">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id55" title="Link to this definition"></a></dt>
<dd><p>Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.</p>
<p>This method retrieves embeddings for the head entities and relations from the input tensor <cite>x</cite>,
applies necessary dropout and normalization, and then uses the <cite>k_vs_all_score</cite> method to compute
the scores against all possible tail entities in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.FloatTensor</em>)  A tensor containing indices for head entities and relations. The tensor is expected to have
a specific format suitable for the models embedding retrieval process.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of scores, where each row corresponds to the scores of all tail entities for a
single head entity and relation pair. The shape of the tensor is (size of the batch, number of entities).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This method is typically used in evaluating the models performance in link prediction tasks,
where its important to rank the likelihood of every possible tail entity for a given head entity
and relation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id56">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id56" title="Link to this definition"></a></dt>
<dd><p>Computes scores for a batch of triples against a sampled subset of entities in a K-vs-Sample setting.</p>
<p>Given a batch of head entities and relations (h,r), this method computes the scores for all possible triples
formed with these head entities and relations against a subset of entities, i.e.,
[score(h,r,x)|x in Entities] =&gt; [0.0,0.1,,0.8], shape=&gt; (1, <a href="#id109"><span class="problematic" id="id110">|Entities|</span></a>). TODO: Add mathematical format for sphinx.
The subset of entities is specified by the <cite>target_entity_idx</cite>, which is an integer index representing a specific entity.
Given a batch of head entities and relations =&gt; shape (size of batch,| Entities|).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.FloatTensor</em>)  A tensor containing indices for head entities and relations. The tensor is expected to have
a specific format suitable for the models embedding retrieval process.</p></li>
<li><p><strong>target_entity_idx</strong> (<em>int</em>)  Index of the target entity against which the scores are to be computed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of scores where each element corresponds to the score of the target entity
for a single head entity and relation pair. The shape of the tensor is (size of the batch, 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This method is particularly useful in scenarios like link prediction, where its necessary to
evaluate the likelihood of a specific relationship between a given head entity and a particular
target entity.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.OMult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">OMult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.OMult" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>OMult extends the base knowledge graph embedding model by integrating octonion
algebra. This model leverages the properties of octonions to represent and process
the embeddings of entities and relations in a knowledge graph, aiming to capture
complex interactions and patterns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model,
such as embedding dimensions and learning rate.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.OMult.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.OMult.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the OMult model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.OMult.octonion_normalizer">
<span class="sig-name descname"><span class="pre">octonion_normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_rel_e0:</span> <span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e1:</span> <span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">...</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e7:</span> <span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.OMult.octonion_normalizer" title="Link to this definition"></a></dt>
<dd><p>Normalizes octonion components to unit length.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.OMult.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.OMult.score" title="Link to this definition"></a></dt>
<dd><p>Computes the score of a triple using octonion multiplication.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.OMult.k_vs_all_score">
<span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bpe_head_ent_emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bpe_rel_ent_emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.OMult.k_vs_all_score" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using octonion embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.OMult.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.OMult.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Performs a forward pass for K-vs-All scoring, returning scores for all entities.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id57">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">octonion_normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_rel_e0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e3</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e4</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e5</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e6</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_rel_e7</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id57" title="Link to this definition"></a></dt>
<dd><p>Normalizes the components of an octonion.</p>
<p>Each component of the octonion is divided by the square root of the sum of
the squares of all components, normalizing it to unit length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>emb_rel_e0</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>emb_rel_e1</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>...</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
<li><p><strong>emb_rel_e7</strong> (<em>torch.Tensor</em>)  The eight components of an octonion.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized components of the octonion.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, ]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id58">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id58" title="Link to this definition"></a></dt>
<dd><p>Computes the score of a triple using octonion multiplication.</p>
<p>The method involves splitting the embeddings into real and imaginary parts,
normalizing the relation embeddings, performing octonion multiplication,
and then calculating the score based on the inner product.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>head_ent_emb</strong> (<em>torch.FloatTensor</em>)  Embedding of the head entity.</p></li>
<li><p><strong>rel_ent_emb</strong> (<em>torch.FloatTensor</em>)  Embedding of the relation.</p></li>
<li><p><strong>tail_ent_emb</strong> (<em>torch.FloatTensor</em>)  Embedding of the tail entity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The score of the triple.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id59">
<span class="sig-name descname"><span class="pre">k_vs_all_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bpe_head_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bpe_rel_ent_emb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id59" title="Link to this definition"></a></dt>
<dd><p>Computes scores in a K-vs-All setting using octonion embeddings for a batch of head entities and relations.</p>
<p>This method splits the head entity and relation embeddings into their octonion components, normalizes
the relation embeddings if necessary, and then applies octonion multiplication. It computes the score
by performing an inner product with all tail entity embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bpe_head_ent_emb</strong> (<em>torch.FloatTensor</em>)  Batched embeddings of head entities, each represented as an octonion.</p></li>
<li><p><strong>bpe_rel_ent_emb</strong> (<em>torch.FloatTensor</em>)  Batched embeddings of relations, each represented as an octonion.</p></li>
<li><p><strong>E</strong> (<em>torch.FloatTensor</em>)  Embeddings of all possible tail entities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all possible triples formed with the given head entities and relations against all entities.
The shape of the output is (size of batch, number of entities).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method is particularly useful in scenarios like link prediction, where the goal is to rank all possible
tail entities for a given head entity and relation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id60">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id60" title="Link to this definition"></a></dt>
<dd><p>Performs a forward pass for K-vs-All scoring.</p>
<p>TODO: Add mathematical format for sphinx.</p>
<p>Given a head entity and a relation (h,r), this method computes scores for all
possible triples, i.e., [score(h,r,x)|x in Entities] =&gt; [0.0,0.1,,0.8], shape=&gt; (1, <a href="#id111"><span class="problematic" id="id112">|Entities|</span></a>), returning a score for each entity in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>)  Tensor containing indices for head entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scores for all triples formed with the given head entities and relations against all entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.Shallom">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">Shallom</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.Shallom" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>Shallom is a shallow neural model designed for relation prediction in knowledge graphs.
The model combines entity embeddings and passes them through a neural network to predict
the likelihood of different relations. Its based on the paper:
A Shallow Neural Model for Relation Prediction
(<a class="reference external" href="https://arxiv.org/abs/2101.09090">https://arxiv.org/abs/2101.09090</a>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Shallom.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.Shallom.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the Shallom model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.Shallom.shallom">
<span class="sig-name descname"><span class="pre">shallom</span></span><a class="headerlink" href="#dicee.Shallom.shallom" title="Link to this definition"></a></dt>
<dd><p>A sequential neural network model used for predicting relations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Sequential</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Shallom.get_embeddings">
<span class="sig-name descname"><span class="pre">get_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">np.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.Shallom.get_embeddings" title="Link to this definition"></a></dt>
<dd><p>Retrieves the entity embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Shallom.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Shallom.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Computes relation scores for all pairs of entities in the batch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Shallom.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.Shallom.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Computes relation scores for a batch of triples.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id61">
<span class="sig-name descname"><span class="pre">get_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id61" title="Link to this definition"></a></dt>
<dd><p>Retrieves the entity embeddings from the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing the entity embeddings as a NumPy array and None for the relation embeddings.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple[np.ndarray, None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id62">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id62" title="Link to this definition"></a></dt>
<dd><p>Computes relation scores for all pairs of entities in the batch.</p>
<p>Each pair of entities is passed through the Shallom neural network to predict
the likelihood of various relations between them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor of entity pairs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of relation scores for each pair of entities in the batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id63">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id63" title="Link to this definition"></a></dt>
<dd><p>Computes relation scores for a batch of triples.</p>
<p>This method first computes relation scores for all possible relations for each pair of entities
and then selects the scores corresponding to the actual relations in the triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)  A tensor containing a batch of triples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A flattened tensor of relation scores for the given batch of triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.LFMult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">LFMult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>Embedding with polynomial functions. We represent all entities and relations in the polynomial space as:
f(x) = sum_{i=0}^{d-1} a_k x^{i%d} and use the three differents scoring function as in the paper to evaluate the score.
We also consider combining with Neural Networks.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx_triple</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Perform the forward pass for triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.LongTensor</em>)  The input tensor containing the indexes of head, relation, and tail entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor containing the scores for the input triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.construct_multi_coeff">
<span class="sig-name descname"><span class="pre">construct_multi_coeff</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.construct_multi_coeff" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.poly_NN">
<span class="sig-name descname"><span class="pre">poly_NN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coefh</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coefr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeft</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.poly_NN" title="Link to this definition"></a></dt>
<dd><p>Constructing a 2 layers NN to represent the embeddings.
h = sigma(wh^T x + bh ),  r = sigma(wr^T x + br ),  t = sigma(wt^T x + bt )</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.linear">
<span class="sig-name descname"><span class="pre">linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.linear" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.scalar_batch_NN">
<span class="sig-name descname"><span class="pre">scalar_batch_NN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.scalar_batch_NN" title="Link to this definition"></a></dt>
<dd><p>element wise multiplication between a,b and c:
Inputs : a, b, c ====&gt; torch.tensor of size batch_size x m x d
Output : a tensor of size batch_size x d</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.tri_score">
<span class="sig-name descname"><span class="pre">tri_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">coeff_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeff_r</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeff_t</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.tri_score" title="Link to this definition"></a></dt>
<dd><p>this part implement the trilinear scoring techniques:</p>
<p>score(h,r,t) = int_{0}{1} h(x)r(x)t(x) dx = sum_{i,j,k = 0}^{d-1} dfrac{a_i*b_j*c_k}{1+(i+j+k)%d}</p>
<ol class="arabic simple">
<li><p>generate the range for i,j and k from [0 d-1]</p></li>
</ol>
<p>2. perform
dfrac{a_i*b_j*c_k}{1+(i+j+k)%d} in parallel for every batch</p>
<ol class="arabic simple" start="3">
<li><p>take the sum over each batch</p></li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.vtp_score">
<span class="sig-name descname"><span class="pre">vtp_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.vtp_score" title="Link to this definition"></a></dt>
<dd><p>this part implement the vector triple product scoring techniques:</p>
<p>score(h,r,t) = int_{0}{1} h(x)r(x)t(x) dx = sum_{i,j,k = 0}^{d-1} dfrac{a_i*c_j*b_k - b_i*c_j*a_k}{(1+(i+j)%d)(1+k)}</p>
<ol class="arabic simple">
<li><p>generate the range for i,j and k from [0 d-1]</p></li>
<li><p>Compute the first and second terms of the sum</p></li>
<li><p>Multiply with then denominator and take the sum</p></li>
<li><p>take the sum over each batch</p></li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.comp_func">
<span class="sig-name descname"><span class="pre">comp_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.comp_func" title="Link to this definition"></a></dt>
<dd><p>this part implement the function composition scoring techniques: i.e. score = &lt;hor, t&gt;</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.polynomial">
<span class="sig-name descname"><span class="pre">polynomial</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">coeff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degree</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.polynomial" title="Link to this definition"></a></dt>
<dd><p>This function takes a matrix tensor of coefficients (coeff), a tensor vector of points x  and range of integer [0,1,d]
and return a vector tensor (coeff[0][0] + coeff[0][1]x ++ coeff[0][d]x^d,</p>
<blockquote>
<div><dl class="simple">
<dt>coeff[1][0] + coeff[1][1]x ++ coeff[1][d]x^d)</dt><dd></dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.LFMult.pop">
<span class="sig-name descname"><span class="pre">pop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">coeff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degree</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.LFMult.pop" title="Link to this definition"></a></dt>
<dd><p>This function allow us to evaluate the composition of two polynomes without for loops :)
it takes a matrix tensor of coefficients (coeff), a matrix tensor of points x  and range of integer [0,1,d]</p>
<blockquote>
<div><dl class="simple">
<dt>and return a tensor (coeff[0][0] + coeff[0][1]x ++ coeff[0][d]x^d,</dt><dd><dl class="simple">
<dt>coeff[1][0] + coeff[1][1]x ++ coeff[1][d]x^d)</dt><dd></dd>
</dl>
</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.PykeenKGE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">PykeenKGE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.PykeenKGE" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>A class for using knowledge graph embedding models implemented in Pykeen.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> (<em>dict</em>)  A dictionary of arguments containing hyperparameters and settings for the model,
such as embedding dimensions, random seed, and model-specific kwargs.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.PykeenKGE.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#dicee.PykeenKGE.name" title="Link to this definition"></a></dt>
<dd><p>The name identifier for the PykeenKGE model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.PykeenKGE.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#dicee.PykeenKGE.model" title="Link to this definition"></a></dt>
<dd><p>The Pykeen model instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pykeen.models.base.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.PykeenKGE.loss_history">
<span class="sig-name descname"><span class="pre">loss_history</span></span><a class="headerlink" href="#dicee.PykeenKGE.loss_history" title="Link to this definition"></a></dt>
<dd><p>A list to store the training loss history.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.PykeenKGE.args">
<span class="sig-name descname"><span class="pre">args</span></span><a class="headerlink" href="#dicee.PykeenKGE.args" title="Link to this definition"></a></dt>
<dd><p>The arguments used to initialize the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.PykeenKGE.entity_embeddings">
<span class="sig-name descname"><span class="pre">entity_embeddings</span></span><a class="headerlink" href="#dicee.PykeenKGE.entity_embeddings" title="Link to this definition"></a></dt>
<dd><p>Entity embeddings learned by the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.PykeenKGE.relation_embeddings">
<span class="sig-name descname"><span class="pre">relation_embeddings</span></span><a class="headerlink" href="#dicee.PykeenKGE.relation_embeddings" title="Link to this definition"></a></dt>
<dd><p>Relation embeddings learned by the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Embedding</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.PykeenKGE.interaction">
<span class="sig-name descname"><span class="pre">interaction</span></span><a class="headerlink" href="#dicee.PykeenKGE.interaction" title="Link to this definition"></a></dt>
<dd><p>Interaction module used by the Pykeen model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pykeen.nn.modules.Interaction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.PykeenKGE.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.PykeenKGE.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Compute scores for all entities given a batch of head entities and relations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.PykeenKGE.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.PykeenKGE.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Compute scores for a batch of triples.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.PykeenKGE.forward_k_vs_sample">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.PykeenKGE.forward_k_vs_sample" title="Link to this definition"></a></dt>
<dd><p>Compute scores against a sampled subset of entities.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>This class provides an interface for using knowledge graph embedding models implemented
in Pykeen. It initializes Pykeen models based on the provided arguments and allows for
scoring triples and conducting knowledge graph embedding experiments.</p>
<dl class="py method">
<dt class="sig sig-object py" id="id64">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id64" title="Link to this definition"></a></dt>
<dd><p>TODO: Format in Numpy-style documentation</p>
<p># =&gt; Explicit version by this we can apply bn and dropout</p>
<p># (1) Retrieve embeddings of heads and relations +  apply Dropout &amp; Normalization if given.
h, r = self.get_head_relation_representation(x)
# (2) Reshape (1).
if self.last_dim &gt; 0:</p>
<blockquote>
<div><p>h = h.reshape(len(x), self.embedding_dim, self.last_dim)
r = r.reshape(len(x), self.embedding_dim, self.last_dim)</p>
</div></blockquote>
<p># (3) Reshape all entities.
if self.last_dim &gt; 0:</p>
<blockquote>
<div><p>t = self.entity_embeddings.weight.reshape(self.num_entities, self.embedding_dim, self.last_dim)</p>
</div></blockquote>
<dl class="simple">
<dt>else:</dt><dd><p>t = self.entity_embeddings.weight</p>
</dd>
</dl>
<p># (4) Call the score_t from interactions to generate triple scores.
return self.interaction.score_t(h=h, r=r, all_entities=t, slice_size=1)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id65">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#id65" title="Link to this definition"></a></dt>
<dd><p>TODO: Format in Numpy-style documentation</p>
<p># =&gt; Explicit version by this we can apply bn and dropout</p>
<p># (1) Retrieve embeddings of heads, relations and tails and apply Dropout &amp; Normalization if given.
h, r, t = self.get_triple_representation(x)
# (2) Reshape (1).
if self.last_dim &gt; 0:</p>
<blockquote>
<div><p>h = h.reshape(len(x), self.embedding_dim, self.last_dim)
r = r.reshape(len(x), self.embedding_dim, self.last_dim)
t = t.reshape(len(x), self.embedding_dim, self.last_dim)</p>
</div></blockquote>
<p># (3) Compute the triple score
return self.interaction.score(h=h, r=r, t=t, slice_size=None, slice_dim=0)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id66">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entity_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id66" title="Link to this definition"></a></dt>
<dd><p>Forward pass for K vs. Sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  This function is not implemented in the current model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.BytE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">BytE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BytE" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.models.base_model.BaseKGE</span></code></a></p>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code class="xref py py-meth docutils literal notranslate"><span class="pre">to()</span></code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> call to the parent class
must be made before assignment on the child.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>training</strong> (<em>bool</em>)  Boolean represents whether this module is in training or
evaluation mode.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.BytE.loss_function">
<span class="sig-name descname"><span class="pre">loss_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">yhat_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BytE.loss_function" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>yhat_batch</strong>  </p></li>
<li><p><strong>y_batch</strong>  </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BytE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BytE.forward" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>B by T tensor</em>)  </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BytE.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_new_tokens</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BytE.generate" title="Link to this definition"></a></dt>
<dd><p>Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete
the sequence max_new_tokens times, feeding the predictions back into the model each time.
Most likely youll want to make sure to be in model.eval() mode of operation for this.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BytE.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BytE.training_step" title="Link to this definition"></a></dt>
<dd><p>Here you compute and return the training loss and some additional metrics for e.g. the progress bar or
logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong>  The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong>  The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong>  The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary which can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code> in the case of
automatic optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - In automatic optimization, this will skip to the next batch (but is not supported for
multi-GPU, TPU, or DeepSpeed). For manual optimization, this has no special meaning, as returning
the loss is not required.</p></li>
</ul>
</p>
</dd>
</dl>
<p>In this step youd normally do the forward pass and calculate the loss for a batch.
You can also do fancier things like multiple forward passes or something model specific.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>To use multiple optimizers, you can switch to manual optimization and control their stepping:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">automatic_optimization</span> <span class="o">=</span> <span class="kc">False</span>


<span class="c1"># Multiple optimizers (e.g.: GANs)</span>
<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">opt1</span><span class="p">,</span> <span class="n">opt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>

    <span class="c1"># do training_step with encoder</span>
    <span class="o">...</span>
    <span class="n">opt1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># do training_step with decoder</span>
    <span class="o">...</span>
    <span class="n">opt2</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> &gt; 1, the loss returned here will be automatically
normalized by <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> internally.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.BaseKGE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">BaseKGE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BaseKGE" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseKGELightning</span></code></p>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code class="xref py py-meth docutils literal notranslate"><span class="pre">to()</span></code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> call to the parent class
must be made before assignment on the child.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>training</strong> (<em>bool</em>)  Boolean represents whether this module is in training or
evaluation mode.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.forward_byte_pair_encoded_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_byte_pair_encoded_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BaseKGE.forward_byte_pair_encoded_k_vs_all" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>B x 2 x T</em>)  </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.forward_byte_pair_encoded_triple">
<span class="sig-name descname"><span class="pre">forward_byte_pair_encoded_triple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BaseKGE.forward_byte_pair_encoded_triple" title="Link to this definition"></a></dt>
<dd><p>Perform the forward pass for byte pair encoded triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tuple</em><em>[</em><em>torch.LongTensor</em><em>, </em><em>torch.LongTensor</em><em>]</em>)  The input tuple containing byte pair encoded entities and relations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor containing the scores for the byte pair encoded triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.init_params_with_sanity_checking">
<span class="sig-name descname"><span class="pre">init_params_with_sanity_checking</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BaseKGE.init_params_with_sanity_checking" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BaseKGE.forward" title="Link to this definition"></a></dt>
<dd><p>Perform the forward pass of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Union</em><em>[</em><em>torch.LongTensor</em><em>, </em><em>Tuple</em><em>[</em><em>torch.LongTensor</em><em>, </em><em>torch.LongTensor</em><em>]</em><em>]</em>)  The input tensor or a tuple containing the input tensor and target entity indexes.</p></li>
<li><p><strong>y_idx</strong> (<em>torch.LongTensor</em><em>, </em><em>optional</em>)  The target entity indexes (default is None).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the forward pass.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.forward_triples">
<span class="sig-name descname"><span class="pre">forward_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.BaseKGE.forward_triples" title="Link to this definition"></a></dt>
<dd><p>Perform the forward pass for triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.LongTensor</em>)  The input tensor containing the indexes of head, relation, and tail entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor containing the scores for the input triples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.forward_k_vs_all">
<span class="sig-name descname"><span class="pre">forward_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BaseKGE.forward_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Forward pass for K vs. All.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  This function is not implemented in the current model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.forward_k_vs_sample">
<span class="sig-name descname"><span class="pre">forward_k_vs_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BaseKGE.forward_k_vs_sample" title="Link to this definition"></a></dt>
<dd><p>Forward pass for K vs. Sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  This function is not implemented in the current model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.get_triple_representation">
<span class="sig-name descname"><span class="pre">get_triple_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx_hrt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BaseKGE.get_triple_representation" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.get_head_relation_representation">
<span class="sig-name descname"><span class="pre">get_head_relation_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indexed_triple</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.BaseKGE.get_head_relation_representation" title="Link to this definition"></a></dt>
<dd><p>Get the representation for the head and relation entities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indexed_triple</strong> (<em>torch.LongTensor</em>)  The indexes of the head and relation entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The representation for the head and relation entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.FloatTensor, torch.FloatTensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.get_sentence_representation">
<span class="sig-name descname"><span class="pre">get_sentence_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.BaseKGE.get_sentence_representation" title="Link to this definition"></a></dt>
<dd><p>Get the representation for a sentence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.LongTensor</em>)  The input tensor containing the indexes of head, relation, and tail entities.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The representation for the input sentence.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.get_bpe_head_and_relation_representation">
<span class="sig-name descname"><span class="pre">get_bpe_head_and_relation_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.FloatTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.BaseKGE.get_bpe_head_and_relation_representation" title="Link to this definition"></a></dt>
<dd><p>Get the representation for BPE head and relation entities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>B x 2 x T</em>)  </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The representation for BPE head and relation entities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.FloatTensor, torch.FloatTensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BaseKGE.get_embeddings">
<span class="sig-name descname"><span class="pre">get_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.BaseKGE.get_embeddings" title="Link to this definition"></a></dt>
<dd><p>Get the entity and relation embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The entity and relation embeddings.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple[np.ndarray, np.ndarray]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.create_recipriocal_triples">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">create_recipriocal_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.create_recipriocal_triples" title="Link to this definition"></a></dt>
<dd><p>Add inverse triples into dask dataframe
:param x:
:return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.get_er_vocab">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">get_er_vocab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.get_er_vocab" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.get_re_vocab">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">get_re_vocab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.get_re_vocab" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.get_ee_vocab">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">get_ee_vocab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.get_ee_vocab" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.timeit">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">timeit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.timeit" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.save_pickle">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">save_pickle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">object</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.save_pickle" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.load_pickle">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">load_pickle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.load_pickle" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.select_model">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">select_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_continual_training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">storage_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.select_model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.load_model">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_of_experiment_folder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'model.pt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.load_model" title="Link to this definition"></a></dt>
<dd><p>Load weights and initialize pytorch module from namespace arguments</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.load_model_ensemble">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">load_model_ensemble</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_of_experiment_folder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><span class="pre">dicee.models.base_model.BaseKGE</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas.DataFrame</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">pandas.DataFrame</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.load_model_ensemble" title="Link to this definition"></a></dt>
<dd><p>Construct Ensemble Of weights and initialize pytorch module from namespace arguments</p>
<ol class="arabic simple">
<li><p>Detect models under given path</p></li>
<li><p>Accumulate parameters of detected models</p></li>
<li><p>Normalize parameters</p></li>
<li><p>Insert (3) into model.</p></li>
</ol>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.save_numpy_ndarray">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">save_numpy_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.save_numpy_ndarray" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.numpy_data_type_changer">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">numpy_data_type_changer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#dicee.numpy_data_type_changer" title="Link to this definition"></a></dt>
<dd><p>Detect most efficient data type for a given triples
:param train_set:
:param num:
:return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.save_checkpoint_model">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">save_checkpoint_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.save_checkpoint_model" title="Link to this definition"></a></dt>
<dd><p>Store Pytorch model into disk</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.store">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">store</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trained_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'model'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_storage_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_embeddings_as_csv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.store" title="Link to this definition"></a></dt>
<dd><p>Store trained_model model and save embeddings into csv file.
:param trainer: an instance of trainer class
:param full_storage_path: path to save parameters.
:param model_name: string representation of the name of the model.
:param trained_model: an instance of BaseKGE see core.models.base_model .
:param save_embeddings_as_csv: for easy access of embeddings.
:return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.add_noisy_triples">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">add_noisy_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pandas.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_noise_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pandas.DataFrame</span></span></span><a class="headerlink" href="#dicee.add_noisy_triples" title="Link to this definition"></a></dt>
<dd><p>Add randomly constructed triples
:param train_set:
:param add_noise_rate:
:return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.read_or_load_kg">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">read_or_load_kg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cls</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.read_or_load_kg" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.intialize_model">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">intialize_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.intialize_model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.load_json">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">load_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#dicee.load_json" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.save_embeddings">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">save_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.save_embeddings" title="Link to this definition"></a></dt>
<dd><p>Save it as CSV if memory allows.
:param embeddings:
:param indexes:
:param path:
:return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.random_prediction">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">random_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pre_trained_kge</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.random_prediction" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.deploy_triple_prediction">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">deploy_triple_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pre_trained_kge</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_subject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_predicate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_object</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.deploy_triple_prediction" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.deploy_tail_entity_prediction">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">deploy_tail_entity_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pre_trained_kge</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_subject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_predicate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.deploy_tail_entity_prediction" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.deploy_head_entity_prediction">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">deploy_head_entity_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pre_trained_kge</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_object</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_predicate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.deploy_head_entity_prediction" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.deploy_relation_prediction">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">deploy_relation_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pre_trained_kge</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_subject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str_object</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.deploy_relation_prediction" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.vocab_to_parquet">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">vocab_to_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab_to_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_for_serialization</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_into</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.vocab_to_parquet" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.create_experiment_folder">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">create_experiment_folder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Experiments'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.create_experiment_folder" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.continual_training_setup_executor">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">continual_training_setup_executor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">executor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.continual_training_setup_executor" title="Link to this definition"></a></dt>
<dd><p>storage_path:str A path leading to a parent directory, where a subdirectory containing KGE related data</p>
<p>full_storage_path:str A path leading to a subdirectory containing KGE related data</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.exponential_function">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">exponential_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ascending_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.exponential_function" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.load_numpy">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">load_numpy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#dicee.load_numpy" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.evaluate">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">entity_to_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">easy_answers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hard_answers</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.evaluate" title="Link to this definition"></a></dt>
<dd><p># &#64;TODO: CD: Renamed this function
Evaluate multi hop query answering on different query types</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.download_file">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">download_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">url</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination_folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.download_file" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.download_files_from_url">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">download_files_from_url</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_url</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination_folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.download_files_from_url" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_url</strong> (e.g. <a class="reference external" href="https://files.dice-research.org/projects/DiceEmbeddings/KINSHIP-Keci-dim128-epoch256-KvsAll">https://files.dice-research.org/projects/DiceEmbeddings/KINSHIP-Keci-dim128-epoch256-KvsAll</a>)  </p></li>
<li><p><strong>destination_folder</strong> (<em>e.g. &quot;KINSHIP-Keci-dim128-epoch256-KvsAll&quot;</em>)  </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.download_pretrained_model">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">download_pretrained_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#dicee.download_pretrained_model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.DICE_Trainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">DICE_Trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_continual_training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">storage_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">object</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DICE_Trainer" title="Link to this definition"></a></dt>
<dd><p>Implements a training framework for knowledge graph embedding models using [PyTorch Lightning](<a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html</a>),
supporting [multi-GPU](<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html</a>) and CPU training. This trainer can handle continual training scenarios and supports
different forms of labeling and evaluation methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<a class="reference internal" href="config/index.html#dicee.config.Namespace" title="dicee.config.Namespace"><em>Namespace</em></a>)  Command line arguments or configurations specifying training parameters and model settings.</p></li>
<li><p><strong>is_continual_training</strong> (<em>bool</em>)  Flag indicating whether the training session is part of a continual learning process.</p></li>
<li><p><strong>storage_path</strong> (<em>str</em>)  Path to the directory where training checkpoints and models are stored.</p></li>
<li><p><strong>evaluator</strong> (<em>object</em><em>, </em><em>optional</em>)  An evaluation object responsible for model evaluation. This can be any object that implements
an <cite>eval</cite> method accepting model predictions and returning evaluation metrics.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.report">
<span class="sig-name descname"><span class="pre">report</span></span><a class="headerlink" href="#dicee.DICE_Trainer.report" title="Link to this definition"></a></dt>
<dd><p>A dictionary to store training reports and metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.trainer">
<span class="sig-name descname"><span class="pre">trainer</span></span><a class="headerlink" href="#dicee.DICE_Trainer.trainer" title="Link to this definition"></a></dt>
<dd><p>The PyTorch Lightning Trainer instance used for model training.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>lightening.Trainer or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.form_of_labelling">
<span class="sig-name descname"><span class="pre">form_of_labelling</span></span><a class="headerlink" href="#dicee.DICE_Trainer.form_of_labelling" title="Link to this definition"></a></dt>
<dd><p>The form of labeling used during training, which can be EntityPrediction, RelationPrediction, or Pyke.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.continual_start">
<span class="sig-name descname"><span class="pre">continual_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DICE_Trainer.continual_start" title="Link to this definition"></a></dt>
<dd><p>Initializes and starts the training process, including model loading and fitting.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.initialize_trainer">
<span class="sig-name descname"><span class="pre">initialize_trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">lightening.Trainer</span></span></span><a class="headerlink" href="#dicee.DICE_Trainer.initialize_trainer" title="Link to this definition"></a></dt>
<dd><p>Initializes a PyTorch Lightning Trainer instance with the specified callbacks.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.initialize_or_load_model">
<span class="sig-name descname"><span class="pre">initialize_or_load_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.DICE_Trainer.initialize_or_load_model" title="Link to this definition"></a></dt>
<dd><p>Initializes or loads a model for training based on the training configuration.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.initialize_dataloader">
<span class="sig-name descname"><span class="pre">initialize_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.Dataset</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.DataLoader</span></span></span><a class="headerlink" href="#dicee.DICE_Trainer.initialize_dataloader" title="Link to this definition"></a></dt>
<dd><p>Initializes a DataLoader for the given dataset.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.initialize_dataset">
<span class="sig-name descname"><span class="pre">initialize_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="knowledge_graph/index.html#dicee.knowledge_graph.KG" title="dicee.knowledge_graph.KG"><span class="pre">KG</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">form_of_labelling</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.Dataset</span></span></span><a class="headerlink" href="#dicee.DICE_Trainer.initialize_dataset" title="Link to this definition"></a></dt>
<dd><p>Prepares and initializes a dataset for training.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.start">
<span class="sig-name descname"><span class="pre">start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">knowledge_graph</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="knowledge_graph/index.html#dicee.knowledge_graph.KG" title="dicee.knowledge_graph.KG"><span class="pre">KG</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#dicee.BaseKGE" title="dicee.BaseKGE"><span class="pre">BaseKGE</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.DICE_Trainer.start" title="Link to this definition"></a></dt>
<dd><p>Starts the training process for a given knowledge graph.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.DICE_Trainer.k_fold_cross_validation">
<span class="sig-name descname"><span class="pre">k_fold_cross_validation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#dicee.BaseKGE" title="dicee.BaseKGE"><span class="pre">BaseKGE</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.DICE_Trainer.k_fold_cross_validation" title="Link to this definition"></a></dt>
<dd><p>Performs K-fold cross-validation on the dataset and returns the trained model and form of labelling.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id67">
<span class="sig-name descname"><span class="pre">continual_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#id67" title="Link to this definition"></a></dt>
<dd><p>Initializes and starts the training process, including model loading and fitting.
This method is specifically designed for continual training scenarios.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>model</strong> (<em>BaseKGE</em>)  The trained knowledge graph embedding model instance. <cite>BaseKGE</cite> is a placeholder
for the actual model class, which should be a subclass of the base model class
used in your framework.</p></li>
<li><p><strong>form_of_labelling</strong> (<em>str</em>)  The form of labeling used during the training. This can indicate the type of
prediction task the model is trained for, such as EntityPrediction,
RelationPrediction, or other custom labeling forms defined in your implementation.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id68">
<span class="sig-name descname"><span class="pre">initialize_trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">lightning.Trainer</span></span></span><a class="headerlink" href="#id68" title="Link to this definition"></a></dt>
<dd><p>Initializes a PyTorch Lightning Trainer instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>callbacks</strong> (<em>List</em>)  A list of PyTorch Lightning callbacks to be used during training.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The initialized PyTorch Lightning Trainer instance.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pl.Trainer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id69">
<span class="sig-name descname"><span class="pre">initialize_or_load_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><span class="pre">dicee.models.base_model.BaseKGE</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id69" title="Link to this definition"></a></dt>
<dd><p>Initializes or loads a knowledge graph embedding model based on the training configuration.
This method decides whether to start training from scratch or to continue training from a
previously saved model state, depending on the <cite>is_continual_training</cite> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>model</strong> (<em>BaseKGE</em>)  The model instance that is either initialized from scratch or loaded from a saved state.
<cite>BaseKGE</cite> is a generic placeholder for the actual model class, which is a subclass of the
base knowledge graph embedding model class used in your implementation.</p></li>
<li><p><strong>form_of_labelling</strong> (<em>str</em>)  A string indicating the type of prediction task the model is configured for. Possible values
include EntityPrediction and RelationPrediction, which signify whether the model is
trained to predict missing entities or relations in a knowledge graph. The actual values
depend on the specific tasks supported by your implementation.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The method uses the <cite>is_continual_training</cite> attribute to determine if the model should be loaded
from a saved state. If <cite>is_continual_training</cite> is True, the method attempts to load the model and its
configuration from the specified <cite>storage_path</cite>. If <cite>is_continual_training</cite> is False or the model
cannot be loaded, a new model instance is initialized.</p>
<p>This method also sets the <cite>form_of_labelling</cite> attribute based on the models configuration, which
is used to inform downstream training and evaluation processes about the type of prediction task.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id70">
<span class="sig-name descname"><span class="pre">initialize_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.Dataset</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.DataLoader</span></span></span><a class="headerlink" href="#id70" title="Link to this definition"></a></dt>
<dd><p>Initializes and returns a PyTorch DataLoader object for the given dataset.</p>
<p>This DataLoader is configured based on the training arguments provided,
including batch size, shuffle status, and the number of workers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dataset</strong> (<em>torch.utils.data.Dataset</em>)  The dataset to be loaded into the DataLoader. This dataset should already
be processed and ready for training or evaluation.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A DataLoader instance ready for training or evaluation, configured with the
appropriate batch size, shuffle setting, and number of workers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.data.DataLoader</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id71">
<span class="sig-name descname"><span class="pre">initialize_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="knowledge_graph/index.html#dicee.knowledge_graph.KG" title="dicee.knowledge_graph.KG"><span class="pre">dicee.knowledge_graph.KG</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">form_of_labelling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.Dataset</span></span></span><a class="headerlink" href="#id71" title="Link to this definition"></a></dt>
<dd><p>Initializes and returns a dataset suitable for training or evaluation, based on the
knowledge graph data and the specified form of labelling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<a class="reference internal" href="knowledge_graph/index.html#dicee.knowledge_graph.KG" title="dicee.knowledge_graph.KG"><em>KG</em></a>)  The knowledge graph data used to construct the dataset. This should include
training, validation, and test sets along with any other necessary information
like entity and relation mappings.</p></li>
<li><p><strong>form_of_labelling</strong> (<em>str</em>)  The form of labelling to be used for the dataset, indicating the prediction
task (e.g., EntityPrediction, RelationPrediction).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A processed dataset ready for use with a PyTorch DataLoader, tailored to the
specified form of labelling and containing all necessary data for training
or evaluation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.data.Dataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id72">
<span class="sig-name descname"><span class="pre">start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">knowledge_graph</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="knowledge_graph/index.html#dicee.knowledge_graph.KG" title="dicee.knowledge_graph.KG"><span class="pre">dicee.knowledge_graph.KG</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><span class="pre">dicee.models.base_model.BaseKGE</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id72" title="Link to this definition"></a></dt>
<dd><p>Starts the training process for the selected model using the provided knowledge graph data.
The method selects and trains the model based on the configuration specified in the arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>knowledge_graph</strong> (<a class="reference internal" href="knowledge_graph/index.html#dicee.knowledge_graph.KG" title="dicee.knowledge_graph.KG"><em>KG</em></a>)  The knowledge graph data containing entities, relations, and triples, which will be used
for training the model.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the trained model instance and the form of labelling used during
training. The form of labelling indicates the type of prediction task.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[<a class="reference internal" href="#dicee.BaseKGE" title="dicee.BaseKGE">BaseKGE</a>, str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id73">
<span class="sig-name descname"><span class="pre">k_fold_cross_validation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="knowledge_graph/index.html#dicee.knowledge_graph.KG" title="dicee.knowledge_graph.KG"><span class="pre">dicee.knowledge_graph.KG</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="models/base_model/index.html#dicee.models.base_model.BaseKGE" title="dicee.models.base_model.BaseKGE"><span class="pre">dicee.models.base_model.BaseKGE</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id73" title="Link to this definition"></a></dt>
<dd><p>Conducts K-fold cross-validation on the provided dataset to assess the performance
of the model specified in the training arguments. The process involves partitioning
the dataset into K distinct subsets, iteratively using one subset for testing and
the remainder for training. The models performance is evaluated on each test split
to compute the Mean Reciprocal Rank (MRR) scores.</p>
<p>Steps:
1. The dataset is divided into K train and test splits.
2. For each split:
2.1. A trainer and model are initialized based on the provided configuration.
2.2. The model is trained using the training portion of the split.
2.3. The MRR score of the trained model is computed using the test portion of the split.
3. The process aggregates the MRR scores across all splits to report the mean and standard deviation
of the MRR, providing a comprehensive evaluation of the models performance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dataset</strong> (<a class="reference internal" href="knowledge_graph/index.html#dicee.knowledge_graph.KG" title="dicee.knowledge_graph.KG"><em>KG</em></a>)  The dataset to be used for K-fold cross-validation. This dataset should include
the triples (head entity, relation, tail entity) for the entire knowledge graph.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing:
- The trained model instance from the last fold of the cross-validation.
- The form of labelling used during training, indicating the prediction task
(e.g., EntityPrediction, RelationPrediction).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[<a class="reference internal" href="#dicee.BaseKGE" title="dicee.BaseKGE">BaseKGE</a>, str]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The function assumes the presence of a predefined number of folds (K) specified in
the training arguments. It utilizes PyTorch Lightning for model training and evaluation,
leveraging GPU acceleration if available. The final output includes the model trained
on the last fold and a summary of the cross-validation performance metrics.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.KGE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">KGE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">construct_ensemble</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_semantic_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="abstracts/index.html#dicee.abstracts.BaseInteractiveKGE" title="dicee.abstracts.BaseInteractiveKGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.abstracts.BaseInteractiveKGE</span></code></a></p>
<p>Knowledge Graph Embedding Class for interactive usage of pre-trained models</p>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.get_transductive_entity_embeddings">
<span class="sig-name descname"><span class="pre">get_transductive_entity_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_pytorch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_numpy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">numpy.ndarray</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.KGE.get_transductive_entity_embeddings" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.create_vector_database">
<span class="sig-name descname"><span class="pre">create_vector_database</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">collection_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">location</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'localhost'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">port</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6333</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.create_vector_database" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.generate" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.__str__">
<span class="sig-name descname"><span class="pre">__str__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.__str__" title="Link to this definition"></a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.eval_lp_performance">
<span class="sig-name descname"><span class="pre">eval_lp_performance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">List[Tuple[str,</span> <span class="pre">str,</span> <span class="pre">str]]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filtered</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.eval_lp_performance" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.predict_missing_head_entity">
<span class="sig-name descname"><span class="pre">predict_missing_head_entity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">relation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_entity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">within</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span></span></span><a class="headerlink" href="#dicee.KGE.predict_missing_head_entity" title="Link to this definition"></a></dt>
<dd><p>Given a relation and a tail entity, return top k ranked head entity.</p>
<p>argmax_{e in E } f(e,r,t), where r in R, t in E.</p>
<section id="id74">
<h4>Parameter<a class="headerlink" href="#id74" title="Link to this heading"></a></h4>
<p>relation:  Union[List[str], str]</p>
<p>String representation of selected relations.</p>
<p>tail_entity: Union[List[str], str]</p>
<p>String representation of selected entities.</p>
<p>k: int</p>
<p>Highest ranked k entities.</p>
</section>
<section id="returns-tuple">
<h4>Returns: Tuple<a class="headerlink" href="#returns-tuple" title="Link to this heading"></a></h4>
<p>Highest K scores and entities</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.predict_missing_relations">
<span class="sig-name descname"><span class="pre">predict_missing_relations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_entity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tail_entity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">within</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span></span></span><a class="headerlink" href="#dicee.KGE.predict_missing_relations" title="Link to this definition"></a></dt>
<dd><p>Given a head entity and a tail entity, return top k ranked relations.</p>
<p>argmax_{r in R } f(h,r,t), where h, t in E.</p>
<section id="id75">
<h4>Parameter<a class="headerlink" href="#id75" title="Link to this heading"></a></h4>
<p>head_entity: List[str]</p>
<p>String representation of selected entities.</p>
<p>tail_entity: List[str]</p>
<p>String representation of selected entities.</p>
<p>k: int</p>
<p>Highest ranked k entities.</p>
</section>
<section id="id76">
<h4>Returns: Tuple<a class="headerlink" href="#id76" title="Link to this heading"></a></h4>
<p>Highest K scores and entities</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.predict_missing_tail_entity">
<span class="sig-name descname"><span class="pre">predict_missing_tail_entity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_entity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">within</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.KGE.predict_missing_tail_entity" title="Link to this definition"></a></dt>
<dd><p>Given a head entity and a relation, return top k ranked entities</p>
<p>argmax_{e in E } f(h,r,e), where h in E and r in R.</p>
<section id="id77">
<h4>Parameter<a class="headerlink" href="#id77" title="Link to this heading"></a></h4>
<p>head_entity: List[str]</p>
<p>String representation of selected entities.</p>
<p>tail_entity: List[str]</p>
<p>String representation of selected entities.</p>
</section>
<section id="id78">
<h4>Returns: Tuple<a class="headerlink" href="#id78" title="Link to this heading"></a></h4>
<p>scores</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">within</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.KGE.predict" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong>  </p></li>
<li><p><strong>h</strong>  </p></li>
<li><p><strong>r</strong>  </p></li>
<li><p><strong>t</strong>  </p></li>
<li><p><strong>within</strong>  </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.predict_topk">
<span class="sig-name descname"><span class="pre">predict_topk</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topk</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">within</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.predict_topk" title="Link to this definition"></a></dt>
<dd><p>Predict missing item in a given triple.</p>
<section id="id79">
<h4>Parameter<a class="headerlink" href="#id79" title="Link to this heading"></a></h4>
<p>head_entity: List[str]</p>
<p>String representation of selected entities.</p>
<p>relation: List[str]</p>
<p>String representation of selected relations.</p>
<p>tail_entity: List[str]</p>
<p>String representation of selected entities.</p>
<p>k: int</p>
<p>Highest ranked k item.</p>
</section>
<section id="id80">
<h4>Returns: Tuple<a class="headerlink" href="#id80" title="Link to this heading"></a></h4>
<p>Highest K scores and items</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.triple_score">
<span class="sig-name descname"><span class="pre">triple_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.KGE.triple_score" title="Link to this definition"></a></dt>
<dd><p>Predict triple score</p>
<section id="id81">
<h4>Parameter<a class="headerlink" href="#id81" title="Link to this heading"></a></h4>
<p>head_entity: List[str]</p>
<p>String representation of selected entities.</p>
<p>relation: List[str]</p>
<p>String representation of selected relations.</p>
<p>tail_entity: List[str]</p>
<p>String representation of selected entities.</p>
<p>logits: bool</p>
<p>If logits is True, unnormalized score returned</p>
</section>
<section id="id82">
<h4>Returns: Tuple<a class="headerlink" href="#id82" title="Link to this heading"></a></h4>
<p>pytorch tensor of triple score</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.t_norm">
<span class="sig-name descname"><span class="pre">t_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tens_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tens_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tnorm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'min'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.KGE.t_norm" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.tensor_t_norm">
<span class="sig-name descname"><span class="pre">tensor_t_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subquery_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tnorm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'min'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#dicee.KGE.tensor_t_norm" title="Link to this definition"></a></dt>
<dd><p>Compute T-norm over [0,1] ^{n   imes d} where n denotes the number of hops and d denotes number of entities</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.t_conorm">
<span class="sig-name descname"><span class="pre">t_conorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tens_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tens_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tconorm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'min'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.KGE.t_conorm" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.negnorm">
<span class="sig-name descname"><span class="pre">negnorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tens_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'standard'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.KGE.negnorm" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.return_multi_hop_query_results">
<span class="sig-name descname"><span class="pre">return_multi_hop_query_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggregated_query_for_all_entities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">only_scores</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.return_multi_hop_query_results" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.single_hop_query_answering">
<span class="sig-name descname"><span class="pre">single_hop_query_answering</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">only_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.single_hop_query_answering" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.answer_multi_hop_query">
<span class="sig-name descname"><span class="pre">answer_multi_hop_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Ellipsis</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">queries</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Ellipsis</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tnorm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'prod'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'standard'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">only_scores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.KGE.answer_multi_hop_query" title="Link to this definition"></a></dt>
<dd><p># &#64;TODO: Refactoring is needed
# &#64;TODO: Score computation for each query type should be done in a static function</p>
<p>Find an answer set for EPFO queries including negation and disjunction</p>
<section id="id83">
<h4>Parameter<a class="headerlink" href="#id83" title="Link to this heading"></a></h4>
<p>query_type: str
The type of the query, e.g., 2p.</p>
<p>query: Union[str, Tuple[str, Tuple[str, str]]]
The query itself, either a string or a nested tuple.</p>
<p>queries: List of Tuple[Union[str, Tuple[str, str]], ]</p>
<p>tnorm: str
The t-norm operator.</p>
<p>neg_norm: str
The negation norm.</p>
<p><a href="#id127"><span class="problematic" id="id128">lambda_</span></a>: float
lambda parameter for sugeno and yager negation norms</p>
<p>k: int
The top-k substitutions for intermediate variables.</p>
<dl class="field-list simple">
<dt class="field-odd">returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><em>List[Tuple[str, torch.Tensor]]</em></p></li>
<li><p><em>Entities and corresponding scores sorted in the descening order of scores</em></p></li>
</ul>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.find_missing_triples">
<span class="sig-name descname"><span class="pre">find_missing_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">confidence</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topk</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">at_most</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">sys.maxsize</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Set</span></span></span><a class="headerlink" href="#dicee.KGE.find_missing_triples" title="Link to this definition"></a></dt>
<dd><blockquote>
<div><p>Find missing triples</p>
<p>Iterative over a set of entities E and a set of relation R :</p>
</div></blockquote>
<p>orall e in E and
orall r in R f(e,r,x)</p>
<blockquote>
<div><p>Return (e,r,x)</p>
</div></blockquote>
<p>otin G and  f(e,r,x) &gt; confidence</p>
<blockquote>
<div><p>confidence: float</p>
<p>A threshold for an output of a sigmoid function given a triple.</p>
<p>topk: int</p>
<p>Highest ranked k item to select triples with f(e,r,x) &gt; confidence .</p>
<p>at_most: int</p>
<p>Stop after finding at_most missing triples</p>
<p>{(e,r,x) | f(e,r,x) &gt; confidence land (e,r,x)</p>
</div></blockquote>
<p>otin G</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">share</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.deploy" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.train_triples">
<span class="sig-name descname"><span class="pre">train_triples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.train_triples" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.train_k_vs_all">
<span class="sig-name descname"><span class="pre">train_k_vs_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KGE.train_k_vs_all" title="Link to this definition"></a></dt>
<dd><p>Train k vs all
:param head_entity:
:param relation:
:param iteration:
:param lr:
:return:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KGE.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.KGE.train" title="Link to this definition"></a></dt>
<dd><p>Retrained a pretrain model on an input KG via negative sampling.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.Execute">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">Execute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuous_training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.Execute" title="Link to this definition"></a></dt>
<dd><p>A class for Training, Retraining and Evaluation a model.</p>
<ol class="arabic simple">
<li><p>Loading &amp; Preprocessing &amp; Serializing input data.</p></li>
<li><p>Training &amp; Validation &amp; Testing</p></li>
<li><p>Storing all necessary info</p></li>
</ol>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.Execute.read_or_load_kg">
<span class="sig-name descname"><span class="pre">read_or_load_kg</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.Execute.read_or_load_kg" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Execute.read_preprocess_index_serialize_data">
<span class="sig-name descname"><span class="pre">read_preprocess_index_serialize_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.Execute.read_preprocess_index_serialize_data" title="Link to this definition"></a></dt>
<dd><p>Read &amp; Preprocess &amp; Index &amp; Serialize Input Data</p>
<ol class="arabic simple">
<li><p>Read or load the data from disk into memory.</p></li>
<li><p>Store the statistics of the data.</p></li>
</ol>
<section id="id84">
<h4>Parameter<a class="headerlink" href="#id84" title="Link to this heading"></a></h4>
<dl class="field-list simple">
<dt class="field-odd">rtype<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Execute.load_indexed_data">
<span class="sig-name descname"><span class="pre">load_indexed_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.Execute.load_indexed_data" title="Link to this definition"></a></dt>
<dd><p>Load the indexed data from disk into memory</p>
<section id="id85">
<h4>Parameter<a class="headerlink" href="#id85" title="Link to this heading"></a></h4>
<dl class="field-list simple">
<dt class="field-odd">rtype<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Execute.save_trained_model">
<span class="sig-name descname"><span class="pre">save_trained_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.Execute.save_trained_model" title="Link to this definition"></a></dt>
<dd><p>Save a knowledge graph embedding model</p>
<ol class="arabic simple">
<li><p>Send model to eval mode and cpu.</p></li>
<li><p>Store the memory footprint of the model.</p></li>
<li><p>Save the model into disk.</p></li>
<li><p>Update the stats of KG again ?</p></li>
</ol>
<section id="id86">
<h4>Parameter<a class="headerlink" href="#id86" title="Link to this heading"></a></h4>
<dl class="field-list simple">
<dt class="field-odd">rtype<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Execute.end">
<span class="sig-name descname"><span class="pre">end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">form_of_labelling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#dicee.Execute.end" title="Link to this definition"></a></dt>
<dd><p>End training</p>
<ol class="arabic simple">
<li><p>Store trained model.</p></li>
<li><p>Report runtimes.</p></li>
<li><p>Eval model if required.</p></li>
</ol>
<section id="id87">
<h4>Parameter<a class="headerlink" href="#id87" title="Link to this heading"></a></h4>
<dl class="field-list simple">
<dt class="field-odd">rtype<span class="colon">:</span></dt>
<dd class="field-odd"><p>A dict containing information about the training and/or evaluation</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Execute.write_report">
<span class="sig-name descname"><span class="pre">write_report</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.Execute.write_report" title="Link to this definition"></a></dt>
<dd><p>Report training related information in a report.json file</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.Execute.start">
<span class="sig-name descname"><span class="pre">start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#dicee.Execute.start" title="Link to this definition"></a></dt>
<dd><p>Start training</p>
<p># (1) Loading the Data
# (2) Create an evaluator object.
# (3) Create a trainer object.
# (4) Start the training</p>
<section id="id88">
<h4>Parameter<a class="headerlink" href="#id88" title="Link to this heading"></a></h4>
<dl class="field-list simple">
<dt class="field-odd">rtype<span class="colon">:</span></dt>
<dd class="field-odd"><p>A dict containing information about the training and/or evaluation</p>
</dd>
</dl>
</section>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.mapping_from_first_two_cols_to_third">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">mapping_from_first_two_cols_to_third</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.mapping_from_first_two_cols_to_third" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id89">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">timeit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id89" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id90">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">load_pickle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id90" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.reload_dataset">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">reload_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">form_of_labelling</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_technique</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.reload_dataset" title="Link to this definition"></a></dt>
<dd><p>Reload the files from disk to construct the Pytorch dataset</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.construct_dataset">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">construct_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ordered_bpe_entities</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_to_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation_to_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">form_of_labelling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_technique</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">byte_pair_encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.Dataset</span></span></span><a class="headerlink" href="#dicee.construct_dataset" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.BPE_NegativeSamplingDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">BPE_NegativeSamplingDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ordered_shaped_bpe_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BPE_NegativeSamplingDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>An abstract class representing a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code>.</p>
<p>All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite <a class="reference internal" href="#dicee.BPE_NegativeSamplingDataset.__getitem__" title="dicee.BPE_NegativeSamplingDataset.__getitem__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__getitem__()</span></code></a>, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
<a class="reference internal" href="#dicee.BPE_NegativeSamplingDataset.__len__" title="dicee.BPE_NegativeSamplingDataset.__len__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__len__()</span></code></a>, which is expected to return the size of the dataset by many
<code class="xref py py-class docutils literal notranslate"><span class="pre">Sampler</span></code> implementations and the default options
of <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>. Subclasses could also
optionally implement <code class="xref py py-meth docutils literal notranslate"><span class="pre">__getitems__()</span></code>, for speedup batched samples
loading. This method accepts list of indices of samples of batch and returns
list of samples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> by default constructs an index
sampler that yields integral indices.  To make it work with a map-style
dataset with non-integral indices/keys, a custom sampler must be provided.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.BPE_NegativeSamplingDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BPE_NegativeSamplingDataset.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BPE_NegativeSamplingDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BPE_NegativeSamplingDataset.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.BPE_NegativeSamplingDataset.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_shaped_bpe_triples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.BPE_NegativeSamplingDataset.collate_fn" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.MultiLabelDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">MultiLabelDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_indices_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_ordered_shaped_bpe_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.MultiLabelDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>An abstract class representing a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code>.</p>
<p>All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite <a class="reference internal" href="#dicee.MultiLabelDataset.__getitem__" title="dicee.MultiLabelDataset.__getitem__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__getitem__()</span></code></a>, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
<a class="reference internal" href="#dicee.MultiLabelDataset.__len__" title="dicee.MultiLabelDataset.__len__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__len__()</span></code></a>, which is expected to return the size of the dataset by many
<code class="xref py py-class docutils literal notranslate"><span class="pre">Sampler</span></code> implementations and the default options
of <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>. Subclasses could also
optionally implement <code class="xref py py-meth docutils literal notranslate"><span class="pre">__getitems__()</span></code>, for speedup batched samples
loading. This method accepts list of indices of samples of batch and returns
list of samples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> by default constructs an index
sampler that yields integral indices.  To make it work with a map-style
dataset with non-integral indices/keys, a custom sampler must be provided.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.MultiLabelDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.MultiLabelDataset.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.MultiLabelDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.MultiLabelDataset.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.MultiClassClassificationDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">MultiClassClassificationDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subword_units</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.MultiClassClassificationDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>Dataset for the 1vsALL training strategy</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set_idx</strong>  Indexed triples for the training.</p></li>
<li><p><strong>entity_idxs</strong>  mapping.</p></li>
<li><p><strong>relation_idxs</strong>  mapping.</p></li>
<li><p><strong>form</strong>  <p>?</p>
</p></li>
<li><p><strong>num_workers</strong>  int for <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.utils.data.Dataset</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.MultiClassClassificationDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.MultiClassClassificationDataset.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.MultiClassClassificationDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.MultiClassClassificationDataset.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.OnevsAllDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">OnevsAllDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_idxs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.OnevsAllDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>Dataset for the 1vsALL training strategy</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set_idx</strong>  Indexed triples for the training.</p></li>
<li><p><strong>entity_idxs</strong>  mapping.</p></li>
<li><p><strong>relation_idxs</strong>  mapping.</p></li>
<li><p><strong>form</strong>  <p>?</p>
</p></li>
<li><p><strong>num_workers</strong>  int for <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.utils.data.Dataset</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.OnevsAllDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.OnevsAllDataset.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.OnevsAllDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.OnevsAllDataset.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.KvsAll">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">KvsAll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_idxs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation_idxs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">form</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KvsAll" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<dl class="simple">
<dt>Creates a dataset for KvsAll training by inheriting from torch.utils.data.Dataset.</dt><dd><p>Let D denote a dataset for KvsAll training and be defined as D:= {(x,y)_i}_i ^N, where
x: (h,r) is an unique tuple of an entity h in E and a relation r in R that has been seed in the input graph.
y: denotes a multi-label vector in [0,1]^{<a href="#id113"><span class="problematic" id="id114">|E|</span></a>} is a binary label.</p>
</dd>
</dl>
<p>orall y_i =1 s.t. (h r E_i) in KG</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>TODO</p>
</div>
<dl class="simple">
<dt>train_set_idx<span class="classifier">numpy.ndarray</span></dt><dd><p>n by 3 array representing n triples</p>
</dd>
<dt>entity_idxs<span class="classifier">dictonary</span></dt><dd><p>string representation of an entity to its integer id</p>
</dd>
<dt>relation_idxs<span class="classifier">dictonary</span></dt><dd><p>string representation of a relation to its integer id</p>
</dd>
</dl>
<p>self : torch.utils.data.Dataset</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">KvsAll</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">? array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
</pre></div>
</div>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.KvsAll.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KvsAll.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KvsAll.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KvsAll.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.AllvsAll">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">AllvsAll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_idxs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation_idxs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AllvsAll" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<dl class="simple">
<dt>Creates a dataset for AllvsAll training by inheriting from torch.utils.data.Dataset.</dt><dd><p>Let D denote a dataset for AllvsAll training and be defined as D:= {(x,y)_i}_i ^N, where
x: (h,r) is a possible unique tuple of an entity h in E and a relation r in R. Hence N = <a href="#id115"><span class="problematic" id="id116">|E|</span></a> x <a href="#id117"><span class="problematic" id="id118">|R|</span></a>
y: denotes a multi-label vector in [0,1]^{<a href="#id119"><span class="problematic" id="id120">|E|</span></a>} is a binary label.</p>
</dd>
</dl>
<p>orall y_i =1 s.t. (h r E_i) in KG</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<dl class="simple">
<dt>AllvsAll extends KvsAll via none existing (h,r). Hence, it adds data points that are labelled without 1s,</dt><dd><p>only with 0s.</p>
</dd>
</dl>
</div>
<dl class="simple">
<dt>train_set_idx<span class="classifier">numpy.ndarray</span></dt><dd><p>n by 3 array representing n triples</p>
</dd>
<dt>entity_idxs<span class="classifier">dictonary</span></dt><dd><p>string representation of an entity to its integer id</p>
</dd>
<dt>relation_idxs<span class="classifier">dictonary</span></dt><dd><p>string representation of a relation to its integer id</p>
</dd>
</dl>
<p>self : torch.utils.data.Dataset</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">AllvsAll</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">? array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
</pre></div>
</div>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.AllvsAll.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AllvsAll.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.AllvsAll.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.AllvsAll.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.KvsSampleDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">KvsSampleDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_entities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_relations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KvsSampleDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<blockquote>
<div><dl class="simple">
<dt>KvsSample a Dataset:</dt><dd><dl class="simple">
<dt>D:= {(x,y)_i}_i ^N, where</dt><dd><p>. x:(h,r) is a unique h in E and a relation r in R and
. y in [0,1]^{<a href="#id121"><span class="problematic" id="id122">|E|</span></a>} is a binary label.</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>orall y_i =1 s.t. (h r E_i) in KG</dt><dd><blockquote>
<div><dl class="simple">
<dt>At each mini-batch construction, we subsample(y), hence n</dt><dd><p><a href="#id123"><span class="problematic" id="id124">|new_y|</span></a> &lt;&lt; <a href="#id125"><span class="problematic" id="id126">|E|</span></a>
new_y contains all 1s if sum(y)&lt; neg_sample ratio
new_y contains</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>train_set_idx</dt><dd><p>Indexed triples for the training.</p>
</dd>
<dt>entity_idxs</dt><dd><p>mapping.</p>
</dd>
<dt>relation_idxs</dt><dd><p>mapping.</p>
</dd>
<dt>form</dt><dd><p>?</p>
</dd>
<dt>store</dt><dd><p>?</p>
</dd>
<dt>label_smoothing_rate</dt><dd><p>?</p>
</dd>
</dl>
<p>torch.utils.data.Dataset</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.KvsSampleDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KvsSampleDataset.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.KvsSampleDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.KvsSampleDataset.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.NegSampleDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">NegSampleDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_relations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.NegSampleDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>An abstract class representing a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code>.</p>
<p>All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite <a class="reference internal" href="#dicee.NegSampleDataset.__getitem__" title="dicee.NegSampleDataset.__getitem__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__getitem__()</span></code></a>, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
<a class="reference internal" href="#dicee.NegSampleDataset.__len__" title="dicee.NegSampleDataset.__len__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__len__()</span></code></a>, which is expected to return the size of the dataset by many
<code class="xref py py-class docutils literal notranslate"><span class="pre">Sampler</span></code> implementations and the default options
of <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>. Subclasses could also
optionally implement <code class="xref py py-meth docutils literal notranslate"><span class="pre">__getitems__()</span></code>, for speedup batched samples
loading. This method accepts list of indices of samples of batch and returns
list of samples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> by default constructs an index
sampler that yields integral indices.  To make it work with a map-style
dataset with non-integral indices/keys, a custom sampler must be provided.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.NegSampleDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.NegSampleDataset.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.NegSampleDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.NegSampleDataset.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.TriplePredictionDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">TriplePredictionDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_relations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.TriplePredictionDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<blockquote>
<div><p>Triple Dataset</p>
<blockquote>
<div><dl class="simple">
<dt>D:= {(x)_i}_i ^N, where</dt><dd><p>. x:(h,r, t) in KG is a unique h in E and a relation r in R and
. collact_fn =&gt; Generates negative triples</p>
</dd>
</dl>
<p>collect_fn:</p>
</div></blockquote>
</div></blockquote>
<p>orall (h,r,t) in G obtain, create negative triples{(h,r,x),(,r,t),(h,m,t)}</p>
<blockquote>
<div><blockquote>
<div><p>y:labels are represented in torch.float16</p>
</div></blockquote>
<dl class="simple">
<dt>train_set_idx</dt><dd><p>Indexed triples for the training.</p>
</dd>
<dt>entity_idxs</dt><dd><p>mapping.</p>
</dd>
<dt>relation_idxs</dt><dd><p>mapping.</p>
</dd>
<dt>form</dt><dd><p>?</p>
</dd>
<dt>store</dt><dd><p>?</p>
</dd>
</dl>
<p>label_smoothing_rate</p>
<p>collate_fn: batch:List[torch.IntTensor]
Returns
-
torch.utils.data.Dataset</p>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.TriplePredictionDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dicee.TriplePredictionDataset.__len__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.TriplePredictionDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.TriplePredictionDataset.__getitem__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.TriplePredictionDataset.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.TriplePredictionDataset.collate_fn" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.CVDataModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">CVDataModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_entities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_relations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.CVDataModule" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pytorch_lightning.LightningDataModule</span></code></p>
<p>Create a Dataset for cross validation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set_idx</strong>  Indexed triples for the training.</p></li>
<li><p><strong>num_entities</strong>  entity to index mapping.</p></li>
<li><p><strong>num_relations</strong>  relation to index mapping.</p></li>
<li><p><strong>batch_size</strong>  int</p></li>
<li><p><strong>form</strong>  <p>?</p>
</p></li>
<li><p><strong>num_workers</strong>  int for <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><p>?</p>
</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.CVDataModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.DataLoader</span></span></span><a class="headerlink" href="#dicee.CVDataModule.train_dataloader" title="Link to this definition"></a></dt>
<dd><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id91"><span class="problematic" id="id92">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#dicee.CVDataModule.prepare_data" title="dicee.CVDataModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#dicee.CVDataModule.setup" title="dicee.CVDataModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><a class="reference internal" href="#dicee.CVDataModule.prepare_data" title="dicee.CVDataModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#dicee.CVDataModule.setup" title="dicee.CVDataModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.CVDataModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.CVDataModule.setup" title="Link to this definition"></a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>stage</strong>  either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.CVDataModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.CVDataModule.transfer_batch_to_device" title="Link to this definition"></a></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to()</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, ).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong>  A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong>  The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong>  The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong>  If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.CVDataModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.CVDataModule.prepare_data" title="Link to this definition"></a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>


<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.QueryGenerator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">QueryGenerator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent2id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel2id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_valid</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator" title="Link to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.list2tuple">
<span class="sig-name descname"><span class="pre">list2tuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.list2tuple" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.tuple2list">
<span class="sig-name descname"><span class="pre">tuple2list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span></span><a class="headerlink" href="#dicee.QueryGenerator.tuple2list" title="Link to this definition"></a></dt>
<dd><p>Convert a nested tuple to a nested list.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.set_global_seed">
<span class="sig-name descname"><span class="pre">set_global_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.set_global_seed" title="Link to this definition"></a></dt>
<dd><p>Set seed</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.construct_graph">
<span class="sig-name descname"><span class="pre">construct_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.QueryGenerator.construct_graph" title="Link to this definition"></a></dt>
<dd><p>Construct graph from triples
Returns dicts with incoming and outgoing edges</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.fill_query">
<span class="sig-name descname"><span class="pre">fill_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_structure</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_in</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#dicee.QueryGenerator.fill_query" title="Link to this definition"></a></dt>
<dd><p>Private method for fill_query logic.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.achieve_answer">
<span class="sig-name descname"><span class="pre">achieve_answer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_in</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">set</span></span></span><a class="headerlink" href="#dicee.QueryGenerator.achieve_answer" title="Link to this definition"></a></dt>
<dd><p>Private method for achieve_answer logic.
&#64;TODO: Document the code</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.write_links">
<span class="sig-name descname"><span class="pre">write_links</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ent_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">small_ent_out</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.write_links" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.ground_queries">
<span class="sig-name descname"><span class="pre">ground_queries</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_structure</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_in</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">small_ent_in</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">small_ent_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.ground_queries" title="Link to this definition"></a></dt>
<dd><p>Generating queries and achieving answers</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.unmap">
<span class="sig-name descname"><span class="pre">unmap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">queries</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tp_answers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp_answers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fn_answers</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.unmap" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.unmap_query">
<span class="sig-name descname"><span class="pre">unmap_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_structure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id2ent</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id2rel</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.unmap_query" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.generate_queries">
<span class="sig-name descname"><span class="pre">generate_queries</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_struct</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.generate_queries" title="Link to this definition"></a></dt>
<dd><p>Passing incoming and outgoing edges to ground queries depending on mode [train valid or text]
and getting queries and answers in return
&#64; TODO: create a class for each single query struct</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.save_queries">
<span class="sig-name descname"><span class="pre">save_queries</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.save_queries" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.load_queries">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_queries</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.load_queries" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.get_queries">
<span class="sig-name descname"><span class="pre">get_queries</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.QueryGenerator.get_queries" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.save_queries_and_answers">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">save_queries_and_answers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">collections.defaultdict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.QueryGenerator.save_queries_and_answers" title="Link to this definition"></a></dt>
<dd><p>Save Queries into Disk</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.QueryGenerator.load_queries_and_answers">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_queries_and_answers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">collections.defaultdict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dicee.QueryGenerator.load_queries_and_answers" title="Link to this definition"></a></dt>
<dd><p>Load Queries from Disk to Memory</p>
</dd></dl>

</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="dicee.__version__">
<span class="sig-prename descclassname"><span class="pre">dicee.</span></span><span class="sig-name descname"><span class="pre">__version__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'0.1.4'</span></em><a class="headerlink" href="#dicee.__version__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../../usage/main.html" class="btn btn-neutral float-left" title="Dicee Manual" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="models/index.html" class="btn btn-neutral float-right" title="dicee.models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Caglar Demir.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>