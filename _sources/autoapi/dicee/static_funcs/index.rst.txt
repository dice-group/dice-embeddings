dicee.static_funcs
==================

.. py:module:: dicee.static_funcs

.. autoapi-nested-parse::

   Static utility functions for DICE embeddings.

   This module provides utility functions for model initialization, data loading,
   serialization, and various helper operations.



Attributes
----------

.. autoapisummary::

   dicee.static_funcs.MODEL_REGISTRY


Functions
---------

.. autoapisummary::

   dicee.static_funcs.create_recipriocal_triples
   dicee.static_funcs.get_er_vocab
   dicee.static_funcs.get_re_vocab
   dicee.static_funcs.get_ee_vocab
   dicee.static_funcs.timeit
   dicee.static_funcs.save_pickle
   dicee.static_funcs.load_pickle
   dicee.static_funcs.load_term_mapping
   dicee.static_funcs.select_model
   dicee.static_funcs.load_model
   dicee.static_funcs.load_model_ensemble
   dicee.static_funcs.save_numpy_ndarray
   dicee.static_funcs.numpy_data_type_changer
   dicee.static_funcs.save_checkpoint_model
   dicee.static_funcs.store
   dicee.static_funcs.add_noisy_triples
   dicee.static_funcs.read_or_load_kg
   dicee.static_funcs.intialize_model
   dicee.static_funcs.load_json
   dicee.static_funcs.save_embeddings
   dicee.static_funcs.random_prediction
   dicee.static_funcs.deploy_triple_prediction
   dicee.static_funcs.deploy_tail_entity_prediction
   dicee.static_funcs.deploy_head_entity_prediction
   dicee.static_funcs.deploy_relation_prediction
   dicee.static_funcs.vocab_to_parquet
   dicee.static_funcs.create_experiment_folder
   dicee.static_funcs.continual_training_setup_executor
   dicee.static_funcs.exponential_function
   dicee.static_funcs.load_numpy
   dicee.static_funcs.evaluate
   dicee.static_funcs.download_file
   dicee.static_funcs.download_files_from_url
   dicee.static_funcs.download_pretrained_model
   dicee.static_funcs.write_csv_from_model_parallel
   dicee.static_funcs.from_pretrained_model_write_embeddings_into_csv


Module Contents
---------------

.. py:data:: MODEL_REGISTRY
   :type:  Dict[str, Tuple[Type, str]]

.. py:function:: create_recipriocal_triples(df: pandas.DataFrame) -> pandas.DataFrame

   Add inverse triples to a DataFrame.

   For each triple (s, p, o), creates an inverse triple (o, p_inverse, s).

   :param df: DataFrame with 'subject', 'relation', and 'object' columns.

   :returns: DataFrame with original and inverse triples concatenated.


.. py:function:: get_er_vocab(data: numpy.ndarray, file_path: Optional[str] = None) -> Dict[Tuple[int, int], List[int]]

   Build entity-relation to tail vocabulary.

   :param data: Array of triples with shape (n, 3) where columns are (head, relation, tail).
   :param file_path: Optional path to save the vocabulary as pickle.

   :returns: Dictionary mapping (head, relation) pairs to list of tail entities.


.. py:function:: get_re_vocab(data: numpy.ndarray, file_path: Optional[str] = None) -> Dict[Tuple[int, int], List[int]]

   Build relation-entity (tail) to head vocabulary.

   :param data: Array of triples with shape (n, 3) where columns are (head, relation, tail).
   :param file_path: Optional path to save the vocabulary as pickle.

   :returns: Dictionary mapping (relation, tail) pairs to list of head entities.


.. py:function:: get_ee_vocab(data: numpy.ndarray, file_path: Optional[str] = None) -> Dict[Tuple[int, int], List[int]]

   Build entity-entity to relation vocabulary.

   :param data: Array of triples with shape (n, 3) where columns are (head, relation, tail).
   :param file_path: Optional path to save the vocabulary as pickle.

   :returns: Dictionary mapping (head, tail) pairs to list of relations.


.. py:function:: timeit(func: Callable) -> Callable

   Decorator to measure and print execution time and memory usage.

   :param func: Function to be timed.

   :returns: Wrapped function that prints timing information.


.. py:function:: save_pickle(*, data: Optional[object] = None, file_path: str) -> None

   Save data to a pickle file.

   Note: Consider using more portable formats (JSON, Parquet) for new code.

   :param data: Object to serialize. If None, nothing is saved.
   :param file_path: Path where the pickle file will be saved.


.. py:function:: load_pickle(file_path: str) -> object

   Load data from a pickle file.

   Note: Consider using more portable formats (JSON, Parquet) for new code.

   :param file_path: Path to the pickle file.

   :returns: Deserialized object from the pickle file.


.. py:function:: load_term_mapping(file_path: str) -> Union[dict, polars.DataFrame]

   Load term-to-index mapping from pickle or CSV file.

   Attempts to load from pickle first, falls back to CSV if not found.

   :param file_path: Base path without extension.

   :returns: Dictionary or Polars DataFrame containing the mapping.


.. py:function:: select_model(args: dict, is_continual_training: bool = None, storage_path: str = None)

.. py:function:: load_model(path_of_experiment_folder: str, model_name='model.pt', verbose=0) -> Tuple[object, Tuple[dict, dict]]

   Load weights and initialize pytorch module from namespace arguments


.. py:function:: load_model_ensemble(path_of_experiment_folder: str) -> Tuple[dicee.models.base_model.BaseKGE, Tuple[pandas.DataFrame, pandas.DataFrame]]

   Construct Ensemble Of weights and initialize pytorch module from namespace arguments

   (1) Detect models under given path
   (2) Accumulate parameters of detected models
   (3) Normalize parameters
   (4) Insert (3) into model.


.. py:function:: save_numpy_ndarray(*, data: numpy.ndarray, file_path: str)

.. py:function:: numpy_data_type_changer(train_set: numpy.ndarray, num: int) -> numpy.ndarray

   Detect most efficient data type for a given triples
   :param train_set:
   :param num:
   :return:


.. py:function:: save_checkpoint_model(model, path: str) -> None

   Store Pytorch model into disk


.. py:function:: store(trained_model, model_name: str = 'model', full_storage_path: str = None, save_embeddings_as_csv=False) -> None

.. py:function:: add_noisy_triples(train_set: pandas.DataFrame, add_noise_rate: float) -> pandas.DataFrame

   Add randomly constructed triples
   :param train_set:
   :param add_noise_rate:
   :return:


.. py:function:: read_or_load_kg(args, cls)

.. py:function:: intialize_model(args: Dict, verbose: int = 0) -> Tuple[dicee.models.base_model.BaseKGE, str]

   Initialize a knowledge graph embedding model.

   :param args: Dictionary containing model configuration including 'model' key.
   :param verbose: Verbosity level. If > 0, prints initialization message.

   :returns: Tuple of (initialized model, form of labelling string).

   :raises ValueError: If the model name is not recognized.


.. py:function:: load_json(path: str) -> Dict

   Load JSON file into a dictionary.

   :param path: Path to the JSON file.

   :returns: Dictionary containing the JSON data.

   :raises FileNotFoundError: If the file does not exist.
   :raises json.JSONDecodeError: If the file contains invalid JSON.


.. py:function:: save_embeddings(embeddings: numpy.ndarray, indexes: List, path: str) -> None

   Save embeddings to a CSV file.

   :param embeddings: NumPy array of embeddings with shape (n_items, embedding_dim).
   :param indexes: List of index labels (entity/relation names).
   :param path: Output file path.


.. py:function:: random_prediction(pre_trained_kge)

.. py:function:: deploy_triple_prediction(pre_trained_kge, str_subject, str_predicate, str_object)

.. py:function:: deploy_tail_entity_prediction(pre_trained_kge, str_subject, str_predicate, top_k)

.. py:function:: deploy_head_entity_prediction(pre_trained_kge, str_object, str_predicate, top_k)

.. py:function:: deploy_relation_prediction(pre_trained_kge, str_subject, str_object, top_k)

.. py:function:: vocab_to_parquet(vocab_to_idx, name, path_for_serialization, print_into)

.. py:function:: create_experiment_folder(folder_name: str = 'Experiments') -> str

   Create a timestamped experiment folder.

   :param folder_name: Base directory name for experiments.

   :returns: Full path to the created experiment folder.


.. py:function:: continual_training_setup_executor(executor) -> None

.. py:function:: exponential_function(x: numpy.ndarray, lam: float, ascending_order=True) -> torch.FloatTensor

.. py:function:: load_numpy(path) -> numpy.ndarray

.. py:function:: evaluate(entity_to_idx, scores, easy_answers, hard_answers)

   # @TODO: CD: Renamed this function
   Evaluate multi hop query answering on different query types


.. py:function:: download_file(url, destination_folder='.')

.. py:function:: download_files_from_url(base_url: str, destination_folder='.') -> None

   :param base_url:
   :type base_url: e.g. "https://files.dice-research.org/projects/DiceEmbeddings/KINSHIP-Keci-dim128-epoch256-KvsAll"
   :param destination_folder:
   :type destination_folder: e.g. "KINSHIP-Keci-dim128-epoch256-KvsAll"


.. py:function:: download_pretrained_model(url: str) -> str

.. py:function:: write_csv_from_model_parallel(path: str)

   Create


.. py:function:: from_pretrained_model_write_embeddings_into_csv(path: str) -> None

